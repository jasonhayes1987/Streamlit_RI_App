{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szq25bF3TAw-",
        "outputId": "5b95ee5b-147e-4499-cd38-0c9119457feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Collecting pygame\n",
            "  Downloading pygame-2.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.3)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
            "Installing collected packages: farama-notifications, pygame, gymnasium\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.1\n",
            "    Uninstalling pygame-2.5.1:\n",
            "      Successfully uninstalled pygame-2.5.1\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 pygame-2.5.2\n",
            "Requirement already satisfied: gymnasium[classic_control] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic_control]) (2.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gymnasium pygame moviepy\n",
        "!pip install gymnasium[classic_control]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zX6znPEQKKV"
      },
      "source": [
        "# Previous Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V_h9AoVuTdIk"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import RewardWrapper, wrappers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from typing import List, Union\n",
        "from pathlib import Path\n",
        "import os\n",
        "# from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFOXu0RF1CYj"
      },
      "outputs": [],
      "source": [
        "class StandardScaler():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.mean = None\n",
        "        self.standard_deviation = None\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.mean = np.mean(data, axis=0)\n",
        "        self.standard_deviation = np.sqrt(np.mean(np.square(data-self.mean), axis=0))\n",
        "\n",
        "    def transform(self, data):\n",
        "        return (data-self.mean)/self.standard_deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8fRSlPztdJ8"
      },
      "outputs": [],
      "source": [
        "class RadialBasisFunction(object):\n",
        "    \"\"\"\n",
        "    Radial Basis Function.\n",
        "    \"\"\"\n",
        "    def __init__(self, RBF_kernels):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -RBF_kernels: List of RBF kernel objects.\n",
        "        \"\"\"\n",
        "        self.RBF_kernels = RBF_kernels\n",
        "\n",
        "    def transform(self, state):\n",
        "        \"\"\"\n",
        "        Transform a state into a feature vector using each kernel.\n",
        "\n",
        "        Parameters:\n",
        "        -state: State to transform.\n",
        "\n",
        "        Returns:\n",
        "        -feature vector.\n",
        "        \"\"\"\n",
        "        vector = np.array([kernel.transform(state) for kernel in self.RBF_kernels]).flatten().reshape(1, -1)\n",
        "        # append a column of one's to the back for a bias term\n",
        "        return np.hstack((vector, np.ones((vector.shape[0], 1))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiK7ti7l4NYI"
      },
      "outputs": [],
      "source": [
        "class RBF_kernel(object):\n",
        "    \"\"\"\n",
        "    RBF Kernel.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, num_C, sigma):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -X: Input data.\n",
        "        -num_C: Number of centers of the RBFs.\n",
        "        -sigma: Sigma of the Gaussian.\n",
        "        \"\"\"\n",
        "        self.sigma=sigma\n",
        "        rng = np.random.default_rng()\n",
        "        self.centers = rng.choice(X, num_C)\n",
        "\n",
        "\n",
        "    def transform(self, state):\n",
        "        \"\"\"\n",
        "        Transform a state into a feature vector.\n",
        "\n",
        "        Parameters:\n",
        "        -state: State to transform.\n",
        "\n",
        "        Returns:\n",
        "        -feature vector.\n",
        "        \"\"\"\n",
        "        return np.exp(-np.sum(np.square(state - self.centers) / (2 * self.sigma ** 2), axis=1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q630KsilrBbR"
      },
      "outputs": [],
      "source": [
        "# code the output layer class\n",
        "class DenseLayer(object):\n",
        "    \"\"\"\n",
        "    Dense Layer class.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -input_size: Input size.\n",
        "        -output_size: Output size.\n",
        "        \"\"\"\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        # add one to input size to account for bias term\n",
        "        self.W = np.random.randn(input_size+1, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -X: Input data.\n",
        "\n",
        "        Returns:\n",
        "        -output: Output of the layer.\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        return np.dot(X, self.W)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate, action):\n",
        "        \"\"\"\n",
        "        Backward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -output_gradient: Gradient of the output.\n",
        "        -learning_rate: Learning rate.\n",
        "\n",
        "        Returns:\n",
        "        -input_gradient: Gradient of the input.\n",
        "        \"\"\"\n",
        "        self.W[:, action] += learning_rate * np.dot(output_gradient, self.X)\n",
        "        return np.dot(output_gradient, self.W)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yk_EOWZwLc5"
      },
      "outputs": [],
      "source": [
        "# code a temporal difference loss function since that is what reinforcement learning uses\n",
        "class TemporalDifferenceLoss(object):\n",
        "    \"\"\"\n",
        "    Temporal Difference Loss class.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -y_true: True labels.\n",
        "        -y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "        -loss: Temporal difference loss.\n",
        "        \"\"\"\n",
        "        return y_true - y_pred\n",
        "\n",
        "    def backward(self, y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Backward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -y_true: True labels.\n",
        "        -y_pred: Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "        -input_gradient: Gradient of the input.\n",
        "        \"\"\"\n",
        "        return -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scT_BnwP5QaE"
      },
      "outputs": [],
      "source": [
        "# code a model class\n",
        "class Model(object):\n",
        "    \"\"\"\n",
        "    Model class.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, loss, transformer=None, scaler=None):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -layers: List of layers.\n",
        "        -loss: Loss class.\n",
        "        -transformer: Transformer class. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "        self.transformer = transformer\n",
        "        self.scaler = scaler\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -X: Input data.\n",
        "\n",
        "        Returns:\n",
        "        -output: Output of the model.\n",
        "        \"\"\"\n",
        "        if self.scaler:\n",
        "            X = self.scaler.transform(X)\n",
        "        if self.transformer:\n",
        "            X = self.transformer.transform(X)\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate, action):\n",
        "        \"\"\"\n",
        "        Backward pass.\n",
        "\n",
        "        Parameters:\n",
        "        -output_gradient: Gradient of the output.\n",
        "        -learning_rate: Learning rate.\n",
        "\n",
        "        Returns:\n",
        "        -input_gradient: Gradient of the input.\n",
        "        \"\"\"\n",
        "        for layer in reversed(self.layers):\n",
        "            output_gradient = layer.backward(output_gradient, learning_rate, action)\n",
        "        return output_gradient\n",
        "\n",
        "\n",
        "    def fit(self, X, y, epochs, learning_rate):\n",
        "        \"\"\"\n",
        "        Fit.\n",
        "\n",
        "        Parameters:\n",
        "        -X: Input data.\n",
        "        -y: True labels.\n",
        "        -epochs: Number of epochs.\n",
        "        -learning_rate: Learning rate.\n",
        "\n",
        "        Returns:\n",
        "        -losses: List of losses.\n",
        "        \"\"\"\n",
        "        losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            loss = self.loss.forward(y, output)\n",
        "            losses.append(loss)\n",
        "            if epoch % 100 == 0:\n",
        "                print('Epoch: {0}, Loss: {1}'.format(epoch, loss))\n",
        "            gradient = self.loss.backward(y, output)\n",
        "            for layer in reversed(self.layers):\n",
        "                gradient = layer.backward(gradient, learning_rate)\n",
        "\n",
        "        return losses\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9_SOxclnIb7"
      },
      "outputs": [],
      "source": [
        "# code a new agent class that can use a continuous observation space and uses\n",
        "# neural networks to learn\n",
        "class Agent:\n",
        "    def __init__(self, env, learning_model, learning_rate, gamma, epsilon):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -env: Environment.\n",
        "        -learning_model: Learning model.\n",
        "        -gamma: Discount factor.\n",
        "        -epsilon: Epsilon greedy random action threshold.\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.learning_model = learning_model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Get action from the Q-table.\n",
        "\n",
        "        Parameters:\n",
        "        -state: int of length n_features representing the assigned bin of each feature\n",
        "\n",
        "        Returns:\n",
        "        -action: random or optimal action\n",
        "        \"\"\"\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return self.env.action_space.sample()\n",
        "        else:\n",
        "            return np.argmax(self.learning_model.forward(state))\n",
        "\n",
        "    def run_episode(self):\n",
        "        \"\"\"\n",
        "        Run an episode of the agent.\n",
        "\n",
        "        Returns:\n",
        "        -tot_reward: Total reward for the episode.\n",
        "        \"\"\"\n",
        "        state, _ = self.env.reset()\n",
        "        done = False\n",
        "        tot_reward = 0\n",
        "        while not done:\n",
        "            action = self.get_action(state)\n",
        "            next_state, reward, term, trunc, _ = self.env.step(action)\n",
        "            tot_reward += reward\n",
        "            target = reward + self.gamma * np.max(self.learning_model.forward(next_state))\n",
        "            prediction = self.learning_model.forward(state)[:, action]\n",
        "            loss = self.learning_model.loss.forward(target, prediction)\n",
        "            output_gradient = self.learning_model.loss.backward(target, prediction)\n",
        "            output_gradient = self.learning_model.backward(output_gradient, self.learning_rate, action)\n",
        "            state = next_state\n",
        "            if term or trunc:\n",
        "                done = True\n",
        "        return tot_reward, loss\n",
        "\n",
        "\n",
        "    def train(self, episodes):\n",
        "        \"\"\"\n",
        "        Train the agent for a number of episodes.\n",
        "\n",
        "        Parameters:\n",
        "        -episodes: Number of episodes to train for.\n",
        "\n",
        "        Returns:\n",
        "        -rewards: List of rewards per episode.\n",
        "        \"\"\"\n",
        "\n",
        "        rewards = []\n",
        "        losses = []\n",
        "        for i in range(episodes):\n",
        "            reward, loss = self.run_episode()\n",
        "            rewards.append(reward)\n",
        "            losses.append(loss)\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Episode {i}; episode reward: {rewards[-1]}; AVG/100 reward: {np.mean(rewards[-100:])}; loss: {losses[-1]}\")\n",
        "\n",
        "        return rewards, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPQspXgU7_6i"
      },
      "outputs": [],
      "source": [
        "# instantiate environment and generate an array of sample states to fit standard scaler\n",
        "# and choose rbf kernel centers\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "X = np.array([env.observation_space.sample() for _ in range(10000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wREZ6p1l86e"
      },
      "outputs": [],
      "source": [
        "# create and fit standard scaler to data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "KGGz1Gfr4s_T",
        "outputId": "029423a9-5295-4d65-bc8d-98e6e7e2bad2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e5662da6a6cf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m rbf = RadialBasisFunction([RBF_kernel(X, 500, 0.5),\n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mRBF_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mRBF_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            RBF_kernel(X, 500, 2.0)]\n\u001b[1;32m      5\u001b[0m                           )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RadialBasisFunction' is not defined"
          ]
        }
      ],
      "source": [
        "rbf = RadialBasisFunction([RBF_kernel(X, 500, 0.05),\n",
        "                           RBF_kernel(X, 500, 0.1),\n",
        "                           RBF_kernel(X, 500, 0.5),\n",
        "                           RBF_kernel(X, 500, 1.0)]\n",
        "                          )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Lwfws_blm67v",
        "outputId": "d2362503-2d0d-4050-b3d5-acd1d7e124e7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6d7905bc1e4f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemporalDifferenceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TemporalDifferenceLoss' is not defined"
          ]
        }
      ],
      "source": [
        "tdl = TemporalDifferenceLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV9kdnyY6Tww"
      },
      "outputs": [],
      "source": [
        "# create a model using layers\n",
        "model = Model(\n",
        "    [DenseLayer(2000, 3)],\n",
        "    loss = tdl,\n",
        "    transformer=rbf,\n",
        "    scaler = scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwxfAz9KnOz1"
      },
      "outputs": [],
      "source": [
        "agent = Agent(env, model, 0.001, 0.99, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "GwaL-hAx18vN",
        "outputId": "bdcff980-1020-44dc-f090-01d9d8cc360b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-2.60733924]\n",
            "Episode 10; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-17.01279561]\n",
            "Episode 20; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-32.84743177]\n",
            "Episode 30; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-47.86022775]\n",
            "Episode 40; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-62.53048168]\n",
            "Episode 50; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-74.26813223]\n",
            "Episode 60; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-93.01395429]\n",
            "Episode 70; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-102.68845043]\n",
            "Episode 80; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-123.11046016]\n",
            "Episode 90; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-135.12320641]\n",
            "Episode 100; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-151.5572792]\n",
            "Episode 110; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-165.17066817]\n",
            "Episode 120; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-172.87803556]\n",
            "Episode 130; episode reward: -200.0; AVG/100 reward: -200.0; loss: [-197.87107734]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-f8c73a389dea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-12d99d972860>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, episodes)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-12d99d972860>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtot_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moutput_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-a0eae681d648>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1a73b4ec5fb9>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF_kernels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# append a column of one's to the back for a bias term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1a73b4ec5fb9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRBF_kernels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# append a column of one's to the back for a bias term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-957a3b4322b5>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2298\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2299\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "rewards, losses = agent.train(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLp8ZCd4G8_p",
        "outputId": "eef77eed-a843-4cc4-ea55-026ef8d96aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action taken: 0\n",
            "next_state: [-0.55217505 -0.00079186], reward: -1.0, term: False, trunc: False\n",
            "total reward: -1.0\n",
            "target: -13.127096604603425\n",
            "prediction: [-12.26140471]\n",
            "loss: [-0.8656919]\n",
            "output gradient 1: -1\n",
            "output gradient 2: [[ 0.95783259  1.65830431  0.50248964]\n",
            " [-1.64889667  0.28784516  1.44635932]\n",
            " [ 0.12463473  0.02256114  1.24633287]\n",
            " ...\n",
            " [ 0.38392523  0.21678581  0.84329568]\n",
            " [ 2.38526893 -0.11831355  0.72243228]\n",
            " [ 0.61280621 -0.82701668 -0.67635865]]\n",
            "output gradient 2 shape: (2000, 3)\n"
          ]
        }
      ],
      "source": [
        "state, _ = env.reset()\n",
        "done = False\n",
        "tot_reward = 0\n",
        "if not done:\n",
        "    action = agent.get_action(state)\n",
        "    # action = Agent.get_action(state)\n",
        "    print(f'action taken: {action}')\n",
        "    next_state, reward, term, trunc, _ = agent.env.step(action)\n",
        "    print(f'next_state: {next_state}, reward: {reward}, term: {term}, trunc: {trunc}')\n",
        "    tot_reward += reward\n",
        "    print(f'total reward: {tot_reward}')\n",
        "    if term or trunc:\n",
        "        done = True\n",
        "    target = reward + agent.gamma * np.max(agent.learning_model.forward(next_state))\n",
        "    print(f'target: {target}')\n",
        "    prediction = agent.learning_model.forward(state)[:, action]\n",
        "    print(f'prediction: {prediction}')\n",
        "    loss = agent.learning_model.loss.forward(target, prediction)\n",
        "    print(f'loss: {loss}')\n",
        "    output_gradient = agent.learning_model.loss.backward(target, prediction)\n",
        "    print(f'output gradient 1: {output_gradient}')\n",
        "    output_gradient = agent.learning_model.backward(output_gradient, agent.learning_rate, action)\n",
        "    print(f'output gradient 2: {output_gradient}')\n",
        "    print(f'output gradient 2 shape: {output_gradient.shape}')\n",
        "    state = next_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_HG4qyX2FWJ",
        "outputId": "e30e0976-4b86-4665-8862-e5269a1e4cc7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.learning_model.layers[0].W[:,1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHZDJqQ4c5KU"
      },
      "source": [
        "## Unit testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpbD5Qaw1oPF",
        "outputId": "a00a6018-d356-4326-95b9-db23423eebd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernel 0 center: [[1.8966708e-05 5.8227245e-02]]\n",
            "kernel 0 variance: 0.5\n",
            "kernel 1 center: [[-1.0237465  -0.05115322]]\n",
            "kernel 1 variance: 1.0\n",
            "initial weights\n",
            "[[-0.69746489 -1.8421081   0.0127258 ]\n",
            " [-2.01116415 -0.54271882 -1.38573249]\n",
            " [ 0.2266632  -1.79648229  1.1964286 ]]\n",
            "initial state: [-0.4757288  0.       ]\n"
          ]
        }
      ],
      "source": [
        "## setup test ##\n",
        "\n",
        "# instantiate environment\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "# generate an array of sample states to use as X\n",
        "X = np.array([env.observation_space.sample() for _ in range(10000)])\n",
        "# create a simple RBF using 2 kernels, each with one center but a different variance\n",
        "rbf_test = RadialBasisFunction([RBF_kernel(X, 1, 0.5),\n",
        "                                RBF_kernel(X, 1, 1.0)]\n",
        "                              )\n",
        "# print rbf kernel info\n",
        "for i,kernel in enumerate(rbf_test.RBF_kernels):\n",
        "    print(f'kernel {i} center: {kernel.centers}')\n",
        "    print(f'kernel {i} variance: {kernel.sigma}')\n",
        "# create layer object\n",
        "layer = DenseLayer(2, 3)\n",
        "# print initial weights\n",
        "print('initial weights')\n",
        "print(layer.W)\n",
        "# create td loss object\n",
        "tdl_test = TemporalDifferenceLoss()\n",
        "# create model\n",
        "# create a model\n",
        "model = Model([layer], tdl_test, transformer=rbf_test)\n",
        "# create an agent\n",
        "agent = Agent(env, model, 0.01, 0.99, 0.1)\n",
        "# reset env state\n",
        "state, _ = agent.env.reset()\n",
        "# print initial state\n",
        "print(f'initial state: {state}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBu9yyilnRS9",
        "outputId": "b8d7c5e1-8486-4623-95fb-0644e734662a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model weights:\n",
            "[[ 0.2191539   1.30698558  0.65683389]\n",
            " [-0.84340084  0.6428416   0.92864706]]\n",
            "kernel 0 center: [[-1.130281  -0.0277459]]\n",
            "kernel 0 variance: 0.5\n",
            "kernel 1 center: [[-0.5831007  0.0144438]]\n",
            "kernel 1 variance: 1.0\n"
          ]
        }
      ],
      "source": [
        "agent.learning_model.transformer.RBF_kernels[0].centers = np.array([[-1.130281, -0.0277459]])\n",
        "agent.learning_model.transformer.RBF_kernels[1].centers = np.array([[-0.5831007, 0.0144438]])\n",
        "agent.learning_model.layers[0].W = np.array([[ 0.2191539, 1.30698558, 0.65683389],\n",
        "                                             [-0.84340084, 0.6428416, 0.92864706]])\n",
        "state = np.array([-0.4954536, 0.])\n",
        "\n",
        "print('model weights:')\n",
        "print(agent.learning_model.layers[0].W)\n",
        "for i, kernel in enumerate(agent.learning_model.transformer.RBF_kernels):\n",
        "    print(f'kernel {i} center: {kernel.centers}')\n",
        "    print(f'kernel {i} variance: {kernel.sigma}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OI_qf47j4f59",
        "outputId": "d9151982-16ea-4448-cb52-a01f27a3421a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.03420244]]\n",
            "action: 2\n",
            "next_state: [-0.20869389 -0.00639961], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.03420244]\n",
            "target: 62.647217168390476\n",
            "td loss: [2.61301473]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.09688669]\n",
            " [  2.01116415   0.54271882 -21.53226574]\n",
            " [ -0.2266632    1.79648229 -29.7064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.09688669]\n",
            " [-2.01116415 -0.54271882 21.53226574]\n",
            " [ 0.2266632  -1.79648229 29.7064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.05537694]]\n",
            "action: 2\n",
            "next_state: [-0.21611933 -0.00742544], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.05537694]\n",
            "target: 62.63894811247363\n",
            "td loss: [2.58357117]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.10591652]\n",
            " [  2.01116415   0.54271882 -21.53947595]\n",
            " [ -0.2266632    1.79648229 -29.7164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.10591652]\n",
            " [-2.01116415 -0.54271882 21.53947595]\n",
            " [ 0.2266632  -1.79648229 29.7164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.07655982]]\n",
            "action: 2\n",
            "next_state: [-0.22453746 -0.00841813], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.07655982]\n",
            "target: 62.622676677348984\n",
            "td loss: [2.54611686]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.11487724]\n",
            " [  2.01116415   0.54271882 -21.54673541]\n",
            " [ -0.2266632    1.79648229 -29.7264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.11487724]\n",
            " [-2.01116415 -0.54271882 21.54673541]\n",
            " [ 0.2266632  -1.79648229 29.7264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.09775118]]\n",
            "action: 2\n",
            "next_state: [-0.23390952 -0.00937206], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.09775118]\n",
            "target: 62.59707209220402\n",
            "td loss: [2.49932091]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.12375901]\n",
            " [  2.01116415   0.54271882 -21.55404941]\n",
            " [ -0.2266632    1.79648229 -29.7364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.12375901]\n",
            " [-2.01116415 -0.54271882 21.55404941]\n",
            " [ 0.2266632  -1.79648229 29.7364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.11895069]]\n",
            "action: 2\n",
            "next_state: [-0.2441909  -0.01028138], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.11895069]\n",
            "target: 62.560816481987544\n",
            "td loss: [2.44186579]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.1325517 ]\n",
            " [  2.01116415   0.54271882 -21.56142294]\n",
            " [ -0.2266632    1.79648229 -29.7464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.1325517 ]\n",
            " [-2.01116415 -0.54271882 21.56142294]\n",
            " [ 0.2266632  -1.79648229 29.7464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.14015758]]\n",
            "action: 2\n",
            "next_state: [-0.25533092 -0.01114002], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.14015758]\n",
            "target: 62.512684710630595\n",
            "td loss: [2.37252713]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.14124502]\n",
            " [  2.01116415   0.54271882 -21.56886058]\n",
            " [ -0.2266632    1.79648229 -29.7564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.14124502]\n",
            " [-2.01116415 -0.54271882 21.56886058]\n",
            " [ 0.2266632  -1.79648229 29.7564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.16137062]]\n",
            "action: 2\n",
            "next_state: [-0.26727268 -0.01194176], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.16137062]\n",
            "target: 62.45158600138155\n",
            "td loss: [2.29021538]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.14982857]\n",
            " [  2.01116415   0.54271882 -21.57636648]\n",
            " [ -0.2266632    1.79648229 -29.7664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.14982857]\n",
            " [-2.01116415 -0.54271882 21.57636648]\n",
            " [ 0.2266632  -1.79648229 29.7664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.18258818]]\n",
            "action: 2\n",
            "next_state: [-0.27995294 -0.01268026], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.18258818]\n",
            "target: 62.37664693474949\n",
            "td loss: [2.19405875]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.15829205]\n",
            " [  2.01116415   0.54271882 -21.58394434]\n",
            " [ -0.2266632    1.79648229 -29.7764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.15829205]\n",
            " [-2.01116415 -0.54271882 21.58394434]\n",
            " [ 0.2266632  -1.79648229 29.7764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.20380822]]\n",
            "action: 2\n",
            "next_state: [-0.29330212 -0.01334918], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.20380822]\n",
            "target: 62.28725074146763\n",
            "td loss: [2.08344252]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.16662539]\n",
            " [  2.01116415   0.54271882 -21.59159733]\n",
            " [ -0.2266632    1.79648229 -29.7864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.16662539]\n",
            " [-2.01116415 -0.54271882 21.59159733]\n",
            " [ 0.2266632  -1.79648229 29.7864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.22502837]]\n",
            "action: 2\n",
            "next_state: [-0.30724436 -0.01394224], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.22502837]\n",
            "target: 62.18309813667508\n",
            "td loss: [1.95806977]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.17481894]\n",
            " [  2.01116415   0.54271882 -21.59932807]\n",
            " [ -0.2266632    1.79648229 -29.7964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.17481894]\n",
            " [-2.01116415 -0.54271882 21.59932807]\n",
            " [ 0.2266632  -1.79648229 29.7964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.24624599]]\n",
            "action: 2\n",
            "next_state: [-0.3216977  -0.01445334], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.24624599]\n",
            "target: 62.064244635696575\n",
            "td loss: [1.81799864]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.18286367]\n",
            " [  2.01116415   0.54271882 -21.60713862]\n",
            " [ -0.2266632    1.79648229 -29.8064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.18286367]\n",
            " [-2.01116415 -0.54271882 21.60713862]\n",
            " [ 0.2266632  -1.79648229 29.8064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.26745824]]\n",
            "action: 2\n",
            "next_state: [-0.3365744  -0.01487669], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.26745824]\n",
            "target: 61.93112386091768\n",
            "td loss: [1.66366562]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.19075138]\n",
            " [  2.01116415   0.54271882 -21.61503042]\n",
            " [ -0.2266632    1.79648229 -29.8164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.19075138]\n",
            " [-2.01116415 -0.54271882 21.61503042]\n",
            " [ 0.2266632  -1.79648229 29.8164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.28866217]]\n",
            "action: 2\n",
            "next_state: [-0.35178134 -0.01520693], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.28866217]\n",
            "target: 61.78456001504761\n",
            "td loss: [1.49589784]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.19847492]\n",
            " [  2.01116415   0.54271882 -21.6230043 ]\n",
            " [ -0.2266632    1.79648229 -29.8264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.19847492]\n",
            " [-2.01116415 -0.54271882 21.6230043 ]\n",
            " [ 0.2266632  -1.79648229 29.8264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.3098548 ]]\n",
            "action: 2\n",
            "next_state: [-0.36722058 -0.01543925], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.3098548]\n",
            "target: 61.62575499338133\n",
            "td loss: [1.31590019]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.20602835]\n",
            " [  2.01116415   0.54271882 -21.63106043]\n",
            " [ -0.2266632    1.79648229 -29.8364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.20602835]\n",
            " [-2.01116415 -0.54271882 21.63106043]\n",
            " [ 0.2266632  -1.79648229 29.8364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.33103322]]\n",
            "action: 2\n",
            "next_state: [-0.38279012 -0.01556954], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.33103322]\n",
            "target: 61.45627686721145\n",
            "td loss: [1.12524365]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.21340713]\n",
            " [  2.01116415   0.54271882 -21.63919839]\n",
            " [ -0.2266632    1.79648229 -29.8464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.21340713]\n",
            " [-2.01116415 -0.54271882 21.63919839]\n",
            " [ 0.2266632  -1.79648229 29.8464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.35219467]]\n",
            "action: 2\n",
            "next_state: [-0.3983846  -0.01559447], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.35219467]\n",
            "target: 61.27800811600474\n",
            "td loss: [0.92581345]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.22060824]\n",
            " [  2.01116415   0.54271882 -21.64741711]\n",
            " [ -0.2266632    1.79648229 -29.8564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.22060824]\n",
            " [-2.01116415 -0.54271882 21.64741711]\n",
            " [ 0.2266632  -1.79648229 29.8564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.37333663]]\n",
            "action: 2\n",
            "next_state: [-0.41389623 -0.01551165], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.37333663]\n",
            "target: 61.093103523836454\n",
            "td loss: [0.71976689]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.22763031]\n",
            " [  2.01116415   0.54271882 -21.65571492]\n",
            " [ -0.2266632    1.79648229 -29.8664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.22763031]\n",
            " [-2.01116415 -0.54271882 21.65571492]\n",
            " [ 0.2266632  -1.79648229 29.8664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.39445689]]\n",
            "action: 2\n",
            "next_state: [-0.42921588 -0.01531965], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.39445689]\n",
            "target: 60.903922042696095\n",
            "td loss: [0.50946515]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.23447369]\n",
            " [  2.01116415   0.54271882 -21.66408957]\n",
            " [ -0.2266632    1.79648229 -29.8764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.23447369]\n",
            " [-2.01116415 -0.54271882 21.66408957]\n",
            " [ 0.2266632  -1.79648229 29.8764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.41555361]]\n",
            "action: 2\n",
            "next_state: [-0.44423398 -0.0150181 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.41555361]\n",
            "target: 60.71296037027092\n",
            "td loss: [0.29740676]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.24114045]\n",
            " [  2.01116415   0.54271882 -21.67253829]\n",
            " [ -0.2266632    1.79648229 -29.8864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.24114045]\n",
            " [-2.01116415 -0.54271882 21.67253829]\n",
            " [ 0.2266632  -1.79648229 29.8864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.43662535]]\n",
            "action: 2\n",
            "next_state: [-0.4588417  -0.01460772], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.43662535]\n",
            "target: 60.52278547289056\n",
            "td loss: [0.08616013]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.24763439]\n",
            " [  2.01116415   0.54271882 -21.6810578 ]\n",
            " [ -0.2266632    1.79648229 -29.8964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.24763439]\n",
            " [-2.01116415 -0.54271882 21.6810578 ]\n",
            " [ 0.2266632  -1.79648229 29.8964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.45767113]]\n",
            "action: 2\n",
            "next_state: [-0.47293207 -0.01409035], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.45767113]\n",
            "target: 60.33596688531046\n",
            "td loss: [-0.12170425]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.25396097]\n",
            " [  2.01116415   0.54271882 -21.68964437]\n",
            " [ -0.2266632    1.79648229 -29.9064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.25396097]\n",
            " [-2.01116415 -0.54271882 21.68964437]\n",
            " [ 0.2266632  -1.79648229 29.9064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.47869045]]\n",
            "action: 2\n",
            "next_state: [-0.48640096 -0.01346889], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.47869045]\n",
            "target: 60.15500976140537\n",
            "td loss: [-0.32368069]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.26012725]\n",
            " [  2.01116415   0.54271882 -21.6982939 ]\n",
            " [ -0.2266632    1.79648229 -29.9164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.26012725]\n",
            " [-2.01116415 -0.54271882 21.6982939 ]\n",
            " [ 0.2266632  -1.79648229 29.9164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.49968326]]\n",
            "action: 2\n",
            "next_state: [-0.49914825 -0.0127473 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.49968326]\n",
            "target: 59.982313351786885\n",
            "td loss: [-0.5173699]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.26614176]\n",
            " [  2.01116415   0.54271882 -21.70700194]\n",
            " [ -0.2266632    1.79648229 -29.9264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.26614176]\n",
            " [-2.01116415 -0.54271882 21.70700194]\n",
            " [ 0.2266632  -1.79648229 29.9264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.52064997]]\n",
            "action: 2\n",
            "next_state: [-0.5110788  -0.01193051], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.52064997]\n",
            "target: 59.82010625229592\n",
            "td loss: [-0.70054372]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.27201437]\n",
            " [  2.01116415   0.54271882 -21.71576374]\n",
            " [ -0.2266632    1.79648229 -29.9364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.27201437]\n",
            " [-2.01116415 -0.54271882 21.71576374]\n",
            " [ 0.2266632  -1.79648229 29.9364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.54159145]]\n",
            "action: 2\n",
            "next_state: [-0.52210313 -0.01102439], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.54159145]\n",
            "target: 59.67045126991217\n",
            "td loss: [-0.87114018]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.27775615]\n",
            " [  2.01116415   0.54271882 -21.72457435]\n",
            " [ -0.2266632    1.79648229 -29.9464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.27775615]\n",
            " [-2.01116415 -0.54271882 21.72457435]\n",
            " [ 0.2266632  -1.79648229 29.9464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.56250899]]\n",
            "action: 2\n",
            "next_state: [-0.53213876 -0.01003561], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.56250899]\n",
            "target: 59.535183019189155\n",
            "td loss: [-1.02732597]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.28337925]\n",
            " [  2.01116415   0.54271882 -21.73342863]\n",
            " [ -0.2266632    1.79648229 -29.9564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.28337925]\n",
            " [-2.01116415 -0.54271882 21.73342863]\n",
            " [ 0.2266632  -1.79648229 29.9564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.58340423]]\n",
            "action: 2\n",
            "next_state: [-0.54111034 -0.00897156], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.58340423]\n",
            "target: 59.4159250183378\n",
            "td loss: [-1.16747921]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.28889667]\n",
            " [  2.01116415   0.54271882 -21.74232129]\n",
            " [ -0.2266632    1.79648229 -29.9664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.28889667]\n",
            " [-2.01116415 -0.54271882 21.74232129]\n",
            " [ 0.2266632  -1.79648229 29.9664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.6042792 ]]\n",
            "action: 2\n",
            "next_state: [-0.5489506  -0.00784029], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.6042792]\n",
            "target: 59.31408300657464\n",
            "td loss: [-1.29019619]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.29432223]\n",
            " [  2.01116415   0.54271882 -21.75124696]\n",
            " [ -0.2266632    1.79648229 -29.9764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.29432223]\n",
            " [-2.01116415 -0.54271882 21.75124696]\n",
            " [ 0.2266632  -1.79648229 29.9764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.62513621]]\n",
            "action: 2\n",
            "next_state: [-0.55560094 -0.00665033], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.62513621]\n",
            "target: 59.23083543170559\n",
            "td loss: [-1.39430077]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.29967032]\n",
            " [  2.01116415   0.54271882 -21.7602002 ]\n",
            " [ -0.2266632    1.79648229 -29.9864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.29967032]\n",
            " [-2.01116415 -0.54271882 21.7602002 ]\n",
            " [ 0.2266632  -1.79648229 29.9864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.64597782]]\n",
            "action: 2\n",
            "next_state: [-0.5610116  -0.00541068], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.64597782]\n",
            "target: 59.16715442706096\n",
            "td loss: [-1.4788234]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.30495586]\n",
            " [  2.01116415   0.54271882 -21.7691755 ]\n",
            " [ -0.2266632    1.79648229 -29.9964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.30495586]\n",
            " [-2.01116415 -0.54271882 21.7691755 ]\n",
            " [ 0.2266632  -1.79648229 29.9964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.66680685]]\n",
            "action: 2\n",
            "next_state: [-0.5651423  -0.00413068], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.66680685]\n",
            "target: 59.12381058211466\n",
            "td loss: [-1.54299627]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.31019414]\n",
            " [  2.01116415   0.54271882 -21.77816737]\n",
            " [ -0.2266632    1.79648229 -30.0064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.31019414]\n",
            " [-2.01116415 -0.54271882 21.77816737]\n",
            " [ 0.2266632  -1.79648229 30.0064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.68762627]]\n",
            "action: 2\n",
            "next_state: [-0.5679622  -0.00281991], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.68762627]\n",
            "target: 59.101381198408795\n",
            "td loss: [-1.58624507]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.31540074]\n",
            " [  2.01116415   0.54271882 -21.78717028]\n",
            " [ -0.2266632    1.79648229 -30.0164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.31540074]\n",
            " [-2.01116415 -0.54271882 21.78717028]\n",
            " [ 0.2266632  -1.79648229 30.0164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.70843917]]\n",
            "action: 2\n",
            "next_state: [-0.5694504  -0.00148816], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.70843917]\n",
            "target: 59.1002653286515\n",
            "td loss: [-1.60817384]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.32059141]\n",
            " [  2.01116415   0.54271882 -21.7961787 ]\n",
            " [ -0.2266632    1.79648229 -30.0264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.32059141]\n",
            " [-2.01116415 -0.54271882 21.7961787 ]\n",
            " [ 0.2266632  -1.79648229 30.0264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.72924877]]\n",
            "action: 2\n",
            "next_state: [-5.6959575e-01 -1.4535870e-04], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.72924877]\n",
            "target: 59.120682367850314\n",
            "td loss: [-1.60856641]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.32578201]\n",
            " [  2.01116415   0.54271882 -21.8051871 ]\n",
            " [ -0.2266632    1.79648229 -30.0364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.32578201]\n",
            " [-2.01116415 -0.54271882 21.8051871 ]\n",
            " [ 0.2266632  -1.79648229 30.0364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.75005833]]\n",
            "action: 2\n",
            "next_state: [-0.5683972   0.00119852], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.75005833]\n",
            "target: 59.162680629809735\n",
            "td loss: [-1.5873777]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.3309884 ]\n",
            " [  2.01116415   0.54271882 -21.81418997]\n",
            " [ -0.2266632    1.79648229 -30.0464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.3309884 ]\n",
            " [-2.01116415 -0.54271882 21.81418997]\n",
            " [ 0.2266632  -1.79648229 30.0464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.77087109]]\n",
            "action: 2\n",
            "next_state: [-0.5658637  0.0025335], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.77087109]\n",
            "target: 59.2261376616834\n",
            "td loss: [-1.54473343]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.33622637]\n",
            " [  2.01116415   0.54271882 -21.82318179]\n",
            " [ -0.2266632    1.79648229 -30.0564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.33622637]\n",
            " [-2.01116415 -0.54271882 21.82318179]\n",
            " [ 0.2266632  -1.79648229 30.0564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.7916903 ]]\n",
            "action: 2\n",
            "next_state: [-0.56201404  0.00384964], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.7916903]\n",
            "target: 59.310748638375095\n",
            "td loss: [-1.48094167]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.34151156]\n",
            " [  2.01116415   0.54271882 -21.83215707]\n",
            " [ -0.2266632    1.79648229 -30.0664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.34151156]\n",
            " [-2.01116415 -0.54271882 21.83215707]\n",
            " [ 0.2266632  -1.79648229 30.0664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.81251913]]\n",
            "action: 2\n",
            "next_state: [-0.55687696  0.00513712], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.81251913]\n",
            "target: 59.41602820235425\n",
            "td loss: [-1.39649093]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.34685934]\n",
            " [  2.01116415   0.54271882 -21.84111033]\n",
            " [ -0.2266632    1.79648229 -30.0764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.34685934]\n",
            " [-2.01116415 -0.54271882 21.84111033]\n",
            " [ 0.2266632  -1.79648229 30.0764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.83336061]]\n",
            "action: 2\n",
            "next_state: [-0.5504907   0.00638629], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.83336061]\n",
            "target: 59.54129140636129\n",
            "td loss: [-1.2920692]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.35228473]\n",
            " [  2.01116415   0.54271882 -21.85003611]\n",
            " [ -0.2266632    1.79648229 -30.0864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.35228473]\n",
            " [-2.01116415 -0.54271882 21.85003611]\n",
            " [ 0.2266632  -1.79648229 30.0864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.85421762]]\n",
            "action: 2\n",
            "next_state: [-0.5429029   0.00758776], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.85421762]\n",
            "target: 59.68565029459937\n",
            "td loss: [-1.16856733]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.35780225]\n",
            " [  2.01116415   0.54271882 -21.85892902]\n",
            " [ -0.2266632    1.79648229 -30.0964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.35780225]\n",
            " [-2.01116415 -0.54271882 21.85892902]\n",
            " [ 0.2266632  -1.79648229 30.0964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.87509286]]\n",
            "action: 2\n",
            "next_state: [-0.53417045  0.00873246], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.87509286]\n",
            "target: 59.8479890065999\n",
            "td loss: [-1.02710386]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.36342583]\n",
            " [  2.01116415   0.54271882 -21.86778373]\n",
            " [ -0.2266632    1.79648229 -30.1064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.36342583]\n",
            " [-2.01116415 -0.54271882 21.86778373]\n",
            " [ 0.2266632  -1.79648229 30.1064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.89598875]]\n",
            "action: 2\n",
            "next_state: [-0.5243587   0.00981173], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.89598875]\n",
            "target: 60.026975125383096\n",
            "td loss: [-0.86901363]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.36916866]\n",
            " [  2.01116415   0.54271882 -21.87659501]\n",
            " [ -0.2266632    1.79648229 -30.1164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.36916866]\n",
            " [-2.01116415 -0.54271882 21.87659501]\n",
            " [ 0.2266632  -1.79648229 30.1164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.91690743]]\n",
            "action: 2\n",
            "next_state: [-0.5135413   0.01081743], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.91690743]\n",
            "target: 60.22102971029566\n",
            "td loss: [-0.69587772]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.37504305]\n",
            " [  2.01116415   0.54271882 -21.88535777]\n",
            " [ -0.2266632    1.79648229 -30.1264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.37504305]\n",
            " [-2.01116415 -0.54271882 21.88535777]\n",
            " [ 0.2266632  -1.79648229 30.1264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.93785069]]\n",
            "action: 2\n",
            "next_state: [-0.5017992   0.01174201], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.93785069]\n",
            "target: 60.428350015441566\n",
            "td loss: [-0.50950068]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.38106024]\n",
            " [  2.01116415   0.54271882 -21.89406708]\n",
            " [ -0.2266632    1.79648229 -30.1364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.38106024]\n",
            " [-2.01116415 -0.54271882 21.89406708]\n",
            " [ 0.2266632  -1.79648229 30.1364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.95881995]]\n",
            "action: 2\n",
            "next_state: [-0.48922062  0.01257863], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.95881995]\n",
            "target: 60.64689396547425\n",
            "td loss: [-0.31192599]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.38723029]\n",
            " [  2.01116415   0.54271882 -21.90271825]\n",
            " [ -0.2266632    1.79648229 -30.1464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.38723029]\n",
            " [-2.01116415 -0.54271882 21.90271825]\n",
            " [ 0.2266632  -1.79648229 30.1464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 60.9798162 ]]\n",
            "action: 2\n",
            "next_state: [-0.47589937  0.01332125], reward: -1.0, term: False, trunc: True\n",
            "prediction: [60.9798162]\n",
            "target: 60.87442467362257\n",
            "td loss: [-0.10539152]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.39356191]\n",
            " [  2.01116415   0.54271882 -21.91130687]\n",
            " [ -0.2266632    1.79648229 -30.1564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.39356191]\n",
            " [-2.01116415 -0.54271882 21.91130687]\n",
            " [ 0.2266632  -1.79648229 30.1564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.00083997]]\n",
            "action: 2\n",
            "next_state: [-0.46193463  0.01396473], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.00083997]\n",
            "target: 61.10852357840094\n",
            "td loss: [0.10768361]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.40006231]\n",
            " [  2.01116415   0.54271882 -21.91982885]\n",
            " [ -0.2266632    1.79648229 -30.1664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.40006231]\n",
            " [-2.01116415 -0.54271882 21.91982885]\n",
            " [ 0.2266632  -1.79648229 30.1664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.02189134]]\n",
            "action: 2\n",
            "next_state: [-0.44742975  0.01450488], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.02189134]\n",
            "target: 61.34663026260294\n",
            "td loss: [0.32473892]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.40673712]\n",
            " [  2.01116415   0.54271882 -21.92828048]\n",
            " [ -0.2266632    1.79648229 -30.1764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.40673712]\n",
            " [-2.01116415 -0.54271882 21.92828048]\n",
            " [ 0.2266632  -1.79648229 30.1764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.04296988]]\n",
            "action: 2\n",
            "next_state: [-0.43249118  0.01493857], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.04296988]\n",
            "target: 61.586106630978165\n",
            "td loss: [0.54313675]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.41359027]\n",
            " [  2.01116415   0.54271882 -21.93665849]\n",
            " [ -0.2266632    1.79648229 -30.1864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.41359027]\n",
            " [-2.01116415 -0.54271882 21.93665849]\n",
            " [ 0.2266632  -1.79648229 30.1864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.06407468]]\n",
            "action: 2\n",
            "next_state: [-0.41722745  0.01526374], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.06407468]\n",
            "target: 61.824296712407126\n",
            "td loss: [0.76022203]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.42062391]\n",
            " [  2.01116415   0.54271882 -21.94496007]\n",
            " [ -0.2266632    1.79648229 -30.1964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.42062391]\n",
            " [-2.01116415 -0.54271882 21.94496007]\n",
            " [ 0.2266632  -1.79648229 30.1964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.08520435]]\n",
            "action: 2\n",
            "next_state: [-0.401748    0.01547943], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.08520435]\n",
            "target: 62.05858772525928\n",
            "td loss: [0.97338337]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.42783844]\n",
            " [  2.01116415   0.54271882 -21.95318298]\n",
            " [ -0.2266632    1.79648229 -30.2064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.42783844]\n",
            " [-2.01116415 -0.54271882 21.95318298]\n",
            " [ 0.2266632  -1.79648229 30.2064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.10635706]]\n",
            "action: 2\n",
            "next_state: [-0.38616225  0.01558576], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.10635706]\n",
            "target: 62.286487857361784\n",
            "td loss: [1.1801308]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.43523249]\n",
            " [  2.01116415   0.54271882 -21.96132551]\n",
            " [ -0.2266632    1.79648229 -30.2164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.43523249]\n",
            " [-2.01116415 -0.54271882 21.96132551]\n",
            " [ 0.2266632  -1.79648229 30.2164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.12753056]]\n",
            "action: 2\n",
            "next_state: [-0.3705783   0.01558395], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.12753056]\n",
            "target: 62.50570535018267\n",
            "td loss: [1.37817479]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.44280303]\n",
            " [  2.01116415   0.54271882 -21.96938656]\n",
            " [ -0.2266632    1.79648229 -30.2264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.44280303]\n",
            " [-2.01116415 -0.54271882 21.96938656]\n",
            " [ 0.2266632  -1.79648229 30.2264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.14872229]]\n",
            "action: 2\n",
            "next_state: [-0.35510212  0.01547618], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.14872229]\n",
            "target: 62.714205960533\n",
            "td loss: [1.56548367]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.4505454 ]\n",
            " [  2.01116415   0.54271882 -21.97736564]\n",
            " [ -0.2266632    1.79648229 -30.2364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.4505454 ]\n",
            " [-2.01116415 -0.54271882 21.97736564]\n",
            " [ 0.2266632  -1.79648229 30.2364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.16992938]]\n",
            "action: 2\n",
            "next_state: [-0.33983654  0.01526559], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.16992938]\n",
            "target: 62.91026705029169\n",
            "td loss: [1.74033767]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.45845352]\n",
            " [  2.01116415   0.54271882 -21.98526288]\n",
            " [ -0.2266632    1.79648229 -30.2464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.45845352]\n",
            " [-2.01116415 -0.54271882 21.98526288]\n",
            " [ 0.2266632  -1.79648229 30.2464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.1911488 ]]\n",
            "action: 2\n",
            "next_state: [-0.3248804   0.01495613], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.1911488]\n",
            "target: 63.09254200292101\n",
            "td loss: [1.90139321]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.46652003]\n",
            " [  2.01116415   0.54271882 -21.99307904]\n",
            " [ -0.2266632    1.79648229 -30.2564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.46652003]\n",
            " [-2.01116415 -0.54271882 21.99307904]\n",
            " [ 0.2266632  -1.79648229 30.2564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.21237741]]\n",
            "action: 2\n",
            "next_state: [-0.31032792  0.01455247], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.21237741]\n",
            "target: 63.26006507122432\n",
            "td loss: [2.04768767]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.47473649]\n",
            " [  2.01116415   0.54271882 -22.00081549]\n",
            " [ -0.2266632    1.79648229 -30.2664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.47473649]\n",
            " [-2.01116415 -0.54271882 22.00081549]\n",
            " [ 0.2266632  -1.79648229 30.2664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.23361207]]\n",
            "action: 2\n",
            "next_state: [-0.29626808  0.01405986], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.23361207]\n",
            "target: 63.41228473951003\n",
            "td loss: [2.17867267]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.48309359]\n",
            " [  2.01116415   0.54271882 -22.00847422]\n",
            " [ -0.2266632    1.79648229 -30.2764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.48309359]\n",
            " [-2.01116415 -0.54271882 22.00847422]\n",
            " [ 0.2266632  -1.79648229 30.2764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.25484973]]\n",
            "action: 2\n",
            "next_state: [-0.28278407  0.013484  ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.25484973]\n",
            "target: 63.54903960652747\n",
            "td loss: [2.29418988]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.49158136]\n",
            " [  2.01116415   0.54271882 -22.01605778]\n",
            " [ -0.2266632    1.79648229 -30.2864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.49158136]\n",
            " [-2.01116415 -0.54271882 22.01605778]\n",
            " [ 0.2266632  -1.79648229 30.2864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.27608751]]\n",
            "action: 2\n",
            "next_state: [-0.2699531   0.01283095], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.27608751]\n",
            "target: 63.670549216609885\n",
            "td loss: [2.3944617]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.50018937]\n",
            " [  2.01116415   0.54271882 -22.02356929]\n",
            " [ -0.2266632    1.79648229 -30.2964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.50018937]\n",
            " [-2.01116415 -0.54271882 22.02356929]\n",
            " [ 0.2266632  -1.79648229 30.2964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.29732282]]\n",
            "action: 2\n",
            "next_state: [-0.25784618  0.01210695], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.29732282]\n",
            "target: 63.777364478160834\n",
            "td loss: [2.48004166]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.50890696]\n",
            " [  2.01116415   0.54271882 -22.03101235]\n",
            " [ -0.2266632    1.79648229 -30.3064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.50890696]\n",
            " [-2.01116415 -0.54271882 22.03101235]\n",
            " [ 0.2266632  -1.79648229 30.3064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.31855335]]\n",
            "action: 2\n",
            "next_state: [-0.24652782  0.01131835], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.31855335]\n",
            "target: 63.87033598413467\n",
            "td loss: [2.55178264]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.51772336]\n",
            " [  2.01116415   0.54271882 -22.03839107]\n",
            " [ -0.2266632    1.79648229 -30.3164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.51772336]\n",
            " [-2.01116415 -0.54271882 22.03839107]\n",
            " [ 0.2266632  -1.79648229 30.3164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.33977721]]\n",
            "action: 2\n",
            "next_state: [-0.23605634  0.01047147], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.33977721]\n",
            "target: 63.95054972407503\n",
            "td loss: [2.61077251]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.52662789]\n",
            " [  2.01116415   0.54271882 -22.04570996]\n",
            " [ -0.2266632    1.79648229 -30.3264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.52662789]\n",
            " [-2.01116415 -0.54271882 22.04570996]\n",
            " [ 0.2266632  -1.79648229 30.3264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.36099294]]\n",
            "action: 2\n",
            "next_state: [-0.22648376  0.00957259], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.36099294]\n",
            "target: 64.0192409195397\n",
            "td loss: [2.65824798]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.53561008]\n",
            " [  2.01116415   0.54271882 -22.05297393]\n",
            " [ -0.2266632    1.79648229 -30.3364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.53561008]\n",
            " [-2.01116415 -0.54271882 22.05297393]\n",
            " [ 0.2266632  -1.79648229 30.3364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.38219952]]\n",
            "action: 2\n",
            "next_state: [-0.21785596  0.00862779], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.38219952]\n",
            "target: 64.07777480584743\n",
            "td loss: [2.69557528]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.54465973]\n",
            " [  2.01116415   0.54271882 -22.06018825]\n",
            " [ -0.2266632    1.79648229 -30.3464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.54465973]\n",
            " [-2.01116415 -0.54271882 22.06018825]\n",
            " [ 0.2266632  -1.79648229 30.3464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.4033964 ]]\n",
            "action: 2\n",
            "next_state: [-0.21021298  0.00764299], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.4033964]\n",
            "target: 64.12753876176508\n",
            "td loss: [2.72414237]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.553767  ]\n",
            " [  2.01116415   0.54271882 -22.06735849]\n",
            " [ -0.2266632    1.79648229 -30.3564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.553767  ]\n",
            " [-2.01116415 -0.54271882 22.06735849]\n",
            " [ 0.2266632  -1.79648229 30.3564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.42458346]]\n",
            "action: 2\n",
            "next_state: [-0.20358911  0.00662387], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.42458346]\n",
            "target: 64.16990442742821\n",
            "td loss: [2.74532096]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.56292242]\n",
            " [  2.01116415   0.54271882 -22.07449045]\n",
            " [ -0.2266632    1.79648229 -30.3664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.56292242]\n",
            " [-2.01116415 -0.54271882 22.07449045]\n",
            " [ 0.2266632  -1.79648229 30.3664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.44576106]]\n",
            "action: 2\n",
            "next_state: [-0.19801326  0.00557585], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.44576106]\n",
            "target: 64.20616062886188\n",
            "td loss: [2.76039956]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.57211694]\n",
            " [  2.01116415   0.54271882 -22.08159019]\n",
            " [ -0.2266632    1.79648229 -30.3764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.57211694]\n",
            " [-2.01116415 -0.54271882 22.08159019]\n",
            " [ 0.2266632  -1.79648229 30.3764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.46692993]]\n",
            "action: 2\n",
            "next_state: [-0.19350913  0.00450413], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.46692993]\n",
            "target: 64.23746861713408\n",
            "td loss: [2.77053869]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.58134184]\n",
            " [  2.01116415   0.54271882 -22.08866393]\n",
            " [ -0.2266632    1.79648229 -30.3864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.58134184]\n",
            " [-2.01116415 -0.54271882 22.08866393]\n",
            " [ 0.2266632  -1.79648229 30.3864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.48809115]]\n",
            "action: 2\n",
            "next_state: [-0.19009542  0.0034137 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.48809115]\n",
            "target: 64.26482046998554\n",
            "td loss: [2.77672932]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.59058875]\n",
            " [  2.01116415   0.54271882 -22.09571803]\n",
            " [ -0.2266632    1.79648229 -30.3964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.59058875]\n",
            " [-2.01116415 -0.54271882 22.09571803]\n",
            " [ 0.2266632  -1.79648229 30.3964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.5092461 ]]\n",
            "action: 2\n",
            "next_state: [-0.1877861   0.00230933], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.5092461]\n",
            "target: 64.28900003344897\n",
            "td loss: [2.77975393]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.59984954]\n",
            " [  2.01116415   0.54271882 -22.10275897]\n",
            " [ -0.2266632    1.79648229 -30.4064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.59984954]\n",
            " [-2.01116415 -0.54271882 22.10275897]\n",
            " [ 0.2266632  -1.79648229 30.4064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.5303964 ]]\n",
            "action: 2\n",
            "next_state: [-0.18659043  0.00119566], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.5303964]\n",
            "target: 64.31055508312252\n",
            "td loss: [2.78015868]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.6091163 ]\n",
            " [  2.01116415   0.54271882 -22.10979328]\n",
            " [ -0.2266632    1.79648229 -30.4164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.6091163 ]\n",
            " [-2.01116415 -0.54271882 22.10979328]\n",
            " [ 0.2266632  -1.79648229 30.4164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.55154383]]\n",
            "action: 2\n",
            "next_state: [-1.8651322e-01  7.7222910e-05], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.55154383]\n",
            "target: 64.32978515680016\n",
            "td loss: [2.77824132]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.61838121]\n",
            " [  2.01116415   0.54271882 -22.11682754]\n",
            " [ -0.2266632    1.79648229 -30.4264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.61838121]\n",
            " [-2.01116415 -0.54271882 22.11682754]\n",
            " [ 0.2266632  -1.79648229 30.4264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.57269026]]\n",
            "action: 2\n",
            "next_state: [-0.18755475 -0.00104153], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.57269026]\n",
            "target: 64.34673362373819\n",
            "td loss: [2.77404336]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.62763646]\n",
            " [  2.01116415   0.54271882 -22.12386834]\n",
            " [ -0.2266632    1.79648229 -30.4364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.62763646]\n",
            " [-2.01116415 -0.54271882 22.12386834]\n",
            " [ 0.2266632  -1.79648229 30.4364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.59383756]]\n",
            "action: 2\n",
            "next_state: [-0.18971086 -0.00215612], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.59383756]\n",
            "target: 64.36117678932857\n",
            "td loss: [2.76733923]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.63687421]\n",
            " [  2.01116415   0.54271882 -22.13092221]\n",
            " [ -0.2266632    1.79648229 -30.4464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.63687421]\n",
            " [-2.01116415 -0.54271882 22.13092221]\n",
            " [ 0.2266632  -1.79648229 30.4464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.61498755]]\n",
            "action: 2\n",
            "next_state: [-0.1929729  -0.00326204], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.61498755]\n",
            "target: 64.37263357816956\n",
            "td loss: [2.75764602]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.64608644]\n",
            " [  2.01116415   0.54271882 -22.13799565]\n",
            " [ -0.2266632    1.79648229 -30.4564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.64608644]\n",
            " [-2.01116415 -0.54271882 22.13799565]\n",
            " [ 0.2266632  -1.79648229 30.4564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.63614191]]\n",
            "action: 2\n",
            "next_state: [-0.19732757 -0.00435468], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.63614191]\n",
            "target: 64.38039978054756\n",
            "td loss: [2.74425787]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.65526491]\n",
            " [  2.01116415   0.54271882 -22.14509501]\n",
            " [ -0.2266632    1.79648229 -30.4664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.65526491]\n",
            " [-2.01116415 -0.54271882 22.14509501]\n",
            " [ 0.2266632  -1.79648229 30.4664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.65730212]]\n",
            "action: 2\n",
            "next_state: [-0.20275684 -0.00542927], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.65730212]\n",
            "target: 64.38354441627835\n",
            "td loss: [2.7262423]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.66440111]\n",
            " [  2.01116415   0.54271882 -22.15222656]\n",
            " [ -0.2266632    1.79648229 -30.4764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.66440111]\n",
            " [-2.01116415 -0.54271882 22.15222656]\n",
            " [ 0.2266632  -1.79648229 30.4764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.67846935]]\n",
            "action: 2\n",
            "next_state: [-0.20923771 -0.00648086], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.67846935]\n",
            "target: 64.38096627589746\n",
            "td loss: [2.70249692]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.6734862 ]\n",
            " [  2.01116415   0.54271882 -22.15939634]\n",
            " [ -0.2266632    1.79648229 -30.4864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.6734862 ]\n",
            " [-2.01116415 -0.54271882 22.15939634]\n",
            " [ 0.2266632  -1.79648229 30.4864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.6996445 ]]\n",
            "action: 2\n",
            "next_state: [-0.216742   -0.00750429], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.6996445]\n",
            "target: 64.37141717994655\n",
            "td loss: [2.67177268]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.68251097]\n",
            " [  2.01116415   0.54271882 -22.1666102 ]\n",
            " [ -0.2266632    1.79648229 -30.4964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.68251097]\n",
            " [-2.01116415 -0.54271882 22.1666102 ]\n",
            " [ 0.2266632  -1.79648229 30.4964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.72082804]]\n",
            "action: 2\n",
            "next_state: [-0.22523616 -0.00849416], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.72082804]\n",
            "target: 64.35356347054989\n",
            "td loss: [2.63273543]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.69146588]\n",
            " [  2.01116415   0.54271882 -22.17387373]\n",
            " [ -0.2266632    1.79648229 -30.5064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.69146588]\n",
            " [-2.01116415 -0.54271882 22.17387373]\n",
            " [ 0.2266632  -1.79648229 30.5064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.74202006]]\n",
            "action: 2\n",
            "next_state: [-0.23468098 -0.00944482], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.74202006]\n",
            "target: 64.32603468011355\n",
            "td loss: [2.58401462]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.70034105]\n",
            " [  2.01116415   0.54271882 -22.18119221]\n",
            " [ -0.2266632    1.79648229 -30.5164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.70034105]\n",
            " [-2.01116415 -0.54271882 22.18119221]\n",
            " [ 0.2266632  -1.79648229 30.5164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.76322018]]\n",
            "action: 2\n",
            "next_state: [-0.24503137 -0.0103504 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.76322018]\n",
            "target: 64.28748474772115\n",
            "td loss: [2.52426457]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.70912635]\n",
            " [  2.01116415   0.54271882 -22.18857059]\n",
            " [ -0.2266632    1.79648229 -30.5264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.70912635]\n",
            " [-2.01116415 -0.54271882 22.18857059]\n",
            " [ 0.2266632  -1.79648229 30.5264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.7844276 ]]\n",
            "action: 2\n",
            "next_state: [-0.2562362  -0.01120482], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.7844276]\n",
            "target: 64.2366641994056\n",
            "td loss: [2.4522366]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.71781146]\n",
            " [  2.01116415   0.54271882 -22.19601342]\n",
            " [ -0.2266632    1.79648229 -30.5364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.71781146]\n",
            " [-2.01116415 -0.54271882 22.19601342]\n",
            " [ 0.2266632  -1.79648229 30.5364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.80564106]]\n",
            "action: 2\n",
            "next_state: [-0.26823804 -0.01200184], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.80564106]\n",
            "target: 64.17246016357535\n",
            "td loss: [2.3668191]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.726386  ]\n",
            " [  2.01116415   0.54271882 -22.20352482]\n",
            " [ -0.2266632    1.79648229 -30.5464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.726386  ]\n",
            " [-2.01116415 -0.54271882 22.20352482]\n",
            " [ 0.2266632  -1.79648229 30.5464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.82685889]]\n",
            "action: 2\n",
            "next_state: [-0.28097317 -0.01273513], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.82685889]\n",
            "target: 64.09399826596417\n",
            "td loss: [2.26713938]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.73483967]\n",
            " [  2.01116415   0.54271882 -22.21110844]\n",
            " [ -0.2266632    1.79648229 -30.5564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.73483967]\n",
            " [-2.01116415 -0.54271882 22.21110844]\n",
            " [ 0.2266632  -1.79648229 30.5564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.84807903]]\n",
            "action: 2\n",
            "next_state: [-0.29437152 -0.01339835], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.84807903]\n",
            "target: 64.00066379484608\n",
            "td loss: [2.15258477]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.74316242]\n",
            " [  2.01116415   0.54271882 -22.21876742]\n",
            " [ -0.2266632    1.79648229 -30.5664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.74316242]\n",
            " [-2.01116415 -0.54271882 22.21876742]\n",
            " [ 0.2266632  -1.79648229 30.5664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.86929908]]\n",
            "action: 2\n",
            "next_state: [-0.30835673 -0.01398522], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.86929908]\n",
            "target: 63.892178600354384\n",
            "td loss: [2.02287952]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.75134465]\n",
            " [  2.01116415   0.54271882 -22.22650434]\n",
            " [ -0.2266632    1.79648229 -30.5764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.75134465]\n",
            " [-2.01116415 -0.54271882 22.22650434]\n",
            " [ 0.2266632  -1.79648229 30.5764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.89051638]]\n",
            "action: 2\n",
            "next_state: [-0.32284638 -0.01448966], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.89051638]\n",
            "target: 63.76862736699425\n",
            "td loss: [1.87811099]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.75937739]\n",
            " [  2.01116415   0.54271882 -22.23432119]\n",
            " [ -0.2266632    1.79648229 -30.5864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.75937739]\n",
            " [-2.01116415 -0.54271882 22.23432119]\n",
            " [ 0.2266632  -1.79648229 30.5864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.91172809]]\n",
            "action: 2\n",
            "next_state: [-0.3377523  -0.01490592], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.91172809]\n",
            "target: 63.63047929916971\n",
            "td loss: [1.71875121]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.76725252]\n",
            " [  2.01116415   0.54271882 -22.24221939]\n",
            " [ -0.2266632    1.79648229 -30.5964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.76725252]\n",
            " [-2.01116415 -0.54271882 22.24221939]\n",
            " [ 0.2266632  -1.79648229 30.5964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.93293124]]\n",
            "action: 2\n",
            "next_state: [-0.352981   -0.01522867], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.93293124]\n",
            "target: 63.47861121971823\n",
            "td loss: [1.54567998]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.77496296]\n",
            " [  2.01116415   0.54271882 -22.25019969]\n",
            " [ -0.2266632    1.79648229 -30.6064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.77496296]\n",
            " [-2.01116415 -0.54271882 22.25019969]\n",
            " [ 0.2266632  -1.79648229 30.6064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.95412286]]\n",
            "action: 2\n",
            "next_state: [-0.36843416 -0.01545316], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.95412286]\n",
            "target: 63.31429305653724\n",
            "td loss: [1.36017019]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.78250288]\n",
            " [  2.01116415   0.54271882 -22.25826225]\n",
            " [ -0.2266632    1.79648229 -30.6164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.78250288]\n",
            " [-2.01116415 -0.54271882 22.25826225]\n",
            " [ 0.2266632  -1.79648229 30.6164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.97530005]]\n",
            "action: 2\n",
            "next_state: [-0.38400948 -0.01557532], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.97530005]\n",
            "target: 63.13915402690648\n",
            "td loss: [1.16385398]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.78986786]\n",
            " [  2.01116415   0.54271882 -22.26640657]\n",
            " [ -0.2266632    1.79648229 -30.6264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.78986786]\n",
            " [-2.01116415 -0.54271882 22.26640657]\n",
            " [ 0.2266632  -1.79648229 30.6264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 61.99646007]]\n",
            "action: 2\n",
            "next_state: [-0.39960137 -0.01559191], reward: -1.0, term: False, trunc: True\n",
            "prediction: [61.99646007]\n",
            "target: 62.955150075854036\n",
            "td loss: [0.95869001]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.797055  ]\n",
            " [  2.01116415   0.54271882 -22.27463153]\n",
            " [ -0.2266632    1.79648229 -30.6364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.797055  ]\n",
            " [-2.01116415 -0.54271882 22.27463153]\n",
            " [ 0.2266632  -1.79648229 30.6364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.01760041]]\n",
            "action: 2\n",
            "next_state: [-0.41510198 -0.01550059], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.01760041]\n",
            "target: 62.76451203896966\n",
            "td loss: [0.74691163]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.80406307]\n",
            " [  2.01116415   0.54271882 -22.28293543]\n",
            " [ -0.2266632    1.79648229 -30.6464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.80406307]\n",
            " [-2.01116415 -0.54271882 22.28293543]\n",
            " [ 0.2266632  -1.79648229 30.6464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.03871889]]\n",
            "action: 2\n",
            "next_state: [-0.43040198 -0.01530002], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.03871889]\n",
            "target: 62.5696710840673\n",
            "td loss: [0.5309522]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.81089255]\n",
            " [  2.01116415   0.54271882 -22.29131598]\n",
            " [ -0.2266632    1.79648229 -30.6564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.81089255]\n",
            " [-2.01116415 -0.54271882 22.29131598]\n",
            " [ 0.2266632  -1.79648229 30.6564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.0598137 ]]\n",
            "action: 2\n",
            "next_state: [-0.4453919  -0.01498993], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.0598137]\n",
            "target: 62.37320281878088\n",
            "td loss: [0.31338912]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.81754564]\n",
            " [  2.01116415   0.54271882 -22.29977036]\n",
            " [ -0.2266632    1.79648229 -30.6664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.81754564]\n",
            " [-2.01116415 -0.54271882 22.29977036]\n",
            " [ 0.2266632  -1.79648229 30.6664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.08088344]]\n",
            "action: 2\n",
            "next_state: [-0.45996302 -0.01457111], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.08088344]\n",
            "target: 62.17774207837943\n",
            "td loss: [0.09685864]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.82402628]\n",
            " [  2.01116415   0.54271882 -22.30829525]\n",
            " [ -0.2266632    1.79648229 -30.6764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.82402628]\n",
            " [-2.01116415 -0.54271882 22.30829525]\n",
            " [ 0.2266632  -1.79648229 30.6764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.10192717]]\n",
            "action: 2\n",
            "next_state: [-0.4740085  -0.01404548], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.10192717]\n",
            "target: 61.98591864080301\n",
            "td loss: [-0.11600853]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.83034006]\n",
            " [  2.01116415   0.54271882 -22.3168869 ]\n",
            " [ -0.2266632    1.79648229 -30.6864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.83034006]\n",
            " [-2.01116415 -0.54271882 22.3168869 ]\n",
            " [ 0.2266632  -1.79648229 30.6864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.12294441]]\n",
            "action: 2\n",
            "next_state: [-0.48742455 -0.01341604], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.12294441]\n",
            "target: 61.80030168108169\n",
            "td loss: [-0.32264273]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.83649415]\n",
            " [  2.01116415   0.54271882 -22.32554116]\n",
            " [ -0.2266632    1.79648229 -30.6964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.83649415]\n",
            " [-2.01116415 -0.54271882 22.32554116]\n",
            " [ 0.2266632  -1.79648229 30.6964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.14393515]]\n",
            "action: 2\n",
            "next_state: [-0.50011134 -0.01268682], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.14393515]\n",
            "target: 61.623341177811966\n",
            "td loss: [-0.52059398]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.8424972 ]\n",
            " [  2.01116415   0.54271882 -22.33425357]\n",
            " [ -0.2266632    1.79648229 -30.7064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.8424972 ]\n",
            " [-2.01116415 -0.54271882 22.33425357]\n",
            " [ 0.2266632  -1.79648229 30.7064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.16489986]]\n",
            "action: 2\n",
            "next_state: [-0.51197416 -0.01186283], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.16489986]\n",
            "target: 61.45731595677456\n",
            "td loss: [-0.7075839]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.84835917]\n",
            " [  2.01116415   0.54271882 -22.34301937]\n",
            " [ -0.2266632    1.79648229 -30.7164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.84835917]\n",
            " [-2.01116415 -0.54271882 22.34301937]\n",
            " [ 0.2266632  -1.79648229 30.7164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.18583942]]\n",
            "action: 2\n",
            "next_state: [-0.5229242  -0.01094999], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.18583942]\n",
            "target: 61.30431656740024\n",
            "td loss: [-0.88152285]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.85409123]\n",
            " [  2.01116415   0.54271882 -22.35183359]\n",
            " [ -0.2266632    1.79648229 -30.7264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.85409123]\n",
            " [-2.01116415 -0.54271882 22.35183359]\n",
            " [ 0.2266632  -1.79648229 30.7264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.20675514]]\n",
            "action: 2\n",
            "next_state: [-0.53287923 -0.00995505], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.20675514]\n",
            "target: 61.16621345483625\n",
            "td loss: [-1.04054169]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.85970558]\n",
            " [  2.01116415   0.54271882 -22.36069106]\n",
            " [ -0.2266632    1.79648229 -30.7364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.85970558]\n",
            " [-2.01116415 -0.54271882 22.36069106]\n",
            " [ 0.2266632  -1.79648229 30.7364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.22764873]]\n",
            "action: 2\n",
            "next_state: [-0.5417647  -0.00888546], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.22764873]\n",
            "target: 61.04466449540041\n",
            "td loss: [-1.18298423]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.86521533]\n",
            " [  2.01116415   0.54271882 -22.36958649]\n",
            " [ -0.2266632    1.79648229 -30.7464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.86521533]\n",
            " [-2.01116415 -0.54271882 22.36958649]\n",
            " [ 0.2266632  -1.79648229 30.7464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.24852221]]\n",
            "action: 2\n",
            "next_state: [-0.549514   -0.00774928], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.24852221]\n",
            "target: 60.941080400582095\n",
            "td loss: [-1.30744181]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.8706343 ]\n",
            " [  2.01116415   0.54271882 -22.37851452]\n",
            " [ -0.2266632    1.79648229 -30.7564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.8706343 ]\n",
            " [-2.01116415 -0.54271882 22.37851452]\n",
            " [ 0.2266632  -1.79648229 30.7564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.26937791]]\n",
            "action: 2\n",
            "next_state: [-0.5560691  -0.00655511], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.26937791]\n",
            "target: 60.85666198285415\n",
            "td loss: [-1.41271593]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.87597696]\n",
            " [  2.01116415   0.54271882 -22.38746967]\n",
            " [ -0.2266632    1.79648229 -30.7664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.87597696]\n",
            " [-2.01116415 -0.54271882 22.38746967]\n",
            " [ 0.2266632  -1.79648229 30.7664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.29021845]]\n",
            "action: 2\n",
            "next_state: [-0.56138104 -0.00531197], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.29021845]\n",
            "target: 60.7923878413272\n",
            "td loss: [-1.4978306]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.88125825]\n",
            " [  2.01116415   0.54271882 -22.39644647]\n",
            " [ -0.2266632    1.79648229 -30.7764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.88125825]\n",
            " [-2.01116415 -0.54271882 22.39644647]\n",
            " [ 0.2266632  -1.79648229 30.7764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.31104661]]\n",
            "action: 2\n",
            "next_state: [-0.56541026 -0.00402921], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.31104661]\n",
            "target: 60.7490360813917\n",
            "td loss: [-1.56201053]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.88649349]\n",
            " [  2.01116415   0.54271882 -22.4054394 ]\n",
            " [ -0.2266632    1.79648229 -30.7864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.88649349]\n",
            " [-2.01116415 -0.54271882 22.4054394 ]\n",
            " [ 0.2266632  -1.79648229 30.7864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.3318654 ]]\n",
            "action: 2\n",
            "next_state: [-0.5681267  -0.00271644], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.3318654]\n",
            "target: 60.72717982009433\n",
            "td loss: [-1.60468558]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.89169827]\n",
            " [  2.01116415   0.54271882 -22.41444294]\n",
            " [ -0.2266632    1.79648229 -30.7964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.89169827]\n",
            " [-2.01116415 -0.54271882 22.41444294]\n",
            " [ 0.2266632  -1.79648229 30.7964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.35267794]]\n",
            "action: 2\n",
            "next_state: [-0.56951016 -0.00138348], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.35267794]\n",
            "target: 60.72722092163092\n",
            "td loss: [-1.62545701]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.89688837]\n",
            " [  2.01116415   0.54271882 -22.42345155]\n",
            " [ -0.2266632    1.79648229 -30.8064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.89688837]\n",
            " [-2.01116415 -0.54271882 22.42345155]\n",
            " [ 0.2266632  -1.79648229 30.8064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.37348742]]\n",
            "action: 2\n",
            "next_state: [-5.6955040e-01 -4.0229912e-05], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.37348742]\n",
            "target: 60.74936222196941\n",
            "td loss: [-1.62412519]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.90207963]\n",
            " [  2.01116415   0.54271882 -22.43245972]\n",
            " [ -0.2266632    1.79648229 -30.8164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.90207963]\n",
            " [-2.01116415 -0.54271882 22.43245972]\n",
            " [ 0.2266632  -1.79648229 30.8164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.3942971 ]]\n",
            "action: 2\n",
            "next_state: [-0.5682471   0.00130332], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.3942971]\n",
            "target: 60.793648051009264\n",
            "td loss: [-1.60064905]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.90728792]\n",
            " [  2.01116415   0.54271882 -22.44146192]\n",
            " [ -0.2266632    1.79648229 -30.8264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.90728792]\n",
            " [-2.01116415 -0.54271882 22.44146192]\n",
            " [ 0.2266632  -1.79648229 30.8264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.41511025]]\n",
            "action: 2\n",
            "next_state: [-0.56560993  0.00263718], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.41511025]\n",
            "target: 60.859930251670605\n",
            "td loss: [-1.55518]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.91252902]\n",
            " [  2.01116415   0.54271882 -22.45045265]\n",
            " [ -0.2266632    1.79648229 -30.8364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.91252902]\n",
            " [-2.01116415 -0.54271882 22.45045265]\n",
            " [ 0.2266632  -1.79648229 30.8364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.4359301 ]]\n",
            "action: 2\n",
            "next_state: [-0.5616585   0.00395143], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.4359301]\n",
            "target: 60.94788783173291\n",
            "td loss: [-1.48804227]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.91781856]\n",
            " [  2.01116415   0.54271882 -22.45942641]\n",
            " [ -0.2266632    1.79648229 -30.8464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.91781856]\n",
            " [-2.01116415 -0.54271882 22.45942641]\n",
            " [ 0.2266632  -1.79648229 30.8464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.45675981]]\n",
            "action: 2\n",
            "next_state: [-0.55642223  0.00523626], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.45675981]\n",
            "target: 61.056998701602836\n",
            "td loss: [-1.39976111]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.92317187]\n",
            " [  2.01116415   0.54271882 -22.46837771]\n",
            " [ -0.2266632    1.79648229 -30.8564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.92317187]\n",
            " [-2.01116415 -0.54271882 22.46837771]\n",
            " [ 0.2266632  -1.79648229 30.8564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.4776024 ]]\n",
            "action: 2\n",
            "next_state: [-0.54994017  0.00648203], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.4776024]\n",
            "target: 61.18654760837083\n",
            "td loss: [-1.29105479]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.92860394]\n",
            " [  2.01116415   0.54271882 -22.47730112]\n",
            " [ -0.2266632    1.79648229 -30.8664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.92860394]\n",
            " [-2.01116415 -0.54271882 22.47730112]\n",
            " [ 0.2266632  -1.79648229 30.8664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.49846075]]\n",
            "action: 2\n",
            "next_state: [-0.5422608   0.00767939], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.49846075]\n",
            "target: 61.33560459482437\n",
            "td loss: [-1.16285615]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.93412925]\n",
            " [  2.01116415   0.54271882 -22.48619124]\n",
            " [ -0.2266632    1.79648229 -30.8764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.93412925]\n",
            " [-2.01116415 -0.54271882 22.48619124]\n",
            " [ 0.2266632  -1.79648229 30.8764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.51933752]]\n",
            "action: 2\n",
            "next_state: [-0.53344154  0.00881928], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.51933752]\n",
            "target: 61.50300802799798\n",
            "td loss: [-1.01632949]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.93976169]\n",
            " [  2.01116415   0.54271882 -22.49504274]\n",
            " [ -0.2266632    1.79648229 -30.8864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.93976169]\n",
            " [-2.01116415 -0.54271882 22.49504274]\n",
            " [ 0.2266632  -1.79648229 30.8864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.54023512]]\n",
            "action: 2\n",
            "next_state: [-0.5235484   0.00989309], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.54023512]\n",
            "target: 61.687367751883365\n",
            "td loss: [-0.85286737]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.94551438]\n",
            " [  2.01116415   0.54271882 -22.50385041]\n",
            " [ -0.2266632    1.79648229 -30.8964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.94551438]\n",
            " [-2.01116415 -0.54271882 22.50385041]\n",
            " [ 0.2266632  -1.79648229 30.8964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.56115566]]\n",
            "action: 2\n",
            "next_state: [-0.51265574  0.01089271], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.56115566]\n",
            "target: 61.88704822843857\n",
            "td loss: [-0.67410743]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.95139954]\n",
            " [  2.01116415   0.54271882 -22.51260916]\n",
            " [ -0.2266632    1.79648229 -30.9064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.95139954]\n",
            " [-2.01116415 -0.54271882 22.51260916]\n",
            " [ 0.2266632  -1.79648229 30.9064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.5821009 ]]\n",
            "action: 2\n",
            "next_state: [-0.5008451   0.01181066], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.5821009]\n",
            "target: 62.100169913553955\n",
            "td loss: [-0.48193099]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.95742833]\n",
            " [  2.01116415   0.54271882 -22.52131409]\n",
            " [ -0.2266632    1.79648229 -30.9164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.95742833]\n",
            " [-2.01116415 -0.54271882 22.52131409]\n",
            " [ 0.2266632  -1.79648229 30.9164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.60307224]]\n",
            "action: 2\n",
            "next_state: [-0.48820493  0.01264014], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.60307224]\n",
            "target: 62.32462999847167\n",
            "td loss: [-0.27844224]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.96361071]\n",
            " [  2.01116415   0.54271882 -22.52996053]\n",
            " [ -0.2266632    1.79648229 -30.9264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.96361071]\n",
            " [-2.01116415 -0.54271882 22.52996053]\n",
            " [ 0.2266632  -1.79648229 30.9264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.62407062]]\n",
            "action: 2\n",
            "next_state: [-0.47482973  0.01337518], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.62407062]\n",
            "target: 62.558111311035084\n",
            "td loss: [-0.06595931]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.96995528]\n",
            " [  2.01116415   0.54271882 -22.53854409]\n",
            " [ -0.2266632    1.79648229 -30.9364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.96995528]\n",
            " [-2.01116415 -0.54271882 22.53854409]\n",
            " [ 0.2266632  -1.79648229 30.9364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.64509656]]\n",
            "action: 2\n",
            "next_state: [-0.46081904  0.01401072], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.64509656]\n",
            "target: 62.79811407503572\n",
            "td loss: [0.15301751]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.97646913]\n",
            " [  2.01116415   0.54271882 -22.5470607 ]\n",
            " [ -0.2266632    1.79648229 -30.9464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.97646913]\n",
            " [-2.01116415 -0.54271882 22.5470607 ]\n",
            " [ 0.2266632  -1.79648229 30.9464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.66615008]]\n",
            "action: 2\n",
            "next_state: [-0.44627637  0.01454265], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.66615008]\n",
            "target: 63.04200762054799\n",
            "td loss: [0.37585754]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.98315777]\n",
            " [  2.01116415   0.54271882 -22.55550669]\n",
            " [ -0.2266632    1.79648229 -30.9564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.98315777]\n",
            " [-2.01116415 -0.54271882 22.55550669]\n",
            " [ 0.2266632  -1.79648229 30.9564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.68723071]]\n",
            "action: 2\n",
            "next_state: [-0.43130845  0.01496792], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.68723071]\n",
            "target: 63.28707631978749\n",
            "td loss: [0.59984561]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.99002496]\n",
            " [  2.01116415   0.54271882 -22.56387881]\n",
            " [ -0.2266632    1.79648229 -30.9664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.99002496]\n",
            " [-2.01116415 -0.54271882 22.56387881]\n",
            " [ 0.2266632  -1.79648229 30.9664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.70833751]]\n",
            "action: 2\n",
            "next_state: [-0.4160239   0.01528455], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.70833751]\n",
            "target: 63.53059814263145\n",
            "td loss: [0.82226063]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -21.99707275]\n",
            " [  2.01116415   0.54271882 -22.57217432]\n",
            " [ -0.2266632    1.79648229 -30.9764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  21.99707275]\n",
            " [-2.01116415 -0.54271882 22.57217432]\n",
            " [ 0.2266632  -1.79648229 30.9764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.72946905]]\n",
            "action: 2\n",
            "next_state: [-0.40053225  0.01549167], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.72946905]\n",
            "target: 63.76989688253218\n",
            "td loss: [1.04042783]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.00430138]\n",
            " [  2.01116415   0.54271882 -22.580391  ]\n",
            " [ -0.2266632    1.79648229 -30.9864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.00430138]\n",
            " [-2.01116415 -0.54271882 22.580391  ]\n",
            " [ 0.2266632  -1.79648229 30.9864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.75062347]]\n",
            "action: 2\n",
            "next_state: [-0.38494274  0.0155895 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.75062347]\n",
            "target: 64.00243364214863\n",
            "td loss: [1.25181017]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.01170936]\n",
            " [  2.01116415   0.54271882 -22.5885272 ]\n",
            " [ -0.2266632    1.79648229 -30.9964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.01170936]\n",
            " [-2.01116415 -0.54271882 22.5885272 ]\n",
            " [ 0.2266632  -1.79648229 30.9964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.77179849]]\n",
            "action: 2\n",
            "next_state: [-0.36936346  0.01557931], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.77179849]\n",
            "target: 64.22586733828405\n",
            "td loss: [1.45406884]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.01929351]\n",
            " [  2.01116415   0.54271882 -22.59658185]\n",
            " [ -0.2266632    1.79648229 -31.0064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.01929351]\n",
            " [-2.01116415 -0.54271882 22.59658185]\n",
            " [ 0.2266632  -1.79648229 31.0064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.79299152]]\n",
            "action: 2\n",
            "next_state: [-0.35390007  0.01546338], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.79299152]\n",
            "target: 64.43813847526125\n",
            "td loss: [1.64514695]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.02704907]\n",
            " [  2.01116415   0.54271882 -22.60455452]\n",
            " [ -0.2266632    1.79648229 -31.0164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.02704907]\n",
            " [-2.01116415 -0.54271882 22.60455452]\n",
            " [ 0.2266632  -1.79648229 31.0164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.81419969]]\n",
            "action: 2\n",
            "next_state: [-0.33865514  0.01524491], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.81419969]\n",
            "target: 64.6375126927533\n",
            "td loss: [1.823313]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.03496986]\n",
            " [  2.01116415   0.54271882 -22.61244538]\n",
            " [ -0.2266632    1.79648229 -31.0264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.03496986]\n",
            " [-2.01116415 -0.54271882 22.61244538]\n",
            " [ 0.2266632  -1.79648229 31.0264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.83541994]]\n",
            "action: 2\n",
            "next_state: [-0.32372725  0.01492791], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.83541994]\n",
            "target: 64.82263276252674\n",
            "td loss: [1.98721282]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.0430484 ]\n",
            " [  2.01116415   0.54271882 -22.62025525]\n",
            " [ -0.2266632    1.79648229 -31.0364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.0430484 ]\n",
            " [-2.01116415 -0.54271882 22.62025525]\n",
            " [ 0.2266632  -1.79648229 31.0364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.85664913]]\n",
            "action: 2\n",
            "next_state: [-0.30921015  0.0145171 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.85664913]\n",
            "target: 64.99255368335811\n",
            "td loss: [2.13590455]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.0512762 ]\n",
            " [  2.01116415   0.54271882 -22.62798555]\n",
            " [ -0.2266632    1.79648229 -31.0464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.0512762 ]\n",
            " [-2.01116415 -0.54271882 22.62798555]\n",
            " [ 0.2266632  -1.79648229 31.0464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.87788414]]\n",
            "action: 2\n",
            "next_state: [-0.2951924   0.01401777], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.87788414]\n",
            "target: 65.14672666819902\n",
            "td loss: [2.26884253]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.05964388]\n",
            " [  2.01116415   0.54271882 -22.63563831]\n",
            " [ -0.2266632    1.79648229 -31.0564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.05964388]\n",
            " [-2.01116415 -0.54271882 22.63563831]\n",
            " [ 0.2266632  -1.79648229 31.0564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.89912191]]\n",
            "action: 2\n",
            "next_state: [-0.2817567   0.01343566], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.89912191]\n",
            "target: 65.2850340534049\n",
            "td loss: [2.38591215]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.06814143]\n",
            " [  2.01116415   0.54271882 -22.64321612]\n",
            " [ -0.2266632    1.79648229 -31.0664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.06814143]\n",
            " [-2.01116415 -0.54271882 22.64321612]\n",
            " [ 0.2266632  -1.79648229 31.0664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.92035959]]\n",
            "action: 2\n",
            "next_state: [-0.26897988  0.01277684], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.92035959]\n",
            "target: 65.4077241339656\n",
            "td loss: [2.48736454]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.07675839]\n",
            " [  2.01116415   0.54271882 -22.65072214]\n",
            " [ -0.2266632    1.79648229 -31.0764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.07675839]\n",
            " [-2.01116415 -0.54271882 22.65072214]\n",
            " [ 0.2266632  -1.79648229 31.0764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.9415946 ]]\n",
            "action: 2\n",
            "next_state: [-0.25693232  0.01204756], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.9415946]\n",
            "target: 65.51539476652073\n",
            "td loss: [2.57380017]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.08548409]\n",
            " [  2.01116415   0.54271882 -22.65816002]\n",
            " [ -0.2266632    1.79648229 -31.0864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.08548409]\n",
            " [-2.01116415 -0.54271882 22.65816002]\n",
            " [ 0.2266632  -1.79648229 31.0864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.96282467]]\n",
            "action: 2\n",
            "next_state: [-0.24567814  0.01125417], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.96282467]\n",
            "target: 65.60894623725335\n",
            "td loss: [2.64612157]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.09430776]\n",
            " [  2.01116415   0.54271882 -22.66553389]\n",
            " [ -0.2266632    1.79648229 -31.0964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.09430776]\n",
            " [-2.01116415 -0.54271882 22.66553389]\n",
            " [ 0.2266632  -1.79648229 31.0964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 62.98404795]]\n",
            "action: 2\n",
            "next_state: [-0.23527513  0.01040301], reward: -1.0, term: False, trunc: True\n",
            "prediction: [62.98404795]\n",
            "target: 65.68949931735574\n",
            "td loss: [2.70545137]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.10321874]\n",
            " [  2.01116415   0.54271882 -22.6728483 ]\n",
            " [ -0.2266632    1.79648229 -31.1064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.10321874]\n",
            " [-2.01116415 -0.54271882 22.6728483 ]\n",
            " [ 0.2266632  -1.79648229 31.1064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.00526299]]\n",
            "action: 2\n",
            "next_state: [-0.22577481  0.00950032], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.00526299]\n",
            "target: 65.75834900288353\n",
            "td loss: [2.75308601]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.11220656]\n",
            " [  2.01116415   0.54271882 -22.68010821]\n",
            " [ -0.2266632    1.79648229 -31.1164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.11220656]\n",
            " [-2.01116415 -0.54271882 22.68010821]\n",
            " [ 0.2266632  -1.79648229 31.1164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.02646883]]\n",
            "action: 2\n",
            "next_state: [-0.21722263  0.00855219], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.02646883]\n",
            "target: 65.81689349981957\n",
            "td loss: [2.79042467]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.12126106]\n",
            " [  2.01116415   0.54271882 -22.68731888]\n",
            " [ -0.2266632    1.79648229 -31.1264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.12126106]\n",
            " [-2.01116415 -0.54271882 22.68731888]\n",
            " [ 0.2266632  -1.79648229 31.1264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.04766493]]\n",
            "action: 2\n",
            "next_state: [-0.20965813  0.0075645 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.04766493]\n",
            "target: 65.86656801199766\n",
            "td loss: [2.81890308]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.13037243]\n",
            " [  2.01116415   0.54271882 -22.69448591]\n",
            " [ -0.2266632    1.79648229 -31.1364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.13037243]\n",
            " [-2.01116415 -0.54271882 22.69448591]\n",
            " [ 0.2266632  -1.79648229 31.1364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.06885124]]\n",
            "action: 2\n",
            "next_state: [-0.2031152   0.00654293], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.06885124]\n",
            "target: 65.90876904404652\n",
            "td loss: [2.8399178]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.13953123]\n",
            " [  2.01116415   0.54271882 -22.70161513]\n",
            " [ -0.2266632    1.79648229 -31.1464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.13953123]\n",
            " [-2.01116415 -0.54271882 22.70161513]\n",
            " [ 0.2266632  -1.79648229 31.1464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.09002813]]\n",
            "action: 2\n",
            "next_state: [-0.19762233  0.00549287], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.09002813]\n",
            "target: 65.94481848447194\n",
            "td loss: [2.85479036]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.14872843]\n",
            " [  2.01116415   0.54271882 -22.70871261]\n",
            " [ -0.2266632    1.79648229 -31.1564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.14872843]\n",
            " [-2.01116415 -0.54271882 22.70871261]\n",
            " [ 0.2266632  -1.79648229 31.1564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.11119635]]\n",
            "action: 2\n",
            "next_state: [-0.19320282  0.00441951], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.11119635]\n",
            "target: 65.97589674665244\n",
            "td loss: [2.86470039]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.15795535]\n",
            " [  2.01116415   0.54271882 -22.71578459]\n",
            " [ -0.2266632    1.79648229 -31.1664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.15795535]\n",
            " [-2.01116415 -0.54271882 22.71578459]\n",
            " [ 0.2266632  -1.79648229 31.1664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.13235703]]\n",
            "action: 2\n",
            "next_state: [-0.189875    0.00332782], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.13235703]\n",
            "target: 66.00300856811663\n",
            "td loss: [2.87065154]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.16720363]\n",
            " [  2.01116415   0.54271882 -22.72283743]\n",
            " [ -0.2266632    1.79648229 -31.1764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.16720363]\n",
            " [-2.01116415 -0.54271882 22.72283743]\n",
            " [ 0.2266632  -1.79648229 31.1764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.15351156]]\n",
            "action: 2\n",
            "next_state: [-0.18765244  0.00222256], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.15351156]\n",
            "target: 66.02693598489059\n",
            "td loss: [2.87342443]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.17646518]\n",
            " [  2.01116415   0.54271882 -22.72987761]\n",
            " [ -0.2266632    1.79648229 -31.1864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.17646518]\n",
            " [-2.01116415 -0.54271882 22.72987761]\n",
            " [ 0.2266632  -1.79648229 31.1864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.17466157]]\n",
            "action: 2\n",
            "next_state: [-0.18654408  0.00110836], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.17466157]\n",
            "target: 66.04822746657284\n",
            "td loss: [2.8735659]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.18573208]\n",
            " [  2.01116415   0.54271882 -22.73691168]\n",
            " [ -0.2266632    1.79648229 -31.1964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.18573208]\n",
            " [-2.01116415 -0.54271882 22.73691168]\n",
            " [ 0.2266632  -1.79648229 31.1964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.19580885]]\n",
            "action: 2\n",
            "next_state: [-1.8655434e-01 -1.0265422e-05], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.19580885]\n",
            "target: 66.06717254893084\n",
            "td loss: [2.8713637]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.19499651]\n",
            " [  2.01116415   0.54271882 -22.74394622]\n",
            " [ -0.2266632    1.79648229 -31.2064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.19499651]\n",
            " [-2.01116415 -0.54271882 22.74394622]\n",
            " [ 0.2266632  -1.79648229 31.2064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.21695528]]\n",
            "action: 2\n",
            "next_state: [-0.1876832  -0.00112885], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.21695528]\n",
            "target: 66.08378703096743\n",
            "td loss: [2.86683175]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.20425068]\n",
            " [  2.01116415   0.54271882 -22.7509878 ]\n",
            " [ -0.2266632    1.79648229 -31.2164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.20425068]\n",
            " [-2.01116415 -0.54271882 22.7509878 ]\n",
            " [ 0.2266632  -1.79648229 31.2164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.23810273]]\n",
            "action: 2\n",
            "next_state: [-0.18992612 -0.00224293], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.23810273]\n",
            "target: 66.09782695052806\n",
            "td loss: [2.85972422]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.21348673]\n",
            " [  2.01116415   0.54271882 -22.75804297]\n",
            " [ -0.2266632    1.79648229 -31.2264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.21348673]\n",
            " [-2.01116415 -0.54271882 22.75804297]\n",
            " [ 0.2266632  -1.79648229 31.2264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.25925301]]\n",
            "action: 2\n",
            "next_state: [-0.1932741  -0.00334798], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.25925301]\n",
            "target: 66.10877590208838\n",
            "td loss: [2.8495229]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.22269661]\n",
            " [  2.01116415   0.54271882 -22.7651182 ]\n",
            " [ -0.2266632    1.79648229 -31.2364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.22269661]\n",
            " [-2.01116415 -0.54271882 22.7651182 ]\n",
            " [ 0.2266632  -1.79648229 31.2364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.28040777]]\n",
            "action: 2\n",
            "next_state: [-0.19771348 -0.00443938], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.28040777]\n",
            "target: 66.11589489475571\n",
            "td loss: [2.83548712]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.23187209]\n",
            " [  2.01116415   0.54271882 -22.77221986]\n",
            " [ -0.2266632    1.79648229 -31.2464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.23187209]\n",
            " [-2.01116415 -0.54271882 22.77221986]\n",
            " [ 0.2266632  -1.79648229 31.2464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.30156848]]\n",
            "action: 2\n",
            "next_state: [-0.20322584 -0.00551235], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.30156848]\n",
            "target: 66.1182108191293\n",
            "td loss: [2.81664233]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.24100462]\n",
            " [  2.01116415   0.54271882 -22.77935418]\n",
            " [ -0.2266632    1.79648229 -31.2564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.24100462]\n",
            " [-2.01116415 -0.54271882 22.77935418]\n",
            " [ 0.2266632  -1.79648229 31.2564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.32273632]]\n",
            "action: 2\n",
            "next_state: [-0.20978777 -0.00656194], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.32273632]\n",
            "target: 66.11458057287774\n",
            "td loss: [2.79184426]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.25008533]\n",
            " [  2.01116415   0.54271882 -22.7865272 ]\n",
            " [ -0.2266632    1.79648229 -31.2664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.25008533]\n",
            " [-2.01116415 -0.54271882 22.7865272 ]\n",
            " [ 0.2266632  -1.79648229 31.2664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.34391211]]\n",
            "action: 2\n",
            "next_state: [-0.21737072 -0.00758294], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.34391211]\n",
            "target: 66.103714291389\n",
            "td loss: [2.75980219]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.25910499]\n",
            " [  2.01116415   0.54271882 -22.79374474]\n",
            " [ -0.2266632    1.79648229 -31.2764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.25910499]\n",
            " [-2.01116415 -0.54271882 22.79374474]\n",
            " [ 0.2266632  -1.79648229 31.2764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.36509631]]\n",
            "action: 2\n",
            "next_state: [-0.22594066 -0.00856995], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.36509631]\n",
            "target: 66.08423415190845\n",
            "td loss: [2.71913784]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.26805403]\n",
            " [  2.01116415   0.54271882 -22.80101238]\n",
            " [ -0.2266632    1.79648229 -31.2864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.26805403]\n",
            " [-2.01116415 -0.54271882 22.80101238]\n",
            " [ 0.2266632  -1.79648229 31.2864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.38628898]]\n",
            "action: 2\n",
            "next_state: [-0.23545797 -0.0095173 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.38628898]\n",
            "target: 66.05473088200257\n",
            "td loss: [2.6684419]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.27692254]\n",
            " [  2.01116415   0.54271882 -22.80833537]\n",
            " [ -0.2266632    1.79648229 -31.2964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.27692254]\n",
            " [-2.01116415 -0.54271882 22.80833537]\n",
            " [ 0.2266632  -1.79648229 31.2964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.40748971]]\n",
            "action: 2\n",
            "next_state: [-0.24587707 -0.0104191 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.40748971]\n",
            "target: 66.01383751515074\n",
            "td loss: [2.60634781]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.28570039]\n",
            " [  2.01116415   0.54271882 -22.81571863]\n",
            " [ -0.2266632    1.79648229 -31.3064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.28570039]\n",
            " [-2.01116415 -0.54271882 22.81571863]\n",
            " [ 0.2266632  -1.79648229 31.3064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.42869765]]\n",
            "action: 2\n",
            "next_state: [-0.25714633 -0.01126926], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.42869765]\n",
            "target: 65.9602674003077\n",
            "td loss: [2.53156975]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.29437723]\n",
            " [  2.01116415   0.54271882 -22.82316668]\n",
            " [ -0.2266632    1.79648229 -31.3164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.29437723]\n",
            " [-2.01116415 -0.54271882 22.82316668]\n",
            " [ 0.2266632  -1.79648229 31.3164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.44991152]]\n",
            "action: 2\n",
            "next_state: [-0.26920786 -0.01206153], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.44991152]\n",
            "target: 65.89289784885207\n",
            "td loss: [2.44298633]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.30294269]\n",
            " [  2.01116415   0.54271882 -22.8306836 ]\n",
            " [ -0.2266632    1.79648229 -31.3264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.30294269]\n",
            " [-2.01116415 -0.54271882 22.8306836 ]\n",
            " [ 0.2266632  -1.79648229 31.3264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.47112961]]\n",
            "action: 2\n",
            "next_state: [-0.28199744 -0.01278958], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.47112961]\n",
            "target: 65.81085099964253\n",
            "td loss: [2.33972139]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.31138648]\n",
            " [  2.01116415   0.54271882 -22.838273  ]\n",
            " [ -0.2266632    1.79648229 -31.3364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.31138648]\n",
            " [-2.01116415 -0.54271882 22.838273  ]\n",
            " [ 0.2266632  -1.79648229 31.3364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.49234983]]\n",
            "action: 2\n",
            "next_state: [-0.2954445  -0.01344705], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.49234983]\n",
            "target: 65.71352060054717\n",
            "td loss: [2.22117077]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.31969859]\n",
            " [  2.01116415   0.54271882 -22.84593799]\n",
            " [ -0.2266632    1.79648229 -31.3464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.31969859]\n",
            " [-2.01116415 -0.54271882 22.84593799]\n",
            " [ 0.2266632  -1.79648229 31.3464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.51356976]]\n",
            "action: 2\n",
            "next_state: [-0.30947217 -0.01402769], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.51356976]\n",
            "target: 65.60064304667738\n",
            "td loss: [2.08707328]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.32786945]\n",
            " [  2.01116415   0.54271882 -22.85368109]\n",
            " [ -0.2266632    1.79648229 -31.3564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.32786945]\n",
            " [-2.01116415 -0.54271882 22.85368109]\n",
            " [ 0.2266632  -1.79648229 31.3564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.53478674]]\n",
            "action: 2\n",
            "next_state: [-0.32399762 -0.01452545], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.53478674]\n",
            "target: 65.47232988467813\n",
            "td loss: [1.93754315]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.33589015]\n",
            " [  2.01116415   0.54271882 -22.86150426]\n",
            " [ -0.2266632    1.79648229 -31.3664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.33589015]\n",
            " [-2.01116415 -0.54271882 22.86150426]\n",
            " [ 0.2266632  -1.79648229 31.3664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.55599788]]\n",
            "action: 2\n",
            "next_state: [-0.33893222 -0.01493458], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.55599788]\n",
            "target: 65.32910721661452\n",
            "td loss: [1.77310934]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.34375265]\n",
            " [  2.01116415   0.54271882 -22.86940885]\n",
            " [ -0.2266632    1.79648229 -31.3764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.34375265]\n",
            " [-2.01116415 -0.54271882 22.86940885]\n",
            " [ 0.2266632  -1.79648229 31.3764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.57720024]]\n",
            "action: 2\n",
            "next_state: [-0.35418203 -0.01524982], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.57720024]\n",
            "target: 65.17189282871053\n",
            "td loss: [1.59469259]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.35144996]\n",
            " [  2.01116415   0.54271882 -22.87739559]\n",
            " [ -0.2266632    1.79648229 -31.3864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.35144996]\n",
            " [-2.01116415 -0.54271882 22.87739559]\n",
            " [ 0.2266632  -1.79648229 31.3864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.59839083]]\n",
            "action: 2\n",
            "next_state: [-0.36964846 -0.01546644], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.59839083]\n",
            "target: 65.00202267855357\n",
            "td loss: [1.40363184]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.35897635]\n",
            " [  2.01116415   0.54271882 -22.88546456]\n",
            " [ -0.2266632    1.79648229 -31.3964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.35897635]\n",
            " [-2.01116415 -0.54271882 22.88546456]\n",
            " [ 0.2266632  -1.79648229 31.3964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.61956678]]\n",
            "action: 2\n",
            "next_state: [-0.38522893 -0.01558045], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.61956678]\n",
            "target: 64.82119351439408\n",
            "td loss: [1.20162674]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.3663275 ]\n",
            " [  2.01116415   0.54271882 -22.89361523]\n",
            " [ -0.2266632    1.79648229 -31.4064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.3663275 ]\n",
            " [-2.01116415 -0.54271882 22.89361523]\n",
            " [ 0.2266632  -1.79648229 31.4064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.64072534]]\n",
            "action: 2\n",
            "next_state: [-0.4008176  -0.01558868], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.64072534]\n",
            "target: 64.6314348949533\n",
            "td loss: [0.99070955]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.37350067]\n",
            " [  2.01116415   0.54271882 -22.90184643]\n",
            " [ -0.2266632    1.79648229 -31.4164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.37350067]\n",
            " [-2.01116415 -0.54271882 22.90184643]\n",
            " [ 0.2266632  -1.79648229 31.4164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.66186405]]\n",
            "action: 2\n",
            "next_state: [-0.41630647 -0.01548886], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.66186405]\n",
            "target: 64.43505448184791\n",
            "td loss: [0.77319043]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.38049475]\n",
            " [  2.01116415   0.54271882 -22.91015642]\n",
            " [ -0.2266632    1.79648229 -31.4264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.38049475]\n",
            " [-2.01116415 -0.54271882 22.91015642]\n",
            " [ 0.2266632  -1.79648229 31.4264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.68298074]]\n",
            "action: 2\n",
            "next_state: [-0.43158618 -0.01527973], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.68298074]\n",
            "target: 64.23456042545742\n",
            "td loss: [0.55157969]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.38731034]\n",
            " [  2.01116415   0.54271882 -22.91854284]\n",
            " [ -0.2266632    1.79648229 -31.4364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.38731034]\n",
            " [-2.01116415 -0.54271882 22.91854284]\n",
            " [ 0.2266632  -1.79648229 31.4364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.70407363]]\n",
            "action: 2\n",
            "next_state: [-0.44654727 -0.01496109], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.70407363]\n",
            "target: 64.03259452700667\n",
            "td loss: [0.32852089]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.39394979]\n",
            " [  2.01116415   0.54271882 -22.92700286]\n",
            " [ -0.2266632    1.79648229 -31.4464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.39394979]\n",
            " [-2.01116415 -0.54271882 22.92700286]\n",
            " [ 0.2266632  -1.79648229 31.4464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.72514137]]\n",
            "action: 2\n",
            "next_state: [-0.46108112 -0.01453384], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.72514137]\n",
            "target: 63.83186894527884\n",
            "td loss: [0.10672758]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.40041716]\n",
            " [  2.01116415   0.54271882 -22.93553311]\n",
            " [ -0.2266632    1.79648229 -31.4564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.40041716]\n",
            " [-2.01116415 -0.54271882 22.93553311]\n",
            " [ 0.2266632  -1.79648229 31.4564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.74618304]]\n",
            "action: 2\n",
            "next_state: [-0.4750811  -0.01399998], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.74618304]\n",
            "target: 63.635077402689845\n",
            "td loss: [-0.11110564]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.40671818]\n",
            " [  2.01116415   0.54271882 -22.9441298 ]\n",
            " [ -0.2266632    1.79648229 -31.4664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.40671818]\n",
            " [-2.01116415 -0.54271882 22.9441298 ]\n",
            " [ 0.2266632  -1.79648229 31.4664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.7671982 ]]\n",
            "action: 2\n",
            "next_state: [-0.48844367 -0.01336258], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.7671982]\n",
            "target: 63.44484876053022\n",
            "td loss: [-0.32234944]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.41286014]\n",
            " [  2.01116415   0.54271882 -22.95278878]\n",
            " [ -0.2266632    1.79648229 -31.4764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.41286014]\n",
            " [-2.01116415 -0.54271882 22.95278878]\n",
            " [ 0.2266632  -1.79648229 31.4764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.78818689]]\n",
            "action: 2\n",
            "next_state: [-0.5010694  -0.01262575], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.78818689]\n",
            "target: 63.26367529038819\n",
            "td loss: [-0.5245116]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.41885178]\n",
            " [  2.01116415   0.54271882 -22.96150554]\n",
            " [ -0.2266632    1.79648229 -31.4864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.41885178]\n",
            " [-2.01116415 -0.54271882 22.96150554]\n",
            " [ 0.2266632  -1.79648229 31.4864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.80914959]]\n",
            "action: 2\n",
            "next_state: [-0.51286405 -0.0117946 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.80914959]\n",
            "target: 63.093885553714884\n",
            "td loss: [-0.71526404]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.42470318]\n",
            " [  2.01116415   0.54271882 -22.9702753 ]\n",
            " [ -0.2266632    1.79648229 -31.4964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.42470318]\n",
            " [-2.01116415 -0.54271882 22.9702753 ]\n",
            " [ 0.2266632  -1.79648229 31.4964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.83008724]]\n",
            "action: 2\n",
            "next_state: [-0.5237391  -0.01087509], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.83008724]\n",
            "target: 62.93761105560147\n",
            "td loss: [-0.89247618]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.43042559]\n",
            " [  2.01116415   0.54271882 -22.97909308]\n",
            " [ -0.2266632    1.79648229 -31.5064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.43042559]\n",
            " [-2.01116415 -0.54271882 22.97909308]\n",
            " [ 0.2266632  -1.79648229 31.5064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.85100117]]\n",
            "action: 2\n",
            "next_state: [-0.53361315 -0.00987404], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.85100117]\n",
            "target: 62.79675093561777\n",
            "td loss: [-1.05425023]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.43603129]\n",
            " [  2.01116415   0.54271882 -22.98795371]\n",
            " [ -0.2266632    1.79648229 -31.5164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.43603129]\n",
            " [-2.01116415 -0.54271882 22.98795371]\n",
            " [ 0.2266632  -1.79648229 31.5164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.8718931 ]]\n",
            "action: 2\n",
            "next_state: [-0.5424121  -0.00879894], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.8718931]\n",
            "target: 62.67298214039367\n",
            "td loss: [-1.19891096]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.44153343]\n",
            " [  2.01116415   0.54271882 -22.99685189]\n",
            " [ -0.2266632    1.79648229 -31.5264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.44153343]\n",
            " [-2.01116415 -0.54271882 22.99685189]\n",
            " [ 0.2266632  -1.79648229 31.5264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.8927651 ]]\n",
            "action: 2\n",
            "next_state: [-0.55007005 -0.00765792], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.8927651]\n",
            "target: 62.56774010749066\n",
            "td loss: [-1.325025]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.44694591]\n",
            " [  2.01116415   0.54271882 -23.00578223]\n",
            " [ -0.2266632    1.79648229 -31.5364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.44694591]\n",
            " [-2.01116415 -0.54271882 23.00578223]\n",
            " [ 0.2266632  -1.79648229 31.5364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.91361953]]\n",
            "action: 2\n",
            "next_state: [-0.55652964 -0.00645959], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.91361953]\n",
            "target: 62.482234142321026\n",
            "td loss: [-1.43138539]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.45228323]\n",
            " [  2.01116415   0.54271882 -23.01473928]\n",
            " [ -0.2266632    1.79648229 -31.5464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.45228323]\n",
            " [-2.01116415 -0.54271882 23.01473928]\n",
            " [ 0.2266632  -1.79648229 31.5464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.93445899]]\n",
            "action: 2\n",
            "next_state: [-0.56174266 -0.00521301], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.93445899]\n",
            "target: 62.417456383912516\n",
            "td loss: [-1.51700261]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.45756037]\n",
            " [  2.01116415   0.54271882 -23.02371754]\n",
            " [ -0.2266632    1.79648229 -31.5564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.45756037]\n",
            " [-2.01116415 -0.54271882 23.02371754]\n",
            " [ 0.2266632  -1.79648229 31.5564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.95528632]]\n",
            "action: 2\n",
            "next_state: [-0.5656702  -0.00392756], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.95528632]\n",
            "target: 62.374182381020226\n",
            "td loss: [-1.58110394]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.46279266]\n",
            " [  2.01116415   0.54271882 -23.0327115 ]\n",
            " [ -0.2266632    1.79648229 -31.5664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.46279266]\n",
            " [-2.01116415 -0.54271882 23.0327115 ]\n",
            " [ 0.2266632  -1.79648229 31.5664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.97610451]]\n",
            "action: 2\n",
            "next_state: [-0.5682831  -0.00261286], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.97610451]\n",
            "target: 62.352992170755755\n",
            "td loss: [-1.62311234]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.46799573]\n",
            " [  2.01116415   0.54271882 -23.04171563]\n",
            " [ -0.2266632    1.79648229 -31.5764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.46799573]\n",
            " [-2.01116415 -0.54271882 23.04171563]\n",
            " [ 0.2266632  -1.79648229 31.5764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 63.99691668]]\n",
            "action: 2\n",
            "next_state: [-0.5695618  -0.00127873], reward: -1.0, term: False, trunc: True\n",
            "prediction: [63.99691668]\n",
            "target: 62.35427513849998\n",
            "td loss: [-1.64264154]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.47318534]\n",
            " [  2.01116415   0.54271882 -23.05072441]\n",
            " [ -0.2266632    1.79648229 -31.5864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.47318534]\n",
            " [-2.01116415 -0.54271882 23.05072441]\n",
            " [ 0.2266632  -1.79648229 31.5864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.01772606]]\n",
            "action: 2\n",
            "next_state: [-5.6949687e-01  6.4900712e-05], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.01772606]\n",
            "target: 62.37823267884218\n",
            "td loss: [-1.63949338]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.47837736]\n",
            " [  2.01116415   0.54271882 -23.05973231]\n",
            " [ -0.2266632    1.79648229 -31.5964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.47837736]\n",
            " [-2.01116415 -0.54271882 23.05973231]\n",
            " [ 0.2266632  -1.79648229 31.5964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.0385359 ]]\n",
            "action: 2\n",
            "next_state: [-0.5680888   0.00140805], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.0385359]\n",
            "target: 62.42488730028779\n",
            "td loss: [-1.6136486]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.48358765]\n",
            " [  2.01116415   0.54271882 -23.06873381]\n",
            " [ -0.2266632    1.79648229 -31.6064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.48358765]\n",
            " [-2.01116415 -0.54271882 23.06873381]\n",
            " [ 0.2266632  -1.79648229 31.6064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.05934946]]\n",
            "action: 2\n",
            "next_state: [-0.5653481   0.00274074], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.05934946]\n",
            "target: 62.49408004195538\n",
            "td loss: [-1.56526942]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.48883198]\n",
            " [  2.01116415   0.54271882 -23.07772341]\n",
            " [ -0.2266632    1.79648229 -31.6164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.48883198]\n",
            " [-2.01116415 -0.54271882 23.07772341]\n",
            " [ 0.2266632  -1.79648229 31.6164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.08016997]]\n",
            "action: 2\n",
            "next_state: [-0.56129503  0.00405304], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.08016997]\n",
            "target: 62.58546142376192\n",
            "td loss: [-1.49470855]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.49412595]\n",
            " [  2.01116415   0.54271882 -23.08669561]\n",
            " [ -0.2266632    1.79648229 -31.6264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.49412595]\n",
            " [-2.01116415 -0.54271882 23.08669561]\n",
            " [ 0.2266632  -1.79648229 31.6264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.10100058]]\n",
            "action: 2\n",
            "next_state: [-0.5559599   0.00533516], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.10100058]\n",
            "target: 62.69848479044962\n",
            "td loss: [-1.40251579]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.49948488]\n",
            " [  2.01116415   0.54271882 -23.09564493]\n",
            " [ -0.2266632    1.79648229 -31.6364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.49948488]\n",
            " [-2.01116415 -0.54271882 23.09564493]\n",
            " [ 0.2266632  -1.79648229 31.6364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.1218443 ]]\n",
            "action: 2\n",
            "next_state: [-0.54938245  0.00657748], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.1218443]\n",
            "target: 62.832391975158274\n",
            "td loss: [-1.28945232]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.50492372]\n",
            " [  2.01116415   0.54271882 -23.10456593]\n",
            " [ -0.2266632    1.79648229 -31.6464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.50492372]\n",
            " [-2.01116415 -0.54271882 23.10456593]\n",
            " [ 0.2266632  -1.79648229 31.6464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.14270399]]\n",
            "action: 2\n",
            "next_state: [-0.54161173  0.00777067], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.14270399]\n",
            "target: 62.98621786846521\n",
            "td loss: [-1.15648612]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.51045692]\n",
            " [  2.01116415   0.54271882 -23.11345322]\n",
            " [ -0.2266632    1.79648229 -31.6564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.51045692]\n",
            " [-2.01116415 -0.54271882 23.11345322]\n",
            " [ 0.2266632  -1.79648229 31.6564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.16358231]]\n",
            "action: 2\n",
            "next_state: [-0.532706   0.0089057], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.16358231]\n",
            "target: 63.15874777932865\n",
            "td loss: [-1.00483453]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.5160983 ]\n",
            " [  2.01116415   0.54271882 -23.12230148]\n",
            " [ -0.2266632    1.79648229 -31.6664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.5160983 ]\n",
            " [-2.01116415 -0.54271882 23.12230148]\n",
            " [ 0.2266632  -1.79648229 31.6664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.18448163]]\n",
            "action: 2\n",
            "next_state: [-0.5227321  0.009974 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.18448163]\n",
            "target: 63.348533953123024\n",
            "td loss: [-0.83594767]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.52186091]\n",
            " [  2.01116415   0.54271882 -23.13110551]\n",
            " [ -0.2266632    1.79648229 -31.6764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.52186091]\n",
            " [-2.01116415 -0.54271882 23.13110551]\n",
            " [ 0.2266632  -1.79648229 31.6764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.20540404]]\n",
            "action: 2\n",
            "next_state: [-0.5117645  0.0109675], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.20540404]\n",
            "target: 63.55388223407333\n",
            "td loss: [-0.65152181]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.52775691]\n",
            " [  2.01116415   0.54271882 -23.13986023]\n",
            " [ -0.2266632    1.79648229 -31.6864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.52775691]\n",
            " [-2.01116415 -0.54271882 23.13986023]\n",
            " [ 0.2266632  -1.79648229 31.6864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.22635128]]\n",
            "action: 2\n",
            "next_state: [-0.4998858   0.01187876], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.22635128]\n",
            "target: 63.77284158230944\n",
            "td loss: [-0.4535097]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.53379736]\n",
            " [  2.01116415   0.54271882 -23.14856075]\n",
            " [ -0.2266632    1.79648229 -31.6964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.53379736]\n",
            " [-2.01116415 -0.54271882 23.14856075]\n",
            " [ 0.2266632  -1.79648229 31.6964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.2473247 ]]\n",
            "action: 2\n",
            "next_state: [-0.48718473  0.01270106], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.2473247]\n",
            "target: 64.00324136852119\n",
            "td loss: [-0.24408333]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.53999213]\n",
            " [  2.01116415   0.54271882 -23.15720243]\n",
            " [ -0.2266632    1.79648229 -31.7064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.53999213]\n",
            " [-2.01116415 -0.54271882 23.15720243]\n",
            " [ 0.2266632  -1.79648229 31.7064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.26832523]]\n",
            "action: 2\n",
            "next_state: [-0.47375622  0.0134285 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.26832523]\n",
            "target: 64.24268163130178\n",
            "td loss: [-0.0256436]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.54634969]\n",
            " [  2.01116415   0.54271882 -23.1657809 ]\n",
            " [ -0.2266632    1.79648229 -31.7164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.54634969]\n",
            " [-2.01116415 -0.54271882 23.1657809 ]\n",
            " [ 0.2266632  -1.79648229 31.7164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.28935332]]\n",
            "action: 2\n",
            "next_state: [-0.45970017  0.01405607], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.28935332]\n",
            "target: 64.48859557091113\n",
            "td loss: [0.19924225]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.55287703]\n",
            " [  2.01116415   0.54271882 -23.17429212]\n",
            " [ -0.2266632    1.79648229 -31.7264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.55287703]\n",
            " [-2.01116415 -0.54271882 23.17429212]\n",
            " [ 0.2266632  -1.79648229 31.7264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.31040898]]\n",
            "action: 2\n",
            "next_state: [-0.4451204   0.01457976], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.31040898]\n",
            "target: 64.73826583997514\n",
            "td loss: [0.42785686]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.55957951]\n",
            " [  2.01116415   0.54271882 -23.18273244]\n",
            " [ -0.2266632    1.79648229 -31.7364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.55957951]\n",
            " [-2.01116415 -0.54271882 23.18273244]\n",
            " [ 0.2266632  -1.79648229 31.7364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.3314917 ]]\n",
            "action: 2\n",
            "next_state: [-0.4301238  0.0149966], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.3314917]\n",
            "target: 64.98890975850361\n",
            "td loss: [0.65741806]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.56646077]\n",
            " [  2.01116415   0.54271882 -23.19109867]\n",
            " [ -0.2266632    1.79648229 -31.7464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.56646077]\n",
            " [-2.01116415 -0.54271882 23.19109867]\n",
            " [ 0.2266632  -1.79648229 31.7464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.35260049]]\n",
            "action: 2\n",
            "next_state: [-0.41481912  0.01530469], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.35260049]\n",
            "target: 65.237735417794\n",
            "td loss: [0.88513493]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.5735227 ]\n",
            " [  2.01116415   0.54271882 -23.19938809]\n",
            " [ -0.2266632    1.79648229 -31.7564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.5735227 ]\n",
            " [-2.01116415 -0.54271882 23.19938809]\n",
            " [ 0.2266632  -1.79648229 31.7564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.3737339 ]]\n",
            "action: 2\n",
            "next_state: [-0.3993159   0.01550324], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.3737339]\n",
            "target: 65.4820005689215\n",
            "td loss: [1.10826667]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.58076543]\n",
            " [  2.01116415   0.54271882 -23.20759853]\n",
            " [ -0.2266632    1.79648229 -31.7664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.58076543]\n",
            " [-2.01116415 -0.54271882 23.20759853]\n",
            " [ 0.2266632  -1.79648229 31.7664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.39489001]]\n",
            "action: 2\n",
            "next_state: [-0.38372332  0.01559257], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.39489001]\n",
            "target: 65.71912193101463\n",
            "td loss: [1.32423192]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.58818732]\n",
            " [  2.01116415   0.54271882 -23.21572839]\n",
            " [ -0.2266632    1.79648229 -31.7764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.58818732]\n",
            " [-2.01116415 -0.54271882 23.21572839]\n",
            " [ 0.2266632  -1.79648229 31.7764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.41606654]]\n",
            "action: 2\n",
            "next_state: [-0.36814928  0.01557402], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.41606654]\n",
            "target: 65.94671879369355\n",
            "td loss: [1.53065225]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.59578506]\n",
            " [  2.01116415   0.54271882 -23.22377664]\n",
            " [ -0.2266632    1.79648229 -31.7864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.59578506]\n",
            " [-2.01116415 -0.54271882 23.22377664]\n",
            " [ 0.2266632  -1.79648229 31.7864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.43726086]]\n",
            "action: 2\n",
            "next_state: [-0.35269934  0.01544995], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.43726086]\n",
            "target: 66.16270117121698\n",
            "td loss: [1.72544031]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.60355377]\n",
            " [  2.01116415   0.54271882 -23.2317429 ]\n",
            " [ -0.2266632    1.79648229 -31.7964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.60355377]\n",
            " [-2.01116415 -0.54271882 23.2317429 ]\n",
            " [ 0.2266632  -1.79648229 31.7964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.45847008]]\n",
            "action: 2\n",
            "next_state: [-0.33747572  0.01522362], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.45847008]\n",
            "target: 66.3653234154752\n",
            "td loss: [1.90685334]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.61148717]\n",
            " [  2.01116415   0.54271882 -23.23962739]\n",
            " [ -0.2266632    1.79648229 -31.8064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.61148717]\n",
            " [-2.01116415 -0.54271882 23.23962739]\n",
            " [ 0.2266632  -1.79648229 31.8064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.47969114]]\n",
            "action: 2\n",
            "next_state: [-0.3225766   0.01489912], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.47969114]\n",
            "target: 66.5532269768443\n",
            "td loss: [2.07353584]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.6195777 ]\n",
            " [  2.01116415   0.54271882 -23.24743098]\n",
            " [ -0.2266632    1.79648229 -31.8164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.6195777 ]\n",
            " [-2.01116415 -0.54271882 23.24743098]\n",
            " [ 0.2266632  -1.79648229 31.8164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.5009209 ]]\n",
            "action: 2\n",
            "next_state: [-0.30809543  0.01448119], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.5009209]\n",
            "target: 66.72546944980324\n",
            "td loss: [2.22454855]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.62781678]\n",
            " [  2.01116415   0.54271882 -23.25515514]\n",
            " [ -0.2266632    1.79648229 -31.8264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.62781678]\n",
            " [-2.01116415 -0.54271882 23.25515514]\n",
            " [ 0.2266632  -1.79648229 31.8264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.52215623]]\n",
            "action: 2\n",
            "next_state: [-0.29412025  0.01397518], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.52215623]\n",
            "target: 66.88153691084588\n",
            "td loss: [2.35938068]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.63619498]\n",
            " [  2.01116415   0.54271882 -23.26280194]\n",
            " [ -0.2266632    1.79648229 -31.8364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.63619498]\n",
            " [-2.01116415 -0.54271882 23.26280194]\n",
            " [ 0.2266632  -1.79648229 31.8364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.5433941 ]]\n",
            "action: 2\n",
            "next_state: [-0.28073338  0.01338685], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.5433941]\n",
            "target: 67.02133197415782\n",
            "td loss: [2.47793788]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.64470224]\n",
            " [  2.01116415   0.54271882 -23.27037402]\n",
            " [ -0.2266632    1.79648229 -31.8464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.64470224]\n",
            " [-2.01116415 -0.54271882 23.27037402]\n",
            " [ 0.2266632  -1.79648229 31.8464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.56463166]]\n",
            "action: 2\n",
            "next_state: [-0.2680111  0.0127223], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.56463166]\n",
            "target: 67.14514495263501\n",
            "td loss: [2.58051329]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.65332809]\n",
            " [  2.01116415   0.54271882 -23.27787458]\n",
            " [ -0.2266632    1.79648229 -31.8564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.65332809]\n",
            " [-2.01116415 -0.54271882 23.27787458]\n",
            " [ 0.2266632  -1.79648229 31.8564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.58586635]]\n",
            "action: 2\n",
            "next_state: [-0.25602332  0.01198778], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.58586635]\n",
            "target: 67.25362221213429\n",
            "td loss: [2.66775586]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.66206183]\n",
            " [  2.01116415   0.54271882 -23.2853073 ]\n",
            " [ -0.2266632    1.79648229 -31.8664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.66206183]\n",
            " [-2.01116415 -0.54271882 23.2853073 ]\n",
            " [ 0.2266632  -1.79648229 31.8664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.60709596]]\n",
            "action: 2\n",
            "next_state: [-0.24483368  0.01118964], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.60709596]\n",
            "target: 67.34770149562104\n",
            "td loss: [2.74060554]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.67089271]\n",
            " [  2.01116415   0.54271882 -23.29267635]\n",
            " [ -0.2266632    1.79648229 -31.8764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.67089271]\n",
            " [-2.01116415 -0.54271882 23.29267635]\n",
            " [ 0.2266632  -1.79648229 31.8764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.62831864]]\n",
            "action: 2\n",
            "next_state: [-0.23449944  0.01033423], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.62831864]\n",
            "target: 67.42855739585045\n",
            "td loss: [2.80023876]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.67981006]\n",
            " [  2.01116415   0.54271882 -23.29998632]\n",
            " [ -0.2266632    1.79648229 -31.8864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.67981006]\n",
            " [-2.01116415 -0.54271882 23.29998632]\n",
            " [ 0.2266632  -1.79648229 31.8864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.64953299]]\n",
            "action: 2\n",
            "next_state: [-0.22507167  0.00942777], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.64953299]\n",
            "target: 67.49752977504762\n",
            "td loss: [2.84799678]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.68880346]\n",
            " [  2.01116415   0.54271882 -23.30724218]\n",
            " [ -0.2266632    1.79648229 -31.8964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.68880346]\n",
            " [-2.01116415 -0.54271882 23.30724218]\n",
            " [ 0.2266632  -1.79648229 31.8964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.67073808]]\n",
            "action: 2\n",
            "next_state: [-0.21659534  0.00847634], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.67073808]\n",
            "target: 67.55606168455488\n",
            "td loss: [2.88532361]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.69786276]\n",
            " [  2.01116415   0.54271882 -23.31444924]\n",
            " [ -0.2266632    1.79648229 -31.9064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.69786276]\n",
            " [-2.01116415 -0.54271882 23.31444924]\n",
            " [ 0.2266632  -1.79648229 31.9064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.69193341]]\n",
            "action: 2\n",
            "next_state: [-0.20910953  0.00748581], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.69193341]\n",
            "target: 67.60562028928325\n",
            "td loss: [2.91368687]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.70697817]\n",
            " [  2.01116415   0.54271882 -23.3216131 ]\n",
            " [ -0.2266632    1.79648229 -31.9164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.70697817]\n",
            " [-2.01116415 -0.54271882 23.3216131 ]\n",
            " [ 0.2266632  -1.79648229 31.9164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.71311897]]\n",
            "action: 2\n",
            "next_state: [-0.20264772  0.00646181], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.71311897]\n",
            "target: 67.64764395750208\n",
            "td loss: [2.93452499]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.71614029]\n",
            " [  2.01116415   0.54271882 -23.32873963]\n",
            " [ -0.2266632    1.79648229 -31.9264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.71614029]\n",
            " [-2.01116415 -0.54271882 23.32873963]\n",
            " [ 0.2266632  -1.79648229 31.9264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.73429515]]\n",
            "action: 2\n",
            "next_state: [-0.19723797  0.00540975], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.73429515]\n",
            "target: 67.68347394307716\n",
            "td loss: [2.94917879]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.72534012]\n",
            " [  2.01116415   0.54271882 -23.33583489]\n",
            " [ -0.2266632    1.79648229 -31.9364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.72534012]\n",
            " [-2.01116415 -0.54271882 23.33583489]\n",
            " [ 0.2266632  -1.79648229 31.9364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.75546274]]\n",
            "action: 2\n",
            "next_state: [-0.19290318  0.00433478], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.75546274]\n",
            "target: 67.71431291005176\n",
            "td loss: [2.95885017]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.73456901]\n",
            " [  2.01116415   0.54271882 -23.34290513]\n",
            " [ -0.2266632    1.79648229 -31.9464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.73456901]\n",
            " [-2.01116415 -0.54271882 23.34290513]\n",
            " [ 0.2266632  -1.79648229 31.9464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.77662288]]\n",
            "action: 2\n",
            "next_state: [-0.18966132  0.00324186], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.77662288]\n",
            "target: 67.74117383199798\n",
            "td loss: [2.96455095]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.74381862]\n",
            " [  2.01116415   0.54271882 -23.34995675]\n",
            " [ -0.2266632    1.79648229 -31.9564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.74381862]\n",
            " [-2.01116415 -0.54271882 23.34995675]\n",
            " [ 0.2266632  -1.79648229 31.9564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.79777699]]\n",
            "action: 2\n",
            "next_state: [-0.18752559  0.00213574], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.79777699]\n",
            "target: 67.76484622149772\n",
            "td loss: [2.96706923]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.75308086]\n",
            " [  2.01116415   0.54271882 -23.35699622]\n",
            " [ -0.2266632    1.79648229 -31.9664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.75308086]\n",
            " [-2.01116415 -0.54271882 23.35699622]\n",
            " [ 0.2266632  -1.79648229 31.9664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.81892673]]\n",
            "action: 2\n",
            "next_state: [-0.18650456  0.00102103], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.81892673]\n",
            "target: 67.78586903967786\n",
            "td loss: [2.96694231]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.76234785]\n",
            " [  2.01116415   0.54271882 -23.36403009]\n",
            " [ -0.2266632    1.79648229 -31.9764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.76234785]\n",
            " [-2.01116415 -0.54271882 23.36403009]\n",
            " [ 0.2266632  -1.79648229 31.9764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.84007388]]\n",
            "action: 2\n",
            "next_state: [-1.8660231e-01 -9.7753509e-05], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.84007388]\n",
            "target: 67.80452228855685\n",
            "td loss: [2.96444841]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.77161176]\n",
            " [  2.01116415   0.54271882 -23.37106494]\n",
            " [ -0.2266632    1.79648229 -31.9864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.77161176]\n",
            " [-2.01116415 -0.54271882 23.37106494]\n",
            " [ 0.2266632  -1.79648229 31.9864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.86122032]]\n",
            "action: 2\n",
            "next_state: [-0.18781845 -0.00121615], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.86122032]\n",
            "target: 67.8207980994097\n",
            "td loss: [2.95957778]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.7808648 ]\n",
            " [  2.01116415   0.54271882 -23.37810735]\n",
            " [ -0.2266632    1.79648229 -31.9964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.7808648 ]\n",
            " [-2.01116415 -0.54271882 23.37810735]\n",
            " [ 0.2266632  -1.79648229 31.9964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.88236792]]\n",
            "action: 2\n",
            "next_state: [-0.19014814 -0.00232968], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.88236792]\n",
            "target: 67.83441907587644\n",
            "td loss: [2.95205115]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.79009909]\n",
            " [  2.01116415   0.54271882 -23.38516385]\n",
            " [ -0.2266632    1.79648229 -32.0064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.79009909]\n",
            " [-2.01116415 -0.54271882 23.38516385]\n",
            " [ 0.2266632  -1.79648229 32.0064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.90351849]]\n",
            "action: 2\n",
            "next_state: [-0.19358197 -0.00343384], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.90351849]\n",
            "target: 67.84484872599532\n",
            "td loss: [2.94133023]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.79930659]\n",
            " [  2.01116415   0.54271882 -23.39224092]\n",
            " [ -0.2266632    1.79648229 -32.0164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.79930659]\n",
            " [-2.01116415 -0.54271882 23.39224092]\n",
            " [ 0.2266632  -1.79648229 32.0164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.92467367]]\n",
            "action: 2\n",
            "next_state: [-0.19810595 -0.00452397], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.92467367]\n",
            "target: 67.85130157351583\n",
            "td loss: [2.9266279]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.80847902]\n",
            " [  2.01116415   0.54271882 -23.39934491]\n",
            " [ -0.2266632    1.79648229 -32.0264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.80847902]\n",
            " [-2.01116415 -0.54271882 23.39934491]\n",
            " [ 0.2266632  -1.79648229 32.0264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.94583491]]\n",
            "action: 2\n",
            "next_state: [-0.20370124 -0.0055953 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.94583491]\n",
            "target: 67.85276535275038\n",
            "td loss: [2.90693045]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.81760783]\n",
            " [  2.01116415   0.54271882 -23.40648204]\n",
            " [ -0.2266632    1.79648229 -32.0364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.81760783]\n",
            " [-2.01116415 -0.54271882 23.40648204]\n",
            " [ 0.2266632  -1.79648229 32.0364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.96700333]]\n",
            "action: 2\n",
            "next_state: [-0.21034408 -0.00664284], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.96700333]\n",
            "target: 67.8480492798805\n",
            "td loss: [2.88104595]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.8266841 ]\n",
            " [  2.01116415   0.54271882 -23.41365833]\n",
            " [ -0.2266632    1.79648229 -32.0464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.8266841 ]\n",
            " [-2.01116415 -0.54271882 23.41365833]\n",
            " [ 0.2266632  -1.79648229 32.0464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 64.98817977]]\n",
            "action: 2\n",
            "next_state: [-0.21800546 -0.00766138], reward: -1.0, term: False, trunc: True\n",
            "prediction: [64.98817977]\n",
            "target: 67.83582659039463\n",
            "td loss: [2.84764682]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.83569859]\n",
            " [  2.01116415   0.54271882 -23.42087959]\n",
            " [ -0.2266632    1.79648229 -32.0564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.83569859]\n",
            " [-2.01116415 -0.54271882 23.42087959]\n",
            " [ 0.2266632  -1.79648229 32.0564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.00936464]]\n",
            "action: 2\n",
            "next_state: [-0.22665097 -0.0086455 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.00936464]\n",
            "target: 67.81467765885463\n",
            "td loss: [2.80531302]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.84464169]\n",
            " [  2.01116415   0.54271882 -23.42815137]\n",
            " [ -0.2266632    1.79648229 -32.0664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.84464169]\n",
            " [-2.01116415 -0.54271882 23.42815137]\n",
            " [ 0.2266632  -1.79648229 32.0664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.03055796]]\n",
            "action: 2\n",
            "next_state: [-0.23624046 -0.00958951], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.03055796]\n",
            "target: 67.78315836942849\n",
            "td loss: [2.75260041]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.85350349]\n",
            " [  2.01116415   0.54271882 -23.4354789 ]\n",
            " [ -0.2266632    1.79648229 -32.0764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.85350349]\n",
            " [-2.01116415 -0.54271882 23.4354789 ]\n",
            " [ 0.2266632  -1.79648229 32.0764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.05175929]]\n",
            "action: 2\n",
            "next_state: [-0.24672796 -0.01048749], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.05175929]\n",
            "target: 67.73986117405627\n",
            "td loss: [2.68810189]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.86227381]\n",
            " [  2.01116415   0.54271882 -23.44286707]\n",
            " [ -0.2266632    1.79648229 -32.0864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.86227381]\n",
            " [-2.01116415 -0.54271882 23.44286707]\n",
            " [ 0.2266632  -1.79648229 32.0864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.07296774]]\n",
            "action: 2\n",
            "next_state: [-0.25806132 -0.01133335], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.07296774]\n",
            "target: 67.68348391832816\n",
            "td loss: [2.61051618]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.87094232]\n",
            " [  2.01116415   0.54271882 -23.45032035]\n",
            " [ -0.2266632    1.79648229 -32.0964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.87094232]\n",
            " [-2.01116415 -0.54271882 23.45032035]\n",
            " [ 0.2266632  -1.79648229 32.0964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.09418201]]\n",
            "action: 2\n",
            "next_state: [-0.27018213 -0.01212083], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.09418201]\n",
            "target: 67.61289516753344\n",
            "td loss: [2.51871316]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.87949864]\n",
            " [  2.01116415   0.54271882 -23.45784282]\n",
            " [ -0.2266632    1.79648229 -32.1064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.87949864]\n",
            " [-2.01116415 -0.54271882 23.45784282]\n",
            " [ 0.2266632  -1.79648229 32.1064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.11540034]]\n",
            "action: 2\n",
            "next_state: [-0.28302574 -0.01284359], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.11540034]\n",
            "target: 67.52720088839654\n",
            "td loss: [2.41180055]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.8879325 ]\n",
            " [  2.01116415   0.54271882 -23.46543803]\n",
            " [ -0.2266632    1.79648229 -32.1164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.8879325 ]\n",
            " [-2.01116415 -0.54271882 23.46543803]\n",
            " [ 0.2266632  -1.79648229 32.1164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.13662063]]\n",
            "action: 2\n",
            "next_state: [-0.296521   -0.01349528], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.13662063]\n",
            "target: 67.42580876664555\n",
            "td loss: [2.28918814]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.8962339 ]\n",
            " [  2.01116415   0.54271882 -23.47310903]\n",
            " [ -0.2266632    1.79648229 -32.1264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.8962339 ]\n",
            " [-2.01116415 -0.54271882 23.47310903]\n",
            " [ 0.2266632  -1.79648229 32.1264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.15784043]]\n",
            "action: 2\n",
            "next_state: [-0.31059068 -0.01406966], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.15784043]\n",
            "target: 67.30847645200015\n",
            "td loss: [2.15063602]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.90439334]\n",
            " [  2.01116415   0.54271882 -23.48085833]\n",
            " [ -0.2266632    1.79648229 -32.1364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.90439334]\n",
            " [-2.01116415 -0.54271882 23.48085833]\n",
            " [ 0.2266632  -1.79648229 32.1364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.17905705]]\n",
            "action: 2\n",
            "next_state: [-0.32515135 -0.01456069], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.17905705]\n",
            "target: 67.17535458165928\n",
            "td loss: [1.99629753]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.91240195]\n",
            " [  2.01116415   0.54271882 -23.48868782]\n",
            " [ -0.2266632    1.79648229 -32.1464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.91240195]\n",
            " [-2.01116415 -0.54271882 23.48868782]\n",
            " [ 0.2266632  -1.79648229 32.1464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.20026762]]\n",
            "action: 2\n",
            "next_state: [-0.34011403 -0.01496267], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.20026762]\n",
            "target: 67.02700115976587\n",
            "td loss: [1.82673354]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.92025177]\n",
            " [  2.01116415   0.54271882 -23.49659882]\n",
            " [ -0.2266632    1.79648229 -32.1564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.92025177]\n",
            " [-2.01116415 -0.54271882 23.49659882]\n",
            " [ 0.2266632  -1.79648229 32.1564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.22146917]]\n",
            "action: 2\n",
            "next_state: [-0.35538438 -0.01527036], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.22146917]\n",
            "target: 66.86439787634413\n",
            "td loss: [1.64292871]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.92793591]\n",
            " [  2.01116415   0.54271882 -23.50459199]\n",
            " [ -0.2266632    1.79648229 -32.1664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.92793591]\n",
            " [-2.01116415 -0.54271882 23.50459199]\n",
            " [ 0.2266632  -1.79648229 32.1664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.24265872]]\n",
            "action: 2\n",
            "next_state: [-0.3708635  -0.01547909], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.24265872]\n",
            "target: 66.68893480499852\n",
            "td loss: [1.44627608]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.93544874]\n",
            " [  2.01116415   0.54271882 -23.51266737]\n",
            " [ -0.2266632    1.79648229 -32.1764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.93544874]\n",
            " [-2.01116415 -0.54271882 23.51266737]\n",
            " [ 0.2266632  -1.79648229 32.1764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.2638334 ]]\n",
            "action: 2\n",
            "next_state: [-0.38644844 -0.01558494], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.2638334]\n",
            "target: 66.50238857509808\n",
            "td loss: [1.23855518]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.94278606]\n",
            " [  2.01116415   0.54271882 -23.52082439]\n",
            " [ -0.2266632    1.79648229 -32.1864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.94278606]\n",
            " [-2.01116415 -0.54271882 23.52082439]\n",
            " [ 0.2266632  -1.79648229 32.1864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.2849905 ]]\n",
            "action: 2\n",
            "next_state: [-0.4020332  -0.01558479], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.2849905]\n",
            "target: 66.30685799425622\n",
            "td loss: [1.0218675]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.94994525]\n",
            " [  2.01116415   0.54271882 -23.52906182]\n",
            " [ -0.2266632    1.79648229 -32.1964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.94994525]\n",
            " [-2.01116415 -0.54271882 23.52906182]\n",
            " [ 0.2266632  -1.79648229 32.1964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.30612756]]\n",
            "action: 2\n",
            "next_state: [-0.41750968 -0.01547646], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.30612756]\n",
            "target: 66.10472735703769\n",
            "td loss: [0.7985998]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.95692533]\n",
            " [  2.01116415   0.54271882 -23.53737787]\n",
            " [ -0.2266632    1.79648229 -32.2064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.95692533]\n",
            " [-2.01116415 -0.54271882 23.53737787]\n",
            " [ 0.2266632  -1.79648229 32.2064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.32724245]]\n",
            "action: 2\n",
            "next_state: [-0.43276843 -0.01525876], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.32724245]\n",
            "target: 65.8985812230322\n",
            "td loss: [0.57133878]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.96372705]\n",
            " [  2.01116415   0.54271882 -23.54577016]\n",
            " [ -0.2266632    1.79648229 -32.2164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.96372705]\n",
            " [-2.01116415 -0.54271882 23.54577016]\n",
            " [ 0.2266632  -1.79648229 32.2164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.34833342]]\n",
            "action: 2\n",
            "next_state: [-0.44770002 -0.01493159], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.34833342]\n",
            "target: 65.69113718307881\n",
            "td loss: [0.34280377]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.97035288]\n",
            " [  2.01116415   0.54271882 -23.55423578]\n",
            " [ -0.2266632    1.79648229 -32.2264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.97035288]\n",
            " [-2.01116415 -0.54271882 23.55423578]\n",
            " [ 0.2266632  -1.79648229 32.2264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.36939914]]\n",
            "action: 2\n",
            "next_state: [-0.46219596 -0.01449592], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.36939914]\n",
            "target: 65.48517425396942\n",
            "td loss: [0.11577511]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.97680703]\n",
            " [  2.01116415   0.54271882 -23.56277137]\n",
            " [ -0.2266632    1.79648229 -32.2364286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.97680703]\n",
            " [-2.01116415 -0.54271882 23.56277137]\n",
            " [ 0.2266632  -1.79648229 32.2364286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.39043875]]\n",
            "action: 2\n",
            "next_state: [-0.4761498  -0.01395385], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.39043875]\n",
            "target: 65.28344847470838\n",
            "td loss: [-0.10699028]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.98309533]\n",
            " [  2.01116415   0.54271882 -23.57137309]\n",
            " [ -0.2266632    1.79648229 -32.2464286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.98309533]\n",
            " [-2.01116415 -0.54271882 23.57137309]\n",
            " [ 0.2266632  -1.79648229 32.2464286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.41145184]]\n",
            "action: 2\n",
            "next_state: [-0.48945832 -0.01330851], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.41145184]\n",
            "target: 65.08864833939982\n",
            "td loss: [-0.3228035]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.98922521]\n",
            " [  2.01116415   0.54271882 -23.58003675]\n",
            " [ -0.2266632    1.79648229 -32.2564286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.98922521]\n",
            " [-2.01116415 -0.54271882 23.58003675]\n",
            " [ 0.2266632  -1.79648229 32.2564286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.43243847]]\n",
            "action: 2\n",
            "next_state: [-0.50202245 -0.01256412], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.43243847]\n",
            "target: 64.90331808730437\n",
            "td loss: [-0.52912038]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -22.99520551]\n",
            " [  2.01116415   0.54271882 -23.58875782]\n",
            " [ -0.2266632    1.79648229 -32.2664286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  22.99520551]\n",
            " [-2.01116415 -0.54271882 23.58875782]\n",
            " [ 0.2266632  -1.79648229 32.2664286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.45339917]]\n",
            "action: 2\n",
            "next_state: [-0.5137482  -0.01172583], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.45339917]\n",
            "target: 64.72983026461227\n",
            "td loss: [-0.72356891]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.00104641]\n",
            " [  2.01116415   0.54271882 -23.59753152]\n",
            " [ -0.2266632    1.79648229 -32.2764286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.00104641]\n",
            " [-2.01116415 -0.54271882 23.59753152]\n",
            " [ 0.2266632  -1.79648229 32.2764286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.47433491]]\n",
            "action: 2\n",
            "next_state: [-0.52454793 -0.0107997 ], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.47433491]\n",
            "target: 64.57034430497959\n",
            "td loss: [-0.90399061]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.00675924]\n",
            " [  2.01116415   0.54271882 -23.60635284]\n",
            " [ -0.2266632    1.79648229 -32.2864286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.00675924]\n",
            " [-2.01116415 -0.54271882 23.60635284]\n",
            " [ 0.2266632  -1.79648229 32.2864286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.49524706]]\n",
            "action: 2\n",
            "next_state: [-0.5343405  -0.00979258], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.49524706]\n",
            "target: 64.42680073955424\n",
            "td loss: [-1.06844632]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.01235636]\n",
            " [  2.01116415   0.54271882 -23.6152166 ]\n",
            " [ -0.2266632    1.79648229 -32.2964286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.01235636]\n",
            " [-2.01116415 -0.54271882 23.6152166 ]\n",
            " [ 0.2266632  -1.79648229 32.2964286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.51613736]]\n",
            "action: 2\n",
            "next_state: [-0.54305255 -0.00871203], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.51613736]\n",
            "target: 64.30088748013736\n",
            "td loss: [-1.21524988]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.01785098]\n",
            " [  2.01116415   0.54271882 -23.62411748]\n",
            " [ -0.2266632    1.79648229 -32.3064286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.01785098]\n",
            " [-2.01116415 -0.54271882 23.62411748]\n",
            " [ 0.2266632  -1.79648229 32.3064286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.53700789]]\n",
            "action: 2\n",
            "next_state: [-0.55061877 -0.00756621], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.53700789]\n",
            "target: 64.19406550923715\n",
            "td loss: [-1.34294239]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.02325706]\n",
            " [  2.01116415   0.54271882 -23.63305011]\n",
            " [ -0.2266632    1.79648229 -32.3164286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.02325706]\n",
            " [-2.01116415 -0.54271882 23.63305011]\n",
            " [ 0.2266632  -1.79648229 32.3164286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y\n",
            "[[-1.94709931 -3.24170484 65.55786105]]\n",
            "action: 2\n",
            "next_state: [-0.5569825  -0.00636378], reward: -1.0, term: False, trunc: True\n",
            "prediction: [65.55786105]\n",
            "target: 64.10756262271272\n",
            "td loss: [-1.45029843]\n",
            "td gradient\n",
            "-1\n",
            "y gradient\n",
            "[[  0.69746489   1.8421081  -23.02858913]\n",
            " [  2.01116415   0.54271882 -23.64200901]\n",
            " [ -0.2266632    1.79648229 -32.3264286 ]]\n",
            "updated weights\n",
            "[[-0.69746489 -1.8421081  23.02858913]\n",
            " [-2.01116415 -0.54271882 23.64200901]\n",
            " [ 0.2266632  -1.79648229 32.3264286 ]]\n",
            "z\n",
            "[[0.51915389 0.90080708 1.        ]]\n",
            "y"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-dae30b971d42>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# compute the output of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# select the correct action using argmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "iterations = 1000\n",
        "for n in range(iterations):\n",
        "    state, _ = agent.env.reset()\n",
        "    while not term or trunc:\n",
        "        # transform state using RBF\n",
        "        z = agent.learning_model.transformer.transform(state)\n",
        "        print('z')\n",
        "        print(z)\n",
        "        # compute the output of the model\n",
        "        y = agent.learning_model.layers[0].forward(z)\n",
        "        print('y')\n",
        "        print(y)\n",
        "        # select the correct action using argmax\n",
        "        action = np.argmax(y)\n",
        "        print(f'action: {action}')\n",
        "        # take action in environment\n",
        "        next_state, reward, term, trunc, _ = agent.env.step(action)\n",
        "        print(f'next_state: {next_state}, reward: {reward}, term: {term}, trunc: {trunc}')\n",
        "        # set prediction\n",
        "        prediction = y[:, action]\n",
        "        print(f'prediction: {prediction}')\n",
        "        # calculate target\n",
        "        target = reward + agent.gamma * np.max(agent.learning_model.forward(next_state))\n",
        "        print(f'target: {target}')\n",
        "        # calculate TD loss\n",
        "        td = agent.learning_model.loss.forward(target, prediction)\n",
        "        print(f'td loss: {td}')\n",
        "        # calculate gradients and update weights\n",
        "        td_gradient = agent.learning_model.loss.backward(target, prediction)\n",
        "        print('td gradient')\n",
        "        print(td_gradient)\n",
        "        output_gradient = agent.learning_model.backward(td_gradient, agent.learning_rate, action)\n",
        "        print('y gradient')\n",
        "        print(output_gradient)\n",
        "        print('updated weights')\n",
        "        print(agent.learning_model.layers[0].W)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUWRvvKYpxR1",
        "outputId": "001f8f52-5919-429f-d128-5f274391546e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.38355333, 0.98950358]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.learning_model.transformer.transform(next_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkLfSUM8TqjF",
        "outputId": "32632543-ba0c-4000-dae8-bad2be027f8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.2191539 ,  1.30315005,  0.65683389],\n",
              "       [-0.84340084,  0.63294656,  0.92864706]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.learning_model.layers[0].W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZVF8GZ4u3-E",
        "outputId": "1691f062-68d0-4eba-9774-69dcfdb1ad00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.75049094,  1.13739274,  1.17083042]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_next = np.dot(agent.learning_model.transformer.transform(next_state), np.array([[ 0.2191539, 1.30698558, 0.65683389],\n",
        "          [-0.84340084, 0.6428416, 0.92864706]]))\n",
        "Y_next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSbH58hTvVaY",
        "outputId": "6fafe4ef-95da-4e97-9588-d97fc0d4810d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15912211203287474"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target\n",
        "target = reward + agent.gamma * np.max(Y_next)\n",
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFXqtF3Rx6vH"
      },
      "outputs": [],
      "source": [
        "# run through an episode at a time and analyze outputs to determine error\n",
        "\n",
        "## setup test ##\n",
        "\n",
        "# instantiate environment\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "# generate an array of sample states to use as X\n",
        "X = np.array([env.observation_space.sample() for _ in range(10000)])\n",
        "# create a simple RBF using 2 kernels, each with one center but a different variance\n",
        "rbf_test = RadialBasisFunction([RBF_kernel(X, 100, 0.5),\n",
        "                                RBF_kernel(X, 100, 1.0),\n",
        "                                RBF_kernel(X, 100, 1.5),\n",
        "                                RBF_kernel(X, 100, 2.0)]\n",
        "                              )\n",
        "# print rbf kernel info\n",
        "for i,kernel in enumerate(rbf_test.RBF_kernels):\n",
        "    print(f'kernel {i} center: {kernel.centers}')\n",
        "    print(f'kernel {i} variance: {kernel.sigma}')\n",
        "\n",
        "# create a model\n",
        "model = Model([DenseLayer(400, 3)], TemporalDifferenceLoss(), transformer=rbf_test)\n",
        "\n",
        "# create td loss object\n",
        "tdl_test =\n",
        "\n",
        "\n",
        "# create an agent\n",
        "agent = Agent(env, model, 0.01, 0.99, 0.1)\n",
        "\n",
        "print('initial weights')\n",
        "print(layer.W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5JfEBqJvQm4"
      },
      "source": [
        "## Use Sci kit learn library to solve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txO-NYPyvVW1"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import FeatureUnion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHz59aA7o3UV"
      },
      "outputs": [],
      "source": [
        "# re-code a new agent class that uses scikit learn library\n",
        "class RBF_Mountain_car_Agent:\n",
        "    def __init__(self):\n",
        "        self.env = None\n",
        "        self.scaler = None\n",
        "        self.rbf_union = None\n",
        "        self.models = None\n",
        "        self.learning_rate = None\n",
        "        self.gamma = None\n",
        "        self.epsilon = None\n",
        "        self.epsilon_decay = None\n",
        "        self.min_epsilon = None\n",
        "        self.RBFSamplers = None\n",
        "        self.n_steps = None\n",
        "\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Get action from the Q-table.\n",
        "\n",
        "        Parameters:\n",
        "        -state: int of length n_features representing the assigned bin of each feature\n",
        "\n",
        "        Returns:\n",
        "        -action: random or optimal action\n",
        "        \"\"\"\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return self.env.action_space.sample()\n",
        "        else:\n",
        "            return np.argmax(self.predict(state))\n",
        "\n",
        "    def run_episode(self):\n",
        "        \"\"\"\n",
        "        Run an episode of the agent.\n",
        "\n",
        "        Returns:\n",
        "        -tot_reward: Total reward for the episode.\n",
        "        \"\"\"\n",
        "        state, _ = self.env.reset()\n",
        "        # print(f'state shape: {state.shape}')\n",
        "        if len(state.shape) == 1:\n",
        "            state = state.reshape(1,-1)\n",
        "            # print(f'state reshaped to: {state.shape}')\n",
        "        done = False\n",
        "        tot_reward = 0\n",
        "        tot_loss = 0\n",
        "        sar_tracker = []\n",
        "        while not done:\n",
        "            action = self.get_action(state)\n",
        "            # decay epsilon\n",
        "            next_state, reward, term, trunc, _ = self.env.step(action)\n",
        "            # print(f'next state shape: {next_state.shape}')\n",
        "            if len(next_state.shape) == 1:\n",
        "                next_state = next_state.reshape(1,-1)\n",
        "                # print(f'reshaped next state shape to: {next_state.shape}')\n",
        "            sar_tracker.append((state, action, reward))\n",
        "            tot_reward += reward\n",
        "            # calculate TD loss and add to tot_loss\n",
        "            tot_loss += (reward + self.gamma * np.max(self.predict(next_state))) - self.predict(state)[action]\n",
        "            if len(sar_tracker) == self.n_steps:\n",
        "                self.update(sar_tracker, next_state)\n",
        "                # remove first state from tracker as Q for that state has been updated\n",
        "                sar_tracker.remove(sar_tracker[0])\n",
        "\n",
        "            state = next_state\n",
        "            if term or trunc:\n",
        "                done = True\n",
        "        return tot_reward, tot_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, env, episodes, learning_rate, gamma, epsilon, epsilon_decay, min_epsilon, n_steps, scaler=False, RBFSamplers=None):\n",
        "        \"\"\"\n",
        "        Train the agent for a number of episodes.\n",
        "\n",
        "        Parameters:\n",
        "        -episodes: Number of episodes to train for.\n",
        "        -learning_rate: learning rate of the regression model\n",
        "        -gamma: Discount factor.\n",
        "        -epsilon: Epsilon greedy random action threshold.\n",
        "        -RBFSamplers: A list of (str, RBFSampler) tuples, where the str is the name of the RBF, and RBFSampler is the an sklearn.kernel_approximation.RBFSampler object\n",
        "        -n_steps: number of steps taken before updating Q value of a (state, action) pair\n",
        "\n",
        "        Returns:\n",
        "        -rewards: List of rewards per episode.\n",
        "        -losses: List of losses per episode.\n",
        "        \"\"\"\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.RBFSamplers = RBFSamplers\n",
        "        self.n_steps = n_steps\n",
        "        self.env = env\n",
        "        # draw samples from env to fit scaler and rbf kernels\n",
        "        X = np.array([self.env.observation_space.sample() for _ in range(10000)])\n",
        "        # create standard scaler\n",
        "        if self.scaler:\n",
        "            self.scaler = StandardScaler()\n",
        "            # fit scaler to samples\n",
        "            X = self.scaler.fit_transform(X)\n",
        "        if self.RBFSamplers:\n",
        "            # create a FeatureUnion object of RBFSamplers\n",
        "            self.rbf_union = FeatureUnion([*self.RBFSamplers])\n",
        "            self.rbf_union.fit(X)\n",
        "        self.models = [SGDRegressor(max_iter=episodes, eta0=self.learning_rate) for _ in range(self.env.action_space.n)]\n",
        "        # run partial fit on each to initialize model weights to make initial target and prediction values\n",
        "        for m in self.models:\n",
        "            m.partial_fit(self.rbf_union.transform([self.env.reset()[0]]), [0])\n",
        "\n",
        "        rewards = []\n",
        "        losses = []\n",
        "        for i in range(episodes):\n",
        "            reward, loss = self.run_episode()\n",
        "            rewards.append(reward)\n",
        "            losses.append(loss)\n",
        "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "            if i % 1 == 0:\n",
        "                print(f\"Episode {i}; episode reward: {rewards[-1]}; AVG/10 reward: {np.mean(rewards[-10:])}; AVG/10 loss: {np.mean(losses[-10:])}\")\n",
        "\n",
        "        return rewards, losses\n",
        "\n",
        "    def predict(self, state):\n",
        "        \"\"\"\n",
        "        returns predictions.\n",
        "        Parameters:\n",
        "        -state: state to run prediction on.\n",
        "\n",
        "        Returns:\n",
        "        -predictions:\n",
        "        \"\"\"\n",
        "        if self.scaler:\n",
        "            state = self.scaler.transform(state)\n",
        "        if self.RBFSamplers:\n",
        "            state = self.rbf_union.transform(state)\n",
        "        predictions = np.array([m.predict(state)[0] for m in self.models])\n",
        "        return predictions\n",
        "\n",
        "    def update(self, sar_tracker, next_state):\n",
        "        \"\"\"\n",
        "        updates the model weights using the sar_tracker array.\n",
        "        Parameters:\n",
        "        -sar_tracker: tracks the (state, action, reward) combinations used in an update.\n",
        "\n",
        "        Returns:\n",
        "        -None\n",
        "        \"\"\"\n",
        "        # get action taken at next state\n",
        "        action = self.get_action(next_state)\n",
        "        # predict return taking action at the next state\n",
        "        # target = agent.models[action].predict([next_state])\n",
        "        target = self.predict(next_state)[action]\n",
        "        # multiply target by discount factor (gamma) which is gamma^n_steps\n",
        "        target = target*self.gamma**len(sar_tracker)\n",
        "        # add discounted return to the sum of rewards from previous states in tracker\n",
        "        target += np.sum([r*self.gamma**i for i,(s,a,r) in enumerate(sar_tracker)])\n",
        "        # grab first state from sar_tracker to be used as 'x' value in partial fit\n",
        "        # function of model\n",
        "        s,a,r = sar_tracker[0]\n",
        "        if self.scaler:\n",
        "            s = self.scaler.transform([s])\n",
        "        if self.RBFSamplers:\n",
        "            s = self.rbf_union.transform(s)\n",
        "        self.models[action].partial_fit(s, [target])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdhWoulTqVrw"
      },
      "outputs": [],
      "source": [
        "def create_rbf_samplers(sigmas, n_components):\n",
        "    rbf_samplers = []\n",
        "    for e,(s,n) in enumerate(zip(sigmas, n_components)):\n",
        "        rbf_samplers.append((f'rbf{e}',RBFSampler(gamma=s, n_components=n)))\n",
        "    return rbf_samplers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOVre50YqVkR"
      },
      "outputs": [],
      "source": [
        "rbf_samplers = create_rbf_samplers([1.0], [50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGcnkcZqklC",
        "outputId": "6a2f8e4d-49d0-4f87-9cbf-09ea446522cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('rbf0', RBFSampler(n_components=50))]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rbf_samplers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMesc7UZ3qIM"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzS_D3pQjf0x",
        "outputId": "f13c02e9-fd14-4713-c0a3-841d3bc8ac81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV-MXnMBiNjO"
      },
      "outputs": [],
      "source": [
        "agent = RBF_Mountain_car_Agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xOkKxF55zpm",
        "outputId": "bbfeeea3-f9c5-4f5e-cdc2-5f8d7032a7a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0; episode reward: 8.0; AVG/10 reward: 8.0; AVG/10 loss: 8.0\n",
            "Episode 1; episode reward: 9.0; AVG/10 reward: 8.5; AVG/10 loss: 8.5\n",
            "Episode 2; episode reward: 11.0; AVG/10 reward: 9.333333333333334; AVG/10 loss: 9.334751400180389\n",
            "Episode 3; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 8.952168183486615\n",
            "Episode 4; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 9.127480628120907\n",
            "Episode 5; episode reward: 10.0; AVG/10 reward: 9.333333333333334; AVG/10 loss: 9.230378805205687\n",
            "Episode 6; episode reward: 10.0; AVG/10 reward: 9.428571428571429; AVG/10 loss: 9.292699815942607\n",
            "Episode 7; episode reward: 9.0; AVG/10 reward: 9.375; AVG/10 loss: 9.203426752500416\n",
            "Episode 8; episode reward: 11.0; AVG/10 reward: 9.555555555555555; AVG/10 loss: 9.359496245376704\n",
            "Episode 9; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 9.371518425968805\n",
            "Episode 10; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 9.512823927043495\n",
            "Episode 11; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 9.444076888506197\n",
            "Episode 12; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 9.174357213015783\n",
            "Episode 13; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 9.22369251149773\n",
            "Episode 14; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 9.17540797761755\n",
            "Episode 15; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 9.128838712804754\n",
            "Episode 16; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 9.08368998574689\n",
            "Episode 17; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 8.936436756435155\n",
            "Episode 18; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 8.584789345137859\n",
            "Episode 19; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 8.345521695900326\n",
            "Episode 20; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 8.219733847724711\n",
            "Episode 21; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 8.30469143383962\n",
            "Episode 22; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 8.280156777572014\n",
            "Episode 23; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 8.361245787001007\n",
            "Episode 24; episode reward: 11.0; AVG/10 reward: 9.3; AVG/10 loss: 8.434495991738231\n",
            "Episode 25; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 8.297500753410436\n",
            "Episode 26; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 8.27513404079993\n",
            "Episode 27; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 8.45664433111855\n",
            "Episode 28; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 8.632714535606045\n",
            "Episode 29; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 8.697850445337284\n",
            "Episode 30; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 8.762224715207164\n",
            "Episode 31; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 8.726048499659912\n",
            "Episode 32; episode reward: 8.0; AVG/10 reward: 9.7; AVG/10 loss: 8.578105097196223\n",
            "Episode 33; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 8.537289088515191\n",
            "Episode 34; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 8.292459320099724\n",
            "Episode 35; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 8.262868241660607\n",
            "Episode 36; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 8.231714335505298\n",
            "Episode 37; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 8.094145936661203\n",
            "Episode 38; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 8.072652723964794\n",
            "Episode 39; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 8.157996760039033\n",
            "Episode 40; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 8.131048370454295\n",
            "Episode 41; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 8.101548968902156\n",
            "Episode 42; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 8.072016963259285\n",
            "Episode 43; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.937653764257513\n",
            "Episode 44; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 8.017613313630704\n",
            "Episode 45; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 8.096634929616782\n",
            "Episode 46; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 7.966310166470275\n",
            "Episode 47; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 7.830679797515579\n",
            "Episode 48; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.695292323656669\n",
            "Episode 49; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 7.566509453628564\n",
            "Episode 50; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 7.441011641724271\n",
            "Episode 51; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 7.42693031357017\n",
            "Episode 52; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 7.632947115798241\n",
            "Episode 53; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.611987487604516\n",
            "Episode 54; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 7.5959126486551725\n",
            "Episode 55; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 7.362629178943027\n",
            "Episode 56; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 7.452374579909408\n",
            "Episode 57; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.65602262598707\n",
            "Episode 58; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.640310649769606\n",
            "Episode 59; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.619831662047709\n",
            "Episode 60; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 7.709950046410863\n",
            "Episode 61; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.571083970811253\n",
            "Episode 62; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.545472432151319\n",
            "Episode 63; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.533978526515379\n",
            "Episode 64; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.4046562588280835\n",
            "Episode 65; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.494623626724426\n",
            "Episode 66; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.366733289697095\n",
            "Episode 67; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 7.3554179371244235\n",
            "Episode 68; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.33445135148356\n",
            "Episode 69; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 7.207704792585567\n",
            "Episode 70; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 7.091765109573288\n",
            "Episode 71; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 6.9806471648544175\n",
            "Episode 72; episode reward: 8.0; AVG/10 reward: 8.8; AVG/10 loss: 6.760242513856673\n",
            "Episode 73; episode reward: 10.0; AVG/10 reward: 8.9; AVG/10 loss: 6.862490401765982\n",
            "Episode 74; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 6.850772387363845\n",
            "Episode 75; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 6.959434452487355\n",
            "Episode 76; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 6.83849377992983\n",
            "Episode 77; episode reward: 9.0; AVG/10 reward: 8.8; AVG/10 loss: 6.71931798308389\n",
            "Episode 78; episode reward: 9.0; AVG/10 reward: 8.8; AVG/10 loss: 6.717109954301715\n",
            "Episode 79; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 6.8260789639037025\n",
            "Episode 80; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 6.920867823803446\n",
            "Episode 81; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 7.1324064543296375\n",
            "Episode 82; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.3334842777429206\n",
            "Episode 83; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.205247072106796\n",
            "Episode 84; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 7.409972359187146\n",
            "Episode 85; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.275823450553014\n",
            "Episode 86; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 7.365247605210297\n",
            "Episode 87; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 7.2323712468679275\n",
            "Episode 88; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.214027009630156\n",
            "Episode 89; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.19809155105114\n",
            "Episode 90; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.185442472490699\n",
            "Episode 91; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.166799959747033\n",
            "Episode 92; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 7.039636617482168\n",
            "Episode 93; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 7.138524474294561\n",
            "Episode 94; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 6.796626995725868\n",
            "Episode 95; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 6.791148795700624\n",
            "Episode 96; episode reward: 11.0; AVG/10 reward: 9.3; AVG/10 loss: 6.997549942057648\n",
            "Episode 97; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 7.202483158025167\n",
            "Episode 98; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 7.074982760798828\n",
            "Episode 99; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 7.051106430267522\n",
            "Episode 100; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 6.80346362293331\n",
            "Episode 101; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 6.786781603255143\n",
            "Episode 102; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.77676474109758\n",
            "Episode 103; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 6.755890813184604\n",
            "Episode 104; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.849714405209264\n",
            "Episode 105; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.933678110587429\n",
            "Episode 106; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.692928524160382\n",
            "Episode 107; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 6.6815509628557805\n",
            "Episode 108; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.780486357417857\n",
            "Episode 109; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 6.980292058067278\n",
            "Episode 110; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 7.1819431233982325\n",
            "Episode 111; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 7.042534607725559\n",
            "Episode 112; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 7.125695448719656\n",
            "Episode 113; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 7.105921061314058\n",
            "Episode 114; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 7.080192315719617\n",
            "Episode 115; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 7.0573106032831205\n",
            "Episode 116; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 6.928587654768862\n",
            "Episode 117; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 6.784177589607597\n",
            "Episode 118; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 6.757796898677382\n",
            "Episode 119; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.514688093460566\n",
            "Episode 120; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.396043820955673\n",
            "Episode 121; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 6.496193484278817\n",
            "Episode 122; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.375539977147939\n",
            "Episode 123; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 6.1394577402704105\n",
            "Episode 124; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 6.137723191403476\n",
            "Episode 125; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 6.019318738421257\n",
            "Episode 126; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 6.014753100214385\n",
            "Episode 127; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 6.136873038073561\n",
            "Episode 128; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 6.241991770583765\n",
            "Episode 129; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 6.240433515951177\n",
            "Episode 130; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 6.227159755995183\n",
            "Episode 131; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 6.225324731618075\n",
            "Episode 132; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 6.21747451056023\n",
            "Episode 133; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.330018359198716\n",
            "Episode 134; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.324228048942156\n",
            "Episode 135; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 6.202295536812901\n",
            "Episode 136; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 6.523597384997997\n",
            "Episode 137; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.50525403642659\n",
            "Episode 138; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.379827946754601\n",
            "Episode 139; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.4839366740302555\n",
            "Episode 140; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 6.474101719089317\n",
            "Episode 141; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.3383230562270985\n",
            "Episode 142; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.327061581186835\n",
            "Episode 143; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 6.1955337445701275\n",
            "Episode 144; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 6.29276497222425\n",
            "Episode 145; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 6.385764507612587\n",
            "Episode 146; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 6.260877239574162\n",
            "Episode 147; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 6.144166564102134\n",
            "Episode 148; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 6.248259971216472\n",
            "Episode 149; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 6.238326570243514\n",
            "Episode 150; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.335044906969269\n",
            "Episode 151; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 6.4407938924540975\n",
            "Episode 152; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 6.53325789217038\n",
            "Episode 153; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 6.625098188435461\n",
            "Episode 154; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 6.373304212248268\n",
            "Episode 155; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 6.486574889728591\n",
            "Episode 156; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 6.481603303599925\n",
            "Episode 157; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 6.57146767738814\n",
            "Episode 158; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 6.3133198028431305\n",
            "Episode 159; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 6.170786234987332\n",
            "Episode 160; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 6.048121471276081\n",
            "Episode 161; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 5.806105802304533\n",
            "Episode 162; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 5.7937402191128164\n",
            "Episode 163; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.788209444380017\n",
            "Episode 164; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.891121075282959\n",
            "Episode 165; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 5.876134569588604\n",
            "Episode 166; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.731598687583413\n",
            "Episode 167; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 5.486029232796021\n",
            "Episode 168; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 5.7207159026522\n",
            "Episode 169; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 5.8344516384997025\n",
            "Episode 170; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.818785393588987\n",
            "Episode 171; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.029415069643646\n",
            "Episode 172; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 6.016637856184543\n",
            "Episode 173; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 6.114734053391223\n",
            "Episode 174; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 5.983567933908196\n",
            "Episode 175; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 5.735691165903313\n",
            "Episode 176; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.7262862820406255\n",
            "Episode 177; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.94394998315292\n",
            "Episode 178; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.815323634703357\n",
            "Episode 179; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.801875550821076\n",
            "Episode 180; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.897827193536892\n",
            "Episode 181; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.89074011643293\n",
            "Episode 182; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 5.654815805649698\n",
            "Episode 183; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.524417209373747\n",
            "Episode 184; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.630292414779332\n",
            "Episode 185; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.743232381581883\n",
            "Episode 186; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.745404752757998\n",
            "Episode 187; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.612944601091944\n",
            "Episode 188; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.717174471226547\n",
            "Episode 189; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.596336506477022\n",
            "Episode 190; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 5.59216746412528\n",
            "Episode 191; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.4749457082495905\n",
            "Episode 192; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.571687590984752\n",
            "Episode 193; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.6795361137866\n",
            "Episode 194; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 5.551055972907479\n",
            "Episode 195; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 5.4146406573580785\n",
            "Episode 196; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 5.287061176139515\n",
            "Episode 197; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 5.513336320940978\n",
            "Episode 198; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 5.261035394094057\n",
            "Episode 199; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 5.2560724577574005\n",
            "Episode 200; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 5.131676155148407\n",
            "Episode 201; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 5.114031802853267\n",
            "Episode 202; episode reward: 8.0; AVG/10 reward: 8.8; AVG/10 loss: 4.990234706699144\n",
            "Episode 203; episode reward: 10.0; AVG/10 reward: 8.8; AVG/10 loss: 4.987056489170376\n",
            "Episode 204; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 5.221621229788797\n",
            "Episode 205; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.334171836252512\n",
            "Episode 206; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.444196331132799\n",
            "Episode 207; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 5.218670546958791\n",
            "Episode 208; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 5.452908626368599\n",
            "Episode 209; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.545220655142943\n",
            "Episode 210; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.655718328730629\n",
            "Episode 211; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 5.52834285914747\n",
            "Episode 212; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 5.750031725772052\n",
            "Episode 213; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 5.500860567838035\n",
            "Episode 214; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 5.253643009986615\n",
            "Episode 215; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.244560704990194\n",
            "Episode 216; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.22403262334318\n",
            "Episode 217; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 5.091894080240737\n",
            "Episode 218; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 5.084808866503897\n",
            "Episode 219; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 4.959362813369546\n",
            "Episode 220; episode reward: 8.0; AVG/10 reward: 8.7; AVG/10 loss: 4.714750308218781\n",
            "Episode 221; episode reward: 10.0; AVG/10 reward: 8.9; AVG/10 loss: 4.952979388077119\n",
            "Episode 222; episode reward: 10.0; AVG/10 reward: 8.9; AVG/10 loss: 4.955513994572792\n",
            "Episode 223; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 5.065411458601242\n",
            "Episode 224; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.172841757532131\n",
            "Episode 225; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.157142584272908\n",
            "Episode 226; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.1691113621748785\n",
            "Episode 227; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.389860894269303\n",
            "Episode 228; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.3782152011958795\n",
            "Episode 229; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.4895925558389305\n",
            "Episode 230; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 5.476514485668647\n",
            "Episode 231; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.336564738840658\n",
            "Episode 232; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.216850926411089\n",
            "Episode 233; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.202092790241066\n",
            "Episode 234; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.313923286203919\n",
            "Episode 235; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.304827943854987\n",
            "Episode 236; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.291319173879112\n",
            "Episode 237; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.157632642629167\n",
            "Episode 238; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 5.038284423445928\n",
            "Episode 239; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 5.03503011341642\n",
            "Episode 240; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.272548478656313\n",
            "Episode 241; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.39509654010534\n",
            "Episode 242; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 5.37962591832058\n",
            "Episode 243; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 5.387369227666668\n",
            "Episode 244; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 5.255363399217702\n",
            "Episode 245; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 5.13880174146056\n",
            "Episode 246; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 5.137231411110443\n",
            "Episode 247; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 5.2523344257706635\n",
            "Episode 248; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 5.123494418673369\n",
            "Episode 249; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 5.11242804001487\n",
            "Episode 250; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 4.857186054322434\n",
            "Episode 251; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 4.72324047723381\n",
            "Episode 252; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 4.708089811991684\n",
            "Episode 253; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 4.804876988375099\n",
            "Episode 254; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 4.81015528241974\n",
            "Episode 255; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.924679004317718\n",
            "Episode 256; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.913289805108326\n",
            "Episode 257; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 5.020634085858221\n",
            "Episode 258; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.250363416223637\n",
            "Episode 259; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.249540197540098\n",
            "Episode 260; episode reward: 11.0; AVG/10 reward: 9.7; AVG/10 loss: 5.589221651118975\n",
            "Episode 261; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 5.6915858050672865\n",
            "Episode 262; episode reward: 10.0; AVG/10 reward: 9.9; AVG/10 loss: 5.796159614392856\n",
            "Episode 263; episode reward: 10.0; AVG/10 reward: 9.9; AVG/10 loss: 5.782791428950233\n",
            "Episode 264; episode reward: 9.0; AVG/10 reward: 9.9; AVG/10 loss: 5.748852389623187\n",
            "Episode 265; episode reward: 9.0; AVG/10 reward: 9.9; AVG/10 loss: 5.728666562316782\n",
            "Episode 266; episode reward: 9.0; AVG/10 reward: 9.9; AVG/10 loss: 5.710768896001991\n",
            "Episode 267; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 5.5872410470171445\n",
            "Episode 268; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 5.457236020425946\n",
            "Episode 269; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 5.322725247333099\n",
            "Episode 270; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 5.0795538446692055\n",
            "Episode 271; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 5.072864178945676\n",
            "Episode 272; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.819200081066042\n",
            "Episode 273; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.720492590954042\n",
            "Episode 274; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.855586849876266\n",
            "Episode 275; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 4.723397893658437\n",
            "Episode 276; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.833117961028763\n",
            "Episode 277; episode reward: 11.0; AVG/10 reward: 9.3; AVG/10 loss: 4.929143049615281\n",
            "Episode 278; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.788361568709339\n",
            "Episode 279; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.765698382023347\n",
            "Episode 280; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.761038185826155\n",
            "Episode 281; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.756293708310783\n",
            "Episode 282; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.898718831535317\n",
            "Episode 283; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.983923411463808\n",
            "Episode 284; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.7291407136748385\n",
            "Episode 285; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.961221819589128\n",
            "Episode 286; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.698629296277923\n",
            "Episode 287; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 4.579527053831219\n",
            "Episode 288; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.820147378437904\n",
            "Episode 289; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.697109009967209\n",
            "Episode 290; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.803426065892251\n",
            "Episode 291; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.658907664570249\n",
            "Episode 292; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.741559484266949\n",
            "Episode 293; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.72318416282363\n",
            "Episode 294; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.945202201137102\n",
            "Episode 295; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.936551557708307\n",
            "Episode 296; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 5.168834952717495\n",
            "Episode 297; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 5.156235142542642\n",
            "Episode 298; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 5.018704962615407\n",
            "Episode 299; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 5.244778397636966\n",
            "Episode 300; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 4.992385243961848\n",
            "Episode 301; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 4.987522242134028\n",
            "Episode 302; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.863547755380685\n",
            "Episode 303; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.741754386123386\n",
            "Episode 304; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.6094366100683555\n",
            "Episode 305; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.4943324193740875\n",
            "Episode 306; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.48858319608374\n",
            "Episode 307; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.376680557385921\n",
            "Episode 308; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.484598795795872\n",
            "Episode 309; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.486459276633899\n",
            "Episode 310; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.591931142632379\n",
            "Episode 311; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.609269428492172\n",
            "Episode 312; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.482415083334481\n",
            "Episode 313; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.599123322988845\n",
            "Episode 314; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.601848902082212\n",
            "Episode 315; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.707983207958298\n",
            "Episode 316; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.707712802693936\n",
            "Episode 317; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.8201911210147355\n",
            "Episode 318; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.6905836711793665\n",
            "Episode 319; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.573831291062571\n",
            "Episode 320; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.700382534521509\n",
            "Episode 321; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.681388675161166\n",
            "Episode 322; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.8016760145401065\n",
            "Episode 323; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.680257205691928\n",
            "Episode 324; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.665837707353599\n",
            "Episode 325; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 4.511112346894713\n",
            "Episode 326; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.380831509449363\n",
            "Episode 327; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.2438463281875\n",
            "Episode 328; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.368792564505483\n",
            "Episode 329; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.460052760841294\n",
            "Episode 330; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.316294881530945\n",
            "Episode 331; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 4.530054755894579\n",
            "Episode 332; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 4.396739108170363\n",
            "Episode 333; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.503341917673312\n",
            "Episode 334; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 4.501256419193379\n",
            "Episode 335; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 4.381645866441265\n",
            "Episode 336; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 4.249805857325428\n",
            "Episode 337; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 4.359946540847174\n",
            "Episode 338; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 4.230033250748468\n",
            "Episode 339; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.233105369926628\n",
            "Episode 340; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 4.11331220152894\n",
            "Episode 341; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 4.00813394151588\n",
            "Episode 342; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 4.103741381174042\n",
            "Episode 343; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 4.097915651101836\n",
            "Episode 344; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 4.201946270503362\n",
            "Episode 345; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.447273644489791\n",
            "Episode 346; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.687633823221091\n",
            "Episode 347; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.689183641104895\n",
            "Episode 348; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 4.674829003693826\n",
            "Episode 349; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.6542189191379775\n",
            "Episode 350; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.88702650718448\n",
            "Episode 351; episode reward: 11.0; AVG/10 reward: 9.9; AVG/10 loss: 4.972218057296798\n",
            "Episode 352; episode reward: 10.0; AVG/10 reward: 10.0; AVG/10 loss: 5.094951127796305\n",
            "Episode 353; episode reward: 9.0; AVG/10 reward: 9.9; AVG/10 loss: 4.957528474060596\n",
            "Episode 354; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 4.807830305352239\n",
            "Episode 355; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.795484917280053\n",
            "Episode 356; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.774780377520769\n",
            "Episode 357; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 4.6268873422862695\n",
            "Episode 358; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.7458833464559795\n",
            "Episode 359; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 4.480256544070528\n",
            "Episode 360; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.469516009206279\n",
            "Episode 361; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.346341010082104\n",
            "Episode 362; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 4.080605320350845\n",
            "Episode 363; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 4.187602594170739\n",
            "Episode 364; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.321612092707369\n",
            "Episode 365; episode reward: 11.0; AVG/10 reward: 9.6; AVG/10 loss: 4.413551420582065\n",
            "Episode 366; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.411861385455456\n",
            "Episode 367; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 4.515696490491898\n",
            "Episode 368; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 4.490476861672856\n",
            "Episode 369; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 4.624290127493933\n",
            "Episode 370; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.614320518375594\n",
            "Episode 371; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 4.487393073181842\n",
            "Episode 372; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 4.611303105492524\n",
            "Episode 373; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 4.492838493037079\n",
            "Episode 374; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 4.35279923045199\n",
            "Episode 375; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.241974927179365\n",
            "Episode 376; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 3.961840479399902\n",
            "Episode 377; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.84356685047603\n",
            "Episode 378; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 3.707852309518688\n",
            "Episode 379; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 3.5589121936523753\n",
            "Episode 380; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 3.5545330133552104\n",
            "Episode 381; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 3.6603951217114394\n",
            "Episode 382; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.7642916993233273\n",
            "Episode 383; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.753069098450043\n",
            "Episode 384; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.8751849203259012\n",
            "Episode 385; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.7435725816041456\n",
            "Episode 386; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.9966733995075474\n",
            "Episode 387; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.105570286198444\n",
            "Episode 388; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.112189206115\n",
            "Episode 389; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 4.235585177952232\n",
            "Episode 390; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.094255854344908\n",
            "Episode 391; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.960037284207624\n",
            "Episode 392; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.9651706520475933\n",
            "Episode 393; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.065550969731038\n",
            "Episode 394; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 4.058132476230979\n",
            "Episode 395; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.040826188636565\n",
            "Episode 396; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.8934208491450186\n",
            "Episode 397; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.8874863740478434\n",
            "Episode 398; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.9982625888262033\n",
            "Episode 399; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.013316746073385\n",
            "Episode 400; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 4.004086168135789\n",
            "Episode 401; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.132077139361117\n",
            "Episode 402; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.121109383319556\n",
            "Episode 403; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 3.862196959582035\n",
            "Episode 404; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.726862507604454\n",
            "Episode 405; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 3.5871804925967945\n",
            "Episode 406; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.724342224246326\n",
            "Episode 407; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.718102521866141\n",
            "Episode 408; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.709876408240895\n",
            "Episode 409; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.809032054006323\n",
            "Episode 410; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.819499431619037\n",
            "Episode 411; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 3.5715650391810834\n",
            "Episode 412; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 3.429110145177225\n",
            "Episode 413; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.6790153047321907\n",
            "Episode 414; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.6695858100446217\n",
            "Episode 415; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.7990459564128605\n",
            "Episode 416; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.7875661582201636\n",
            "Episode 417; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.790219318598812\n",
            "Episode 418; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.657571763646126\n",
            "Episode 419; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.6594023185921403\n",
            "Episode 420; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.783687566180503\n",
            "Episode 421; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 4.01646381458809\n",
            "Episode 422; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 4.147477210318747\n",
            "Episode 423; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 4.016817185390606\n",
            "Episode 424; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 4.138673574292956\n",
            "Episode 425; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.2750334318684775\n",
            "Episode 426; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 4.141642016012017\n",
            "Episode 427; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 4.134355981588348\n",
            "Episode 428; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.258924017981206\n",
            "Episode 429; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 4.1211778565422765\n",
            "Episode 430; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.987239900706348\n",
            "Episode 431; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.968400944408246\n",
            "Episode 432; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.827249815180694\n",
            "Episode 433; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.8163046407757206\n",
            "Episode 434; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.675854677654379\n",
            "Episode 435; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.5288156832295003\n",
            "Episode 436; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.6462506813770084\n",
            "Episode 437; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.6360853829633077\n",
            "Episode 438; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.6140769760676448\n",
            "Episode 439; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.712147149093609\n",
            "Episode 440; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 3.5662449692562745\n",
            "Episode 441; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.5672489382710992\n",
            "Episode 442; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.688374937712932\n",
            "Episode 443; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 3.548981334538145\n",
            "Episode 444; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 3.422174715291643\n",
            "Episode 445; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.4141319897228746\n",
            "Episode 446; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.2846285319212924\n",
            "Episode 447; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.266986336591205\n",
            "Episode 448; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 3.160722479317946\n",
            "Episode 449; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 3.1715396436676047\n",
            "Episode 450; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.42986747369712\n",
            "Episode 451; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.42873950413068\n",
            "Episode 452; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.425454847219954\n",
            "Episode 453; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.6744065697140895\n",
            "Episode 454; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.922878364704311\n",
            "Episode 455; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 4.028520499869018\n",
            "Episode 456; episode reward: 10.0; AVG/10 reward: 9.9; AVG/10 loss: 4.151939008017381\n",
            "Episode 457; episode reward: 8.0; AVG/10 reward: 9.7; AVG/10 loss: 3.903539342417795\n",
            "Episode 458; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.8876595127065285\n",
            "Episode 459; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.8667472708237023\n",
            "Episode 460; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 3.58402435340969\n",
            "Episode 461; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.433496201719149\n",
            "Episode 462; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.436479037107001\n",
            "Episode 463; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.295450822641258\n",
            "Episode 464; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.164618038290158\n",
            "Episode 465; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.1684655854622816\n",
            "Episode 466; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.1621975078909528\n",
            "Episode 467; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.404873887855268\n",
            "Episode 468; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.376294368209025\n",
            "Episode 469; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.38523758643212\n",
            "Episode 470; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.5172692580412805\n",
            "Episode 471; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.547740556693838\n",
            "Episode 472; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.5369958930379988\n",
            "Episode 473; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.5578834428472454\n",
            "Episode 474; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 3.5517661556049704\n",
            "Episode 475; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.5523871426972136\n",
            "Episode 476; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 3.2791883490528106\n",
            "Episode 477; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 3.0098482033682226\n",
            "Episode 478; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 3.0112662603867806\n",
            "Episode 479; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 2.9893021486136506\n",
            "Episode 480; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.109361111580767\n",
            "Episode 481; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 3.092334778660678\n",
            "Episode 482; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 3.0794230280574078\n",
            "Episode 483; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 3.2944912976593956\n",
            "Episode 484; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.3994955742904494\n",
            "Episode 485; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.386764038974011\n",
            "Episode 486; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.5148565423053775\n",
            "Episode 487; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.645241398183019\n",
            "Episode 488; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.778463638869451\n",
            "Episode 489; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.7708909961655026\n",
            "Episode 490; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.6468269412819447\n",
            "Episode 491; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.626698916345963\n",
            "Episode 492; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.5090103324386903\n",
            "Episode 493; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.394720494331377\n",
            "Episode 494; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.3928262192713263\n",
            "Episode 495; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.3920286178166434\n",
            "Episode 496; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.507847627065368\n",
            "Episode 497; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.6150230872644955\n",
            "Episode 498; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.5959944047055195\n",
            "Episode 499; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.4689398239519003\n",
            "Episode 500; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.4471156761880506\n",
            "Episode 501; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.5828213208895945\n",
            "Episode 502; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.559846431294371\n",
            "Episode 503; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.556177018704058\n",
            "Episode 504; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 3.306512457403951\n",
            "Episode 505; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 3.1577070934559446\n",
            "Episode 506; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 3.0329395805431583\n",
            "Episode 507; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 3.0450429054169423\n",
            "Episode 508; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.929797791981474\n",
            "Episode 509; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7951458466093855\n",
            "Episode 510; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.770534381530151\n",
            "Episode 511; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 2.486619185306465\n",
            "Episode 512; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 2.4907347342209203\n",
            "Episode 513; episode reward: 10.0; AVG/10 reward: 8.9; AVG/10 loss: 2.4974457038110787\n",
            "Episode 514; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 2.6286164920063717\n",
            "Episode 515; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 2.6273742069191535\n",
            "Episode 516; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 2.6028835537083923\n",
            "Episode 517; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 2.4595671965242376\n",
            "Episode 518; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 2.579027440380906\n",
            "Episode 519; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7155622420237\n",
            "Episode 520; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8702852732350834\n",
            "Episode 521; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 3.140568813024717\n",
            "Episode 522; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.980781347096946\n",
            "Episode 523; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.837532196179798\n",
            "Episode 524; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.9414329086765147\n",
            "Episode 525; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8203954745607485\n",
            "Episode 526; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7164406258556935\n",
            "Episode 527; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.838153883713914\n",
            "Episode 528; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.724456315500408\n",
            "Episode 529; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8450247584802346\n",
            "Episode 530; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.834743220432305\n",
            "Episode 531; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7152307547593146\n",
            "Episode 532; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8525122920436465\n",
            "Episode 533; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.841328769087822\n",
            "Episode 534; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7196338114238463\n",
            "Episode 535; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 2.7059211948301884\n",
            "Episode 536; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8156717493573282\n",
            "Episode 537; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.823440104764104\n",
            "Episode 538; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.9372963908719267\n",
            "Episode 539; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.8006047794245506\n",
            "Episode 540; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.7829076779253192\n",
            "Episode 541; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.7593329829649003\n",
            "Episode 542; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.768769678961788\n",
            "Episode 543; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.7685297843895813\n",
            "Episode 544; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.8814659694603852\n",
            "Episode 545; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.9902809035741917\n",
            "Episode 546; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 3.1214458556825724\n",
            "Episode 547; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.980362312310997\n",
            "Episode 548; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.9568830869588307\n",
            "Episode 549; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.9570459930656177\n",
            "Episode 550; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.975261850944782\n",
            "Episode 551; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.9812676564012306\n",
            "Episode 552; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.953537220747429\n",
            "Episode 553; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.948306526860135\n",
            "Episode 554; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.83309937531668\n",
            "Episode 555; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.855376607804753\n",
            "Episode 556; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.855453207085696\n",
            "Episode 557; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.8354949953334185\n",
            "Episode 558; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.71345304253933\n",
            "Episode 559; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 2.5676504374834117\n",
            "Episode 560; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 2.553061471120031\n",
            "Episode 561; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.537096930640465\n",
            "Episode 562; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.565506309812803\n",
            "Episode 563; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.693284591498191\n",
            "Episode 564; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.6766476845662313\n",
            "Episode 565; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.6576943746830515\n",
            "Episode 566; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 2.386000011729837\n",
            "Episode 567; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 2.418447903161756\n",
            "Episode 568; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 2.5456223498361146\n",
            "Episode 569; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.811148217019131\n",
            "Episode 570; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.808318505234478\n",
            "Episode 571; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 3.0488773693954423\n",
            "Episode 572; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.157849596612649\n",
            "Episode 573; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.1567730236658234\n",
            "Episode 574; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.1564937164005578\n",
            "Episode 575; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.1708894767578557\n",
            "Episode 576; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.431239985923952\n",
            "Episode 577; episode reward: 10.0; AVG/10 reward: 9.9; AVG/10 loss: 3.5444618873129246\n",
            "Episode 578; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 3.3960949805856346\n",
            "Episode 579; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.3822805277951438\n",
            "Episode 580; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.3669965331037774\n",
            "Episode 581; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.2415921023053045\n",
            "Episode 582; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.2385030308626446\n",
            "Episode 583; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.083522878427476\n",
            "Episode 584; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 3.0714037991403673\n",
            "Episode 585; episode reward: 11.0; AVG/10 reward: 9.8; AVG/10 loss: 3.292580416333402\n",
            "Episode 586; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.277526348738008\n",
            "Episode 587; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.1319331308721687\n",
            "Episode 588; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.2690639122507017\n",
            "Episode 589; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 3.0237591962020427\n",
            "Episode 590; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.897620960502091\n",
            "Episode 591; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.9064158764043047\n",
            "Episode 592; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.895987261584886\n",
            "Episode 593; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.040000763957863\n",
            "Episode 594; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.1826394852042847\n",
            "Episode 595; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 3.0735152755028614\n",
            "Episode 596; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.9632177914346296\n",
            "Episode 597; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.981702554947932\n",
            "Episode 598; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.979048290572838\n",
            "Episode 599; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.2160913367571515\n",
            "Episode 600; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.3378688110768273\n",
            "Episode 601; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.1981940151069854\n",
            "Episode 602; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.197231276395361\n",
            "Episode 603; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.1855345006468077\n",
            "Episode 604; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.1515369977471055\n",
            "Episode 605; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.129151069229741\n",
            "Episode 606; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.2255998015826703\n",
            "Episode 607; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 3.2050914503010843\n",
            "Episode 608; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.1996271437210884\n",
            "Episode 609; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.0784634284930554\n",
            "Episode 610; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 3.069350804166166\n",
            "Episode 611; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 3.050808683239803\n",
            "Episode 612; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.9100868892218217\n",
            "Episode 613; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.7815308147743636\n",
            "Episode 614; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.523381275714761\n",
            "Episode 615; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.528117177214358\n",
            "Episode 616; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 2.6359085388876844\n",
            "Episode 617; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.7646760478570562\n",
            "Episode 618; episode reward: 11.0; AVG/10 reward: 9.6; AVG/10 loss: 2.8539510813806173\n",
            "Episode 619; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.9790913321495447\n",
            "Episode 620; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.9806344929730386\n",
            "Episode 621; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 2.9844458274959704\n",
            "Episode 622; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 3.09053442714583\n",
            "Episode 623; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 3.0713199276722016\n",
            "Episode 624; episode reward: 8.0; AVG/10 reward: 9.8; AVG/10 loss: 3.057713926211416\n",
            "Episode 625; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 2.7789613960344086\n",
            "Episode 626; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.540087015625115\n",
            "Episode 627; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.540022330529014\n",
            "Episode 628; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.415769758497119\n",
            "Episode 629; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.266700150124179\n",
            "Episode 630; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.261417444690944\n",
            "Episode 631; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2659689204259594\n",
            "Episode 632; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2800735617838956\n",
            "Episode 633; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.407813966014942\n",
            "Episode 634; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.5585244586798686\n",
            "Episode 635; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.698247902838428\n",
            "Episode 636; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.6956192214117407\n",
            "Episode 637; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.5289145919411444\n",
            "Episode 638; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.4015394383519224\n",
            "Episode 639; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.395667141830894\n",
            "Episode 640; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.260249981636771\n",
            "Episode 641; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.390383926369668\n",
            "Episode 642; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2563783973559497\n",
            "Episode 643; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2528797449530713\n",
            "Episode 644; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.223030092603932\n",
            "Episode 645; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2036183363694994\n",
            "Episode 646; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.3202871302468444\n",
            "Episode 647; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.3382319580284885\n",
            "Episode 648; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.4852952532948778\n",
            "Episode 649; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.4733254606328483\n",
            "Episode 650; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.469393861307619\n",
            "Episode 651; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.3305399523770136\n",
            "Episode 652; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.3234717003002947\n",
            "Episode 653; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2053475271842187\n",
            "Episode 654; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.3475243798083953\n",
            "Episode 655; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.4936314071272943\n",
            "Episode 656; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.4878505237083304\n",
            "Episode 657; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.608913885962937\n",
            "Episode 658; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.321131518654676\n",
            "Episode 659; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 2.1908756156300813\n",
            "Episode 660; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.2093317073719176\n",
            "Episode 661; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.1913782831074227\n",
            "Episode 662; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 2.055010285439475\n",
            "Episode 663; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.1686313081743966\n",
            "Episode 664; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.1589916313234965\n",
            "Episode 665; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.156851138179759\n",
            "Episode 666; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 2.013455895692283\n",
            "Episode 667; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.883565304370014\n",
            "Episode 668; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.162122545209864\n",
            "Episode 669; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.4294735444601065\n",
            "Episode 670; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.5326040154513807\n",
            "Episode 671; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 2.3937592573907738\n",
            "Episode 672; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.519514196323695\n",
            "Episode 673; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.503346259376271\n",
            "Episode 674; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.5065573158385974\n",
            "Episode 675; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.2259060434132696\n",
            "Episode 676; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.3633650636827084\n",
            "Episode 677; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.2112052352918776\n",
            "Episode 678; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.072807225856193\n",
            "Episode 679; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.076081451839006\n",
            "Episode 680; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.9409000655925706\n",
            "Episode 681; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.19552850663421\n",
            "Episode 682; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.2040607468647124\n",
            "Episode 683; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 2.215162517481583\n",
            "Episode 684; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 1.9317076606212353\n",
            "Episode 685; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 2.059066858960487\n",
            "Episode 686; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 2.0699081114604163\n",
            "Episode 687; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.21056152143277\n",
            "Episode 688; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.328697715286343\n",
            "Episode 689; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.1771155674587153\n",
            "Episode 690; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 2.0413116841184364\n",
            "Episode 691; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.9274394053523145\n",
            "Episode 692; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.918529613700429\n",
            "Episode 693; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 2.0226550354393638\n",
            "Episode 694; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.2985797913195407\n",
            "Episode 695; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.4369254621037015\n",
            "Episode 696; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.4260523146681243\n",
            "Episode 697; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 2.2882071224554763\n",
            "Episode 698; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.2826648405673615\n",
            "Episode 699; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 2.139939677460778\n",
            "Episode 700; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.4094584353974433\n",
            "Episode 701; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.4133710466798988\n",
            "Episode 702; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.551447893678574\n",
            "Episode 703; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.3008307020012886\n",
            "Episode 704; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.147758291802394\n",
            "Episode 705; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 1.873257283872513\n",
            "Episode 706; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 1.8688267137669363\n",
            "Episode 707; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 2.2391996835732\n",
            "Episode 708; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 1.960630052936311\n",
            "Episode 709; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.2366836498086835\n",
            "Episode 710; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.073078134659275\n",
            "Episode 711; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.1768178712275894\n",
            "Episode 712; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 2.023278875699752\n",
            "Episode 713; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.1504704276714124\n",
            "Episode 714; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.281190705042404\n",
            "Episode 715; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.4016370236894673\n",
            "Episode 716; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.407287634240128\n",
            "Episode 717; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.1705431499189047\n",
            "Episode 718; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 2.178616575161457\n",
            "Episode 719; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.1765162905493023\n",
            "Episode 720; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.190700392997161\n",
            "Episode 721; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 2.303981450007636\n",
            "Episode 722; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.3105831009408004\n",
            "Episode 723; episode reward: 11.0; AVG/10 reward: 9.6; AVG/10 loss: 2.4196884018536586\n",
            "Episode 724; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.424499135168458\n",
            "Episode 725; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.4387146512034032\n",
            "Episode 726; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.273617383285553\n",
            "Episode 727; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.3943010960612545\n",
            "Episode 728; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 2.6383481594158154\n",
            "Episode 729; episode reward: 11.0; AVG/10 reward: 9.9; AVG/10 loss: 2.734190126162209\n",
            "Episode 730; episode reward: 10.0; AVG/10 reward: 10.0; AVG/10 loss: 2.8615129864261646\n",
            "Episode 731; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 2.60322770950945\n",
            "Episode 732; episode reward: 9.0; AVG/10 reward: 9.8; AVG/10 loss: 2.602807337476701\n",
            "Episode 733; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 2.2194264516247646\n",
            "Episode 734; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.219175644994509\n",
            "Episode 735; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.1992339690956233\n",
            "Episode 736; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.1902467445172533\n",
            "Episode 737; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 2.038978148180438\n",
            "Episode 738; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 1.7816106064962063\n",
            "Episode 739; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.5537266484103889\n",
            "Episode 740; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 1.548144356312577\n",
            "Episode 741; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.5494323560930001\n",
            "Episode 742; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.5358139961873494\n",
            "Episode 743; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.6757868591617986\n",
            "Episode 744; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 1.3909615832931128\n",
            "Episode 745; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 1.3675773361583172\n",
            "Episode 746; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 1.3781665304951618\n",
            "Episode 747; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 1.5140993644426612\n",
            "Episode 748; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 1.4915391689220319\n",
            "Episode 749; episode reward: 8.0; AVG/10 reward: 8.9; AVG/10 loss: 1.331364772408315\n",
            "Episode 750; episode reward: 10.0; AVG/10 reward: 8.9; AVG/10 loss: 1.3205415243489071\n",
            "Episode 751; episode reward: 8.0; AVG/10 reward: 8.8; AVG/10 loss: 1.178275967769015\n",
            "Episode 752; episode reward: 9.0; AVG/10 reward: 8.8; AVG/10 loss: 1.1908016704837974\n",
            "Episode 753; episode reward: 11.0; AVG/10 reward: 9.0; AVG/10 loss: 1.4277256735620618\n",
            "Episode 754; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.685907048631059\n",
            "Episode 755; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.8431494490974978\n",
            "Episode 756; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 1.706280849757923\n",
            "Episode 757; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.5852838808268228\n",
            "Episode 758; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9782400730442184\n",
            "Episode 759; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.100558607371794\n",
            "Episode 760; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9707835071055761\n",
            "Episode 761; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.1018605437217177\n",
            "Episode 762; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.2172298127675054\n",
            "Episode 763; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.958650974685958\n",
            "Episode 764; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.8604918612973997\n",
            "Episode 765; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.70418633184604\n",
            "Episode 766; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.850854817253919\n",
            "Episode 767; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9872987821508317\n",
            "Episode 768; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.8861897507323284\n",
            "Episode 769; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.9002692951893132\n",
            "Episode 770; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.893647367395659\n",
            "Episode 771; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 2.0363697871867554\n",
            "Episode 772; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 2.143064018067393\n",
            "Episode 773; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.2871777857145448\n",
            "Episode 774; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.271907186659059\n",
            "Episode 775; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.415641211169985\n",
            "Episode 776; episode reward: 8.0; AVG/10 reward: 9.6; AVG/10 loss: 2.259050140184012\n",
            "Episode 777; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 2.099821255398008\n",
            "Episode 778; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9609697996831108\n",
            "Episode 779; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.099985433423485\n",
            "Episode 780; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.234501612611802\n",
            "Episode 781; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9505947659895504\n",
            "Episode 782; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.8332427876969437\n",
            "Episode 783; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.8164092657614415\n",
            "Episode 784; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9331878618343261\n",
            "Episode 785; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.812429222633553\n",
            "Episode 786; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 2.0824488191879587\n",
            "Episode 787; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.2316796726596415\n",
            "Episode 788; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.2129192401067415\n",
            "Episode 789; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 1.9148045590439178\n",
            "Episode 790; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 1.6313567296430072\n",
            "Episode 791; episode reward: 8.0; AVG/10 reward: 9.2; AVG/10 loss: 1.6161054541277218\n",
            "Episode 792; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.6125064669058786\n",
            "Episode 793; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.6134092264349937\n",
            "Episode 794; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.4612974847254967\n",
            "Episode 795; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.4552217718066491\n",
            "Episode 796; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 1.560234053017875\n",
            "Episode 797; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.4080654792119067\n",
            "Episode 798; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.4202223710177055\n",
            "Episode 799; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6963116797083972\n",
            "Episode 800; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.70416067449409\n",
            "Episode 801; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.8543126303858863\n",
            "Episode 802; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.7135101745929582\n",
            "Episode 803; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.563645605443881\n",
            "Episode 804; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 1.4334930916127397\n",
            "Episode 805; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.5439493268233389\n",
            "Episode 806; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.296619935993254\n",
            "Episode 807; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 1.5400542980878016\n",
            "Episode 808; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6576602754293064\n",
            "Episode 809; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.5204358143326924\n",
            "Episode 810; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6356897613797385\n",
            "Episode 811; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7647637597574324\n",
            "Episode 812; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7533517812459145\n",
            "Episode 813; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.625335829735223\n",
            "Episode 814; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6105983967261508\n",
            "Episode 815; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6358849848644084\n",
            "Episode 816; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6399635760494884\n",
            "Episode 817; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.530829692218669\n",
            "Episode 818; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 1.24719987996669\n",
            "Episode 819; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.2344746353674185\n",
            "Episode 820; episode reward: 11.0; AVG/10 reward: 9.2; AVG/10 loss: 1.4944425728932562\n",
            "Episode 821; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.3811515722849486\n",
            "Episode 822; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.5198998983576786\n",
            "Episode 823; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.8035889764736353\n",
            "Episode 824; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.9629326852883366\n",
            "Episode 825; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.946634550938846\n",
            "Episode 826; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.9275424401819106\n",
            "Episode 827; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.9230098050738136\n",
            "Episode 828; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 2.0848145359375687\n",
            "Episode 829; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.2320532837675127\n",
            "Episode 830; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 2.1034656896782\n",
            "Episode 831; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 1.9461045783204067\n",
            "Episode 832; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.9430990934369636\n",
            "Episode 833; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.8082391953897023\n",
            "Episode 834; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6555868233694757\n",
            "Episode 835; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.493765061295179\n",
            "Episode 836; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6391983866450317\n",
            "Episode 837; episode reward: 11.0; AVG/10 reward: 9.4; AVG/10 loss: 1.744567466656484\n",
            "Episode 838; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7189603796341366\n",
            "Episode 839; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.570978474594345\n",
            "Episode 840; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 1.2906012396335196\n",
            "Episode 841; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.5378960285336465\n",
            "Episode 842; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.392254905213179\n",
            "Episode 843; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.505271570226054\n",
            "Episode 844; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7714868170285858\n",
            "Episode 845; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7888042504224881\n",
            "Episode 846; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.6710412705931497\n",
            "Episode 847; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.4115811198801023\n",
            "Episode 848; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.4221618601070982\n",
            "Episode 849; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.4480880036376436\n",
            "Episode 850; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6035795838075504\n",
            "Episode 851; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.6276249782902208\n",
            "Episode 852; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7697898691755303\n",
            "Episode 853; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7687120551043083\n",
            "Episode 854; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7627324375414832\n",
            "Episode 855; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7447555532297145\n",
            "Episode 856; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.7186074391025592\n",
            "Episode 857; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8553212901611338\n",
            "Episode 858; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8414198308930996\n",
            "Episode 859; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.9562363933468876\n",
            "Episode 860; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.954758317744248\n",
            "Episode 861; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7833340105804774\n",
            "Episode 862; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7862586848289321\n",
            "Episode 863; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7991871732329106\n",
            "Episode 864; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8093205693797252\n",
            "Episode 865; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.9536240923928154\n",
            "Episode 866; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.0772004200081544\n",
            "Episode 867; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.084070114878928\n",
            "Episode 868; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 2.2155443559379644\n",
            "Episode 869; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 2.0803348519963385\n",
            "Episode 870; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 2.0587311716200767\n",
            "Episode 871; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 2.0823350223133854\n",
            "Episode 872; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8152052271730041\n",
            "Episode 873; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.5300710217952798\n",
            "Episode 874; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.522135462271687\n",
            "Episode 875; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.5304259851469624\n",
            "Episode 876; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.529339952264602\n",
            "Episode 877; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.518424545515082\n",
            "Episode 878; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.5228603450908476\n",
            "Episode 879; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.667594124710385\n",
            "Episode 880; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8247330536354318\n",
            "Episode 881; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8270274668416981\n",
            "Episode 882; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 1.8070857619849139\n",
            "Episode 883; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 2.078568363877419\n",
            "Episode 884; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.9308702256061587\n",
            "Episode 885; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7634047309033558\n",
            "Episode 886; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.762999502622543\n",
            "Episode 887; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.765412881429801\n",
            "Episode 888; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7659660637656422\n",
            "Episode 889; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.4491796159072206\n",
            "Episode 890; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.4533731861143617\n",
            "Episode 891; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.5789907306736342\n",
            "Episode 892; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 1.5865479916518326\n",
            "Episode 893; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.429205832905505\n",
            "Episode 894; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.4270143106431585\n",
            "Episode 895; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.4467366761454448\n",
            "Episode 896; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.3133968479713212\n",
            "Episode 897; episode reward: 8.0; AVG/10 reward: 9.0; AVG/10 loss: 1.0270812998914414\n",
            "Episode 898; episode reward: 9.0; AVG/10 reward: 8.9; AVG/10 loss: 0.875975516010745\n",
            "Episode 899; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 1.1794017184125252\n",
            "Episode 900; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 1.0057178128510635\n",
            "Episode 901; episode reward: 8.0; AVG/10 reward: 8.8; AVG/10 loss: 0.7302940339381474\n",
            "Episode 902; episode reward: 10.0; AVG/10 reward: 9.0; AVG/10 loss: 1.000316521801222\n",
            "Episode 903; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 1.1303755853277604\n",
            "Episode 904; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.2717637425405113\n",
            "Episode 905; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.299372006828903\n",
            "Episode 906; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.4230407556536366\n",
            "Episode 907; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7070363585853578\n",
            "Episode 908; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.7001094155512284\n",
            "Episode 909; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6696782087189064\n",
            "Episode 910; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6841455690658216\n",
            "Episode 911; episode reward: 8.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6659609793948953\n",
            "Episode 912; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.5092509601811999\n",
            "Episode 913; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.5245772200647558\n",
            "Episode 914; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.3952836619742004\n",
            "Episode 915; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.380252827539286\n",
            "Episode 916; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.2553498459937191\n",
            "Episode 917; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 1.120325109294799\n",
            "Episode 918; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.2692860402613886\n",
            "Episode 919; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.287976103175967\n",
            "Episode 920; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.41556480045623\n",
            "Episode 921; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.695754898214054\n",
            "Episode 922; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6968620246613504\n",
            "Episode 923; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6763355752272804\n",
            "Episode 924; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6845477407768967\n",
            "Episode 925; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6802199464508463\n",
            "Episode 926; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6578787408079687\n",
            "Episode 927; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6512334643141027\n",
            "Episode 928; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.641778624215823\n",
            "Episode 929; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6470056118980658\n",
            "Episode 930; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6483733729507406\n",
            "Episode 931; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.495811687010261\n",
            "Episode 932; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6456271774543736\n",
            "Episode 933; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.510997851627964\n",
            "Episode 934; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.6243708365729013\n",
            "Episode 935; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.7389860971735516\n",
            "Episode 936; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 1.8792260646091936\n",
            "Episode 937; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 2.0085729222146824\n",
            "Episode 938; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 1.854712034749128\n",
            "Episode 939; episode reward: 11.0; AVG/10 reward: 9.8; AVG/10 loss: 1.9473741919515954\n",
            "Episode 940; episode reward: 9.0; AVG/10 reward: 9.7; AVG/10 loss: 1.8116867148300764\n",
            "Episode 941; episode reward: 10.0; AVG/10 reward: 9.8; AVG/10 loss: 1.951349901968559\n",
            "Episode 942; episode reward: 11.0; AVG/10 reward: 9.9; AVG/10 loss: 2.0536270862464154\n",
            "Episode 943; episode reward: 10.0; AVG/10 reward: 10.0; AVG/10 loss: 2.2041857328116796\n",
            "Episode 944; episode reward: 9.0; AVG/10 reward: 9.9; AVG/10 loss: 2.0663099175697934\n",
            "Episode 945; episode reward: 8.0; AVG/10 reward: 9.7; AVG/10 loss: 1.7841585037254408\n",
            "Episode 946; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.648652297309478\n",
            "Episode 947; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.4883744957030145\n",
            "Episode 948; episode reward: 8.0; AVG/10 reward: 9.4; AVG/10 loss: 1.3402169614529549\n",
            "Episode 949; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2380958119475252\n",
            "Episode 950; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.3571058383408785\n",
            "Episode 951; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2516568813827142\n",
            "Episode 952; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.1430881527387393\n",
            "Episode 953; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.1294596312201595\n",
            "Episode 954; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2578603128660464\n",
            "Episode 955; episode reward: 10.0; AVG/10 reward: 9.5; AVG/10 loss: 1.5391334249662283\n",
            "Episode 956; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.5383587916663934\n",
            "Episode 957; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.5770850535598047\n",
            "Episode 958; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 1.8669228413824102\n",
            "Episode 959; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.7018417754316186\n",
            "Episode 960; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.7159937661412006\n",
            "Episode 961; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6953001255539555\n",
            "Episode 962; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6793325216100807\n",
            "Episode 963; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.5196233384937308\n",
            "Episode 964; episode reward: 8.0; AVG/10 reward: 9.3; AVG/10 loss: 1.231514992503145\n",
            "Episode 965; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.065602623893009\n",
            "Episode 966; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.0625645643838917\n",
            "Episode 967; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.0404108091648054\n",
            "Episode 968; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.0502079819412813\n",
            "Episode 969; episode reward: 8.0; AVG/10 reward: 9.1; AVG/10 loss: 0.9262483180175863\n",
            "Episode 970; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 0.9212115953113138\n",
            "Episode 971; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 0.9259593554095561\n",
            "Episode 972; episode reward: 9.0; AVG/10 reward: 9.0; AVG/10 loss: 0.7840146404600232\n",
            "Episode 973; episode reward: 10.0; AVG/10 reward: 9.1; AVG/10 loss: 0.935536865445636\n",
            "Episode 974; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2360958767185437\n",
            "Episode 975; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.264900314494718\n",
            "Episode 976; episode reward: 10.0; AVG/10 reward: 9.4; AVG/10 loss: 1.4016543690193106\n",
            "Episode 977; episode reward: 9.0; AVG/10 reward: 9.4; AVG/10 loss: 1.411739271298424\n",
            "Episode 978; episode reward: 11.0; AVG/10 reward: 9.5; AVG/10 loss: 1.5141686351888157\n",
            "Episode 979; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.65415801020239\n",
            "Episode 980; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6425795687673546\n",
            "Episode 981; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6366800289193626\n",
            "Episode 982; episode reward: 10.0; AVG/10 reward: 9.7; AVG/10 loss: 1.7742560949894517\n",
            "Episode 983; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6444956969539846\n",
            "Episode 984; episode reward: 10.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6331308404796843\n",
            "Episode 985; episode reward: 9.0; AVG/10 reward: 9.6; AVG/10 loss: 1.6248139249026323\n",
            "Episode 986; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.4948063356672745\n",
            "Episode 987; episode reward: 9.0; AVG/10 reward: 9.5; AVG/10 loss: 1.4764992170759759\n",
            "Episode 988; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2213148369023645\n",
            "Episode 989; episode reward: 9.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2141815341937678\n",
            "Episode 990; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.0987053570046281\n",
            "Episode 991; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2130458370561024\n",
            "Episode 992; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.1057186106329175\n",
            "Episode 993; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.1219587942497828\n",
            "Episode 994; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 0.9892630183774397\n",
            "Episode 995; episode reward: 9.0; AVG/10 reward: 9.1; AVG/10 loss: 0.9638327418134309\n",
            "Episode 996; episode reward: 10.0; AVG/10 reward: 9.2; AVG/10 loss: 1.0951074614621927\n",
            "Episode 997; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.087661190246229\n",
            "Episode 998; episode reward: 9.0; AVG/10 reward: 9.2; AVG/10 loss: 1.062780094170065\n",
            "Episode 999; episode reward: 10.0; AVG/10 reward: 9.3; AVG/10 loss: 1.2002790421103922\n"
          ]
        }
      ],
      "source": [
        "rewards, losses = agent.train(env, episodes=1000, learning_rate=0.01, gamma=0.99, epsilon=0.0, epsilon_decay=0.99, min_epsilon=0.0, n_steps=10, scaler=True, RBFSamplers=rbf_samplers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Keswk9KQCdt-"
      },
      "outputs": [],
      "source": [
        "sample_states = np.array([agent.env.observation_space.sample() for _ in range(100)])\n",
        "preds = []\n",
        "for s in sample_states:\n",
        "    preds.append(agent.predict([s]))\n",
        "    preds.append(np.argmax(agent.predict([s])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qseuFTkzDYNA",
        "outputId": "61eef0ea-8276-4e9f-98c4-2b732be25f8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([-45.1895819 , -45.70886532, -45.34686615]),\n",
              " 0,\n",
              " array([-50.95015704, -51.02272957, -50.56793341]),\n",
              " 2,\n",
              " array([-71.09641717, -71.45774276, -70.64237142]),\n",
              " 2,\n",
              " array([-62.46317903, -61.38572145, -61.92070898]),\n",
              " 1,\n",
              " array([-48.88935787, -49.05012479, -48.54653268]),\n",
              " 2,\n",
              " array([-56.65851995, -55.81571011, -56.7521825 ]),\n",
              " 1,\n",
              " array([-52.20205936, -51.60578307, -52.62032273]),\n",
              " 1,\n",
              " array([-47.01166334, -47.54759858, -47.51684144]),\n",
              " 0,\n",
              " array([-43.52300902, -42.54906502, -43.93247752]),\n",
              " 1,\n",
              " array([-52.7906874 , -53.06158549, -51.99724629]),\n",
              " 2,\n",
              " array([-39.26838346, -40.27159755, -39.89826169]),\n",
              " 0,\n",
              " array([-87.44936779, -97.37778723, -85.28948768]),\n",
              " 2,\n",
              " array([-75.64302565, -79.5964192 , -76.79404227]),\n",
              " 0,\n",
              " array([-49.53386226, -50.44019908, -51.14687649]),\n",
              " 0,\n",
              " array([-56.30604592, -54.83278567, -55.98092939]),\n",
              " 1,\n",
              " array([-80.866469  , -87.15681769, -81.62435426]),\n",
              " 0,\n",
              " array([-39.55306426, -40.82420984, -39.90099312]),\n",
              " 0,\n",
              " array([-70.05614321, -71.04289577, -71.30769485]),\n",
              " 0,\n",
              " array([-73.33379103, -72.425349  , -71.28567462]),\n",
              " 2,\n",
              " array([-46.55785038, -46.81732422, -46.42185602]),\n",
              " 2,\n",
              " array([-55.44859078, -56.35075602, -57.25692334]),\n",
              " 0,\n",
              " array([-44.18757211, -42.92395557, -44.55648449]),\n",
              " 1,\n",
              " array([-53.58895762, -52.14590728, -52.65604672]),\n",
              " 1,\n",
              " array([-68.27716496, -67.15902613, -67.83787324]),\n",
              " 1,\n",
              " array([-53.24409834, -53.42349164, -52.48054016]),\n",
              " 2,\n",
              " array([-55.85672061, -56.98999615, -56.79773396]),\n",
              " 0,\n",
              " array([-55.73380042, -56.89068957, -55.35965419]),\n",
              " 2,\n",
              " array([-66.78332473, -67.89381169, -67.36859572]),\n",
              " 0,\n",
              " array([-48.98600404, -49.63482778, -50.39664116]),\n",
              " 0,\n",
              " array([-47.56149331, -46.46864469, -47.9814003 ]),\n",
              " 1,\n",
              " array([-83.15517315, -89.53848785, -81.83091585]),\n",
              " 2,\n",
              " array([-59.96526391, -57.4620287 , -58.33896715]),\n",
              " 1,\n",
              " array([-38.61189278, -39.86248835, -39.01508204]),\n",
              " 0,\n",
              " array([-73.95837374, -75.46502746, -74.64015105]),\n",
              " 0,\n",
              " array([-48.19020106, -47.04394561, -47.71780723]),\n",
              " 1,\n",
              " array([-52.0879213 , -52.77784448, -51.38495313]),\n",
              " 2,\n",
              " array([-75.3036514 , -77.0954667 , -73.83680055]),\n",
              " 2,\n",
              " array([-47.84759486, -48.10934692, -48.94528856]),\n",
              " 0,\n",
              " array([-76.39480115, -80.55185106, -77.19690579]),\n",
              " 0,\n",
              " array([-55.77271999, -53.36832885, -53.45284   ]),\n",
              " 1,\n",
              " array([-67.41293005, -67.43092383, -69.18225797]),\n",
              " 0,\n",
              " array([-63.96507283, -61.77838902, -63.71330427]),\n",
              " 1,\n",
              " array([-82.90546327, -89.91215967, -82.55620922]),\n",
              " 2,\n",
              " array([-71.98209232, -72.10508921, -72.04988481]),\n",
              " 0,\n",
              " array([-56.28509422, -53.96533215, -54.07067752]),\n",
              " 1,\n",
              " array([-47.51919249, -47.98891618, -47.28692617]),\n",
              " 2,\n",
              " array([-71.32182706, -72.06686453, -71.84283702]),\n",
              " 0,\n",
              " array([-59.60343831, -58.2132041 , -58.60541258]),\n",
              " 1,\n",
              " array([-75.38986376, -78.0056008 , -75.87251336]),\n",
              " 0,\n",
              " array([-62.55886298, -60.57989578, -61.71306754]),\n",
              " 1,\n",
              " array([-45.82439911, -45.96974799, -47.56194906]),\n",
              " 0,\n",
              " array([-45.31884353, -46.51747553, -46.09795634]),\n",
              " 0,\n",
              " array([ -83.22395475, -100.06798444,  -88.15386394]),\n",
              " 0,\n",
              " array([-72.59447879, -73.75728834, -72.93685308]),\n",
              " 0,\n",
              " array([-76.40980095, -84.18280377, -80.64364853]),\n",
              " 0,\n",
              " array([-59.08539543, -57.60421014, -60.39641272]),\n",
              " 1,\n",
              " array([-54.63519415, -55.63690673, -56.49238703]),\n",
              " 0,\n",
              " array([-55.61230918, -53.77754557, -54.01224309]),\n",
              " 1,\n",
              " array([-49.09631942, -49.10860825, -51.1953626 ]),\n",
              " 0,\n",
              " array([-75.15651412, -80.5344123 , -78.2023607 ]),\n",
              " 0,\n",
              " array([-49.50743916, -49.83399492, -48.95461618]),\n",
              " 2,\n",
              " array([-55.94743   , -55.73807451, -59.13652508]),\n",
              " 1,\n",
              " array([-49.22468556, -49.30405412, -49.66272011]),\n",
              " 0,\n",
              " array([-50.4256532 , -48.78589261, -50.28299439]),\n",
              " 1,\n",
              " array([-57.29801153, -54.09458398, -54.23477043]),\n",
              " 1,\n",
              " array([-75.68030202, -81.70465618, -78.99200849]),\n",
              " 0,\n",
              " array([-49.06308748, -47.73688259, -49.30289761]),\n",
              " 1,\n",
              " array([-74.04894482, -73.23714018, -70.36582526]),\n",
              " 2,\n",
              " array([-72.85113535, -71.9522663 , -69.7389646 ]),\n",
              " 2,\n",
              " array([-59.11390465, -60.36959855, -61.92740525]),\n",
              " 0,\n",
              " array([-63.55427383, -63.83405218, -66.72526529]),\n",
              " 0,\n",
              " array([-67.48198585, -67.48527716, -69.20976118]),\n",
              " 0,\n",
              " array([-67.19278714, -68.27302722, -69.19131324]),\n",
              " 0,\n",
              " array([-77.74663935, -87.8403577 , -82.35996915]),\n",
              " 0,\n",
              " array([-58.76139099, -59.97665934, -61.48178089]),\n",
              " 0,\n",
              " array([-76.31474415, -76.8841    , -73.82949576]),\n",
              " 2,\n",
              " array([-78.19771009, -81.94529079, -76.50254657]),\n",
              " 2,\n",
              " array([ -87.33370827, -107.14527224,  -92.71450018]),\n",
              " 0,\n",
              " array([-56.90516372, -54.06699949, -54.11099389]),\n",
              " 1,\n",
              " array([-44.7875177 , -46.14851883, -45.78980598]),\n",
              " 0,\n",
              " array([-56.57405332, -54.78154292, -56.22396777]),\n",
              " 1,\n",
              " array([-47.32391688, -48.00560819, -47.89232561]),\n",
              " 0,\n",
              " array([ -85.3940731 , -101.5739223 ,  -91.41486358]),\n",
              " 0,\n",
              " array([-59.79190713, -59.22054879, -59.89457134]),\n",
              " 1,\n",
              " array([-76.03984835, -79.81820541, -76.74567847]),\n",
              " 0,\n",
              " array([-63.47285361, -61.42179391, -62.52749744]),\n",
              " 1,\n",
              " array([-59.31183877, -57.76009216, -58.82528855]),\n",
              " 1,\n",
              " array([-52.75325593, -51.76642824, -52.91597786]),\n",
              " 1,\n",
              " array([-65.84645478, -63.45706726, -63.35546939]),\n",
              " 2,\n",
              " array([-57.87077884, -57.44900174, -57.82882654]),\n",
              " 1,\n",
              " array([-51.41728735, -51.89658079, -50.69065991]),\n",
              " 2,\n",
              " array([-61.61973163, -58.90298053, -59.83446512]),\n",
              " 1,\n",
              " array([-45.19899575, -45.68196304, -45.33813594]),\n",
              " 0,\n",
              " array([ -89.38213023, -100.22875253,  -82.32082066]),\n",
              " 2,\n",
              " array([-67.66950516, -65.12001608, -65.74040215]),\n",
              " 1,\n",
              " array([-80.90828639, -94.48125622, -87.54649475]),\n",
              " 0,\n",
              " array([-66.40121112, -63.73345661, -64.51807244]),\n",
              " 1,\n",
              " array([-63.39025516, -64.24350951, -63.51392966]),\n",
              " 0,\n",
              " array([-58.8783493 , -57.84943077, -58.65642515]),\n",
              " 1,\n",
              " array([-51.82261592, -51.82845788, -51.78436553]),\n",
              " 2]"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw3fj-zR-e3B",
        "outputId": "baa44bc1-e379-468c-f99a-0cc190d65f81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.99,\n",
              " 0.9801,\n",
              " 0.970299,\n",
              " 0.96059601,\n",
              " 0.9509900498999999,\n",
              " 0.941480149401,\n",
              " 0.9320653479069899,\n",
              " 0.9227446944279201,\n",
              " 0.9135172474836408,\n",
              " 0.9043820750088044,\n",
              " 0.8953382542587164,\n",
              " 0.8863848717161292,\n",
              " 0.8775210229989678,\n",
              " 0.8687458127689782,\n",
              " 0.8600583546412884,\n",
              " 0.8514577710948755,\n",
              " 0.8429431933839268,\n",
              " 0.8345137614500875,\n",
              " 0.8261686238355866,\n",
              " 0.8179069375972308,\n",
              " 0.8097278682212584,\n",
              " 0.8016305895390459,\n",
              " 0.7936142836436554,\n",
              " 0.7856781408072188,\n",
              " 0.7778213593991467,\n",
              " 0.7700431458051551,\n",
              " 0.7623427143471035,\n",
              " 0.7547192872036326,\n",
              " 0.7471720943315961,\n",
              " 0.7397003733882802,\n",
              " 0.7323033696543975,\n",
              " 0.7249803359578534,\n",
              " 0.7177305325982749,\n",
              " 0.7105532272722921,\n",
              " 0.7034476949995692,\n",
              " 0.6964132180495735,\n",
              " 0.6894490858690777,\n",
              " 0.682554595010387,\n",
              " 0.6757290490602831,\n",
              " 0.6689717585696803,\n",
              " 0.6622820409839835,\n",
              " 0.6556592205741436,\n",
              " 0.6491026283684022,\n",
              " 0.6426116020847181,\n",
              " 0.6361854860638709,\n",
              " 0.6298236312032323,\n",
              " 0.6235253948912,\n",
              " 0.617290140942288,\n",
              " 0.611117239532865,\n",
              " 0.6050060671375364,\n",
              " 0.598956006466161,\n",
              " 0.5929664464014994,\n",
              " 0.5870367819374844,\n",
              " 0.5811664141181095,\n",
              " 0.5753547499769285,\n",
              " 0.5696012024771592,\n",
              " 0.5639051904523875,\n",
              " 0.5582661385478637,\n",
              " 0.5526834771623851,\n",
              " 0.5471566423907612,\n",
              " 0.5416850759668536,\n",
              " 0.536268225207185,\n",
              " 0.5309055429551132,\n",
              " 0.525596487525562,\n",
              " 0.5203405226503064,\n",
              " 0.5151371174238033,\n",
              " 0.5099857462495653,\n",
              " 0.5048858887870696,\n",
              " 0.4998370298991989,\n",
              " 0.49483865960020695,\n",
              " 0.4898902730042049,\n",
              " 0.48499137027416284,\n",
              " 0.4801414565714212,\n",
              " 0.47534004200570695,\n",
              " 0.4705866415856499,\n",
              " 0.46588077516979337,\n",
              " 0.46122196741809546,\n",
              " 0.4566097477439145,\n",
              " 0.45204365026647536,\n",
              " 0.4475232137638106,\n",
              " 0.4430479816261725,\n",
              " 0.43861750180991077,\n",
              " 0.43423132679181164,\n",
              " 0.4298890135238935,\n",
              " 0.4255901233886546,\n",
              " 0.421334222154768,\n",
              " 0.41712087993322033,\n",
              " 0.41294967113388814,\n",
              " 0.40882017442254925,\n",
              " 0.4047319726783238,\n",
              " 0.40068465295154054,\n",
              " 0.3966778064220251,\n",
              " 0.39271102835780486,\n",
              " 0.3887839180742268,\n",
              " 0.38489607889348454,\n",
              " 0.38104711810454966,\n",
              " 0.37723664692350417,\n",
              " 0.37346428045426916,\n",
              " 0.36972963764972644,\n",
              " 0.3660323412732292,\n",
              " 0.3623720178604969,\n",
              " 0.3587482976818919,\n",
              " 0.355160814705073,\n",
              " 0.35160920655802225,\n",
              " 0.348093114492442,\n",
              " 0.3446121833475176,\n",
              " 0.34116606151404244,\n",
              " 0.337754400898902,\n",
              " 0.334376856889913,\n",
              " 0.33103308832101386,\n",
              " 0.3277227574378037,\n",
              " 0.3244455298634257,\n",
              " 0.3212010745647914,\n",
              " 0.3179890638191435,\n",
              " 0.31480917318095203,\n",
              " 0.3116610814491425,\n",
              " 0.30854447063465107,\n",
              " 0.3054590259283046,\n",
              " 0.30240443566902153,\n",
              " 0.2993803913123313,\n",
              " 0.296386587399208,\n",
              " 0.2934227215252159,\n",
              " 0.29048849430996376,\n",
              " 0.2875836093668641,\n",
              " 0.28470777327319546,\n",
              " 0.2818606955404635,\n",
              " 0.27904208858505886,\n",
              " 0.2762516676992083,\n",
              " 0.2734891510222162,\n",
              " 0.27075425951199406,\n",
              " 0.2680467169168741,\n",
              " 0.26536624974770534,\n",
              " 0.2627125872502283,\n",
              " 0.26008546137772603,\n",
              " 0.25748460676394874,\n",
              " 0.2549097606963093,\n",
              " 0.2523606630893462,\n",
              " 0.2498370564584527,\n",
              " 0.24733868589386818,\n",
              " 0.24486529903492948,\n",
              " 0.2424166460445802,\n",
              " 0.2399924795841344,\n",
              " 0.23759255478829303,\n",
              " 0.23521662924041012,\n",
              " 0.232864462948006,\n",
              " 0.23053581831852593,\n",
              " 0.22823046013534068,\n",
              " 0.22594815553398728,\n",
              " 0.2236886739786474,\n",
              " 0.22145178723886091,\n",
              " 0.2192372693664723,\n",
              " 0.21704489667280757,\n",
              " 0.2148744477060795,\n",
              " 0.2127257032290187,\n",
              " 0.21059844619672852,\n",
              " 0.20849246173476124,\n",
              " 0.2064075371174136,\n",
              " 0.2043434617462395,\n",
              " 0.2023000271287771,\n",
              " 0.2002770268574893,\n",
              " 0.19827425658891443,\n",
              " 0.19629151402302528,\n",
              " 0.19432859888279502,\n",
              " 0.19238531289396707,\n",
              " 0.1904614597650274,\n",
              " 0.1885568451673771,\n",
              " 0.18667127671570335,\n",
              " 0.1848045639485463,\n",
              " 0.18295651830906084,\n",
              " 0.18112695312597024,\n",
              " 0.17931568359471053,\n",
              " 0.17752252675876343,\n",
              " 0.1757473014911758,\n",
              " 0.173989828476264,\n",
              " 0.1722499301915014,\n",
              " 0.17052743088958636,\n",
              " 0.1688221565806905,\n",
              " 0.1671339350148836,\n",
              " 0.16546259566473476,\n",
              " 0.16380796970808742,\n",
              " 0.16216989001100654,\n",
              " 0.16054819111089647,\n",
              " 0.1589427091997875,\n",
              " 0.15735328210778962,\n",
              " 0.15577974928671173,\n",
              " 0.1542219517938446,\n",
              " 0.15267973227590617,\n",
              " 0.1511529349531471,\n",
              " 0.14964140560361563,\n",
              " 0.14814499154757946,\n",
              " 0.14666354163210368,\n",
              " 0.14519690621578263,\n",
              " 0.1437449371536248,\n",
              " 0.14230748778208857,\n",
              " 0.14088441290426768,\n",
              " 0.139475568775225,\n",
              " 0.13808081308747275,\n",
              " 0.136700004956598,\n",
              " 0.13533300490703204,\n",
              " 0.13397967485796172,\n",
              " 0.1326398781093821,\n",
              " 0.13131347932828827,\n",
              " 0.1300003445350054,\n",
              " 0.12870034108965533,\n",
              " 0.1274133376787588,\n",
              " 0.12613920430197118,\n",
              " 0.12487781225895148,\n",
              " 0.12362903413636196,\n",
              " 0.12239274379499834,\n",
              " 0.12116881635704835,\n",
              " 0.11995712819347787,\n",
              " 0.11875755691154309,\n",
              " 0.11756998134242766,\n",
              " 0.11639428152900338,\n",
              " 0.11523033871371334,\n",
              " 0.1140780353265762,\n",
              " 0.11293725497331045,\n",
              " 0.11180788242357734,\n",
              " 0.11068980359934157,\n",
              " 0.10958290556334815,\n",
              " 0.10848707650771466,\n",
              " 0.10740220574263752,\n",
              " 0.10632818368521114,\n",
              " 0.10526490184835903,\n",
              " 0.10421225282987544,\n",
              " 0.10317013030157669,\n",
              " 0.10213842899856092,\n",
              " 0.10111704470857531,\n",
              " 0.10010587426148955,\n",
              " 0.09910481551887466,\n",
              " 0.0981137673636859,\n",
              " 0.09713262969004904,\n",
              " 0.09616130339314856,\n",
              " 0.09519969035921708,\n",
              " 0.0942476934556249,\n",
              " 0.09330521652106866,\n",
              " 0.09237216435585796,\n",
              " 0.09144844271229938,\n",
              " 0.0905339582851764,\n",
              " 0.08962861870232462,\n",
              " 0.08873233251530138,\n",
              " 0.08784500919014836,\n",
              " 0.08696655909824688,\n",
              " 0.0860968935072644,\n",
              " 0.08523592457219176,\n",
              " 0.08438356532646984,\n",
              " 0.08353972967320515,\n",
              " 0.0827043323764731,\n",
              " 0.08187728905270836,\n",
              " 0.08105851616218128,\n",
              " 0.08024793100055946,\n",
              " 0.07944545169055386,\n",
              " 0.07865099717364833,\n",
              " 0.07786448720191184,\n",
              " 0.07708584232989273,\n",
              " 0.0763149839065938,\n",
              " 0.07555183406752786,\n",
              " 0.07479631572685258,\n",
              " 0.07404835256958406,\n",
              " 0.07330786904388821,\n",
              " 0.07257479035344933,\n",
              " 0.07184904244991483,\n",
              " 0.07113055202541568,\n",
              " 0.07041924650516153,\n",
              " 0.06971505404010991,\n",
              " 0.06901790349970881,\n",
              " 0.06832772446471172,\n",
              " 0.0676444472200646,\n",
              " 0.06696800274786396,\n",
              " 0.06629832272038531,\n",
              " 0.06563533949318147,\n",
              " 0.06497898609824965,\n",
              " 0.06432919623726716,\n",
              " 0.06368590427489448,\n",
              " 0.06304904523214554,\n",
              " 0.06241855477982408,\n",
              " 0.06179436923202584,\n",
              " 0.06117642553970558,\n",
              " 0.06056466128430853,\n",
              " 0.05995901467146544,\n",
              " 0.059359424524750785,\n",
              " 0.05876583027950327,\n",
              " 0.05817817197670824,\n",
              " 0.05759639025694116,\n",
              " 0.057020426354371746,\n",
              " 0.05645022209082803,\n",
              " 0.05588571986991975,\n",
              " 0.05532686267122055,\n",
              " 0.05477359404450834,\n",
              " 0.05422585810406326,\n",
              " 0.05368359952302263,\n",
              " 0.0531467635277924,\n",
              " 0.05261529589251448,\n",
              " 0.05208914293358933,\n",
              " 0.05156825150425344,\n",
              " 0.0510525689892109,\n",
              " 0.050542043299318794,\n",
              " 0.050036622866325604,\n",
              " 0.04953625663766235]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eps = 1.0\n",
        "eps_dec = 0.99\n",
        "\n",
        "all_eps = [eps*eps_dec**i for i in range(300)]\n",
        "all_eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwxaa_ZV4-5X",
        "outputId": "d87623fe-a2c2-4dd0-cebe-e225bcf1f835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-opengl\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y python-opengl ffmpeg\n",
        "!pip install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO-5d4nJ6Ie9",
        "outputId": "9a3a693b-64b8-4760-94e9-7370b71aeecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 17 not upgraded.\n",
            "Need to get 7,812 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.1 [28.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.1 [863 kB]\n",
            "Fetched 7,812 kB in 2s (5,094 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 120901 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.1_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.1_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get install xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpA5nNDG5DlD"
      },
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jcvhV_A5Uqx"
      },
      "outputs": [],
      "source": [
        "def test_agent(agent, episodes=5):\n",
        "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "    for episode in range(episodes):\n",
        "        state, _ = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        img = plt.imshow(env.render()) # only call this once\n",
        "        while not done:\n",
        "            action = agent.get_action([state])  # Get action from your agent here\n",
        "            state, reward, term, trunc, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "            img.set_data(env.render()) # just update the data\n",
        "            ipythondisplay.display(plt.gcf())\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "            if term or trunc:\n",
        "                done = True\n",
        "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lux-i84i51eu",
        "outputId": "d86b1482-b6da-4436-f886-25495de7d80b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7e54cf7945b0>"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "disp = Display(visible=0, size=(400, 300))\n",
        "disp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnoKXiVe5_gz"
      },
      "outputs": [],
      "source": [
        "!which xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "VsMPxQ855Y69",
        "outputId": "f21dea66-e5bb-487c-d717-01c9e194ae37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 5, Total Reward: 60.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming `agent` is an instance of your agent class\n",
        "test_agent(agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7ykqTj-1Jgn"
      },
      "outputs": [],
      "source": [
        "# create env\n",
        "env = gym.make(\"MountainCar-v0\")\n",
        "# draw samples from env to fit scaler and rbf kernels\n",
        "X = np.array([env.observation_space.sample() for _ in range(10000)])\n",
        "# create standard scaler\n",
        "scaler = StandardScaler()\n",
        "# fit scaler to samples\n",
        "X = scaler.fit_transform(X)\n",
        "# create rbf sampler object\n",
        "rbf_samplers = []\n",
        "for e,s in enumerate([5.0, 2.0, 1.0, 0.5]):\n",
        "    rbf_samplers.append((f'rbf{e}',RBFSampler(gamma=s, n_components=500, random_state=42)))\n",
        "# create a FeatureUnion object of RBFSamplers\n",
        "rbf_union = FeatureUnion([*rbf_samplers])\n",
        "rbf_union.fit(X)\n",
        "models = [SGDRegressor(max_iter=100, random_state=42, eta0=0.01) for _ in range(3)]\n",
        "#perform initial fit with dummy variables to initialize models\n",
        "for model in models:\n",
        "    model.partial_fit(rbf_union.transform([env.reset()[0]]), [0])\n",
        "agent = RBF_Mountain_car_Agent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpjf-gNBQ9bP"
      },
      "outputs": [],
      "source": [
        "# set parameters of agent\n",
        "agent.env = env\n",
        "agent.scaler = scaler\n",
        "agent.rbf_union = rbf_union\n",
        "agent.models = models\n",
        "agent.learning_rate = 0.01\n",
        "agent.gamma = 0.99\n",
        "agent.epsilon = 0\n",
        "agent.RBFSamplers = rbf_samplers\n",
        "agent.n_steps = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F11rc8BJMHGC",
        "outputId": "d6e46533-68fa-4548-a232-48cb3acfd098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "update fired...\n",
            "target_a: 0.0\n",
            "target_b: 0.0\n",
            "target_c: -5.0\n",
            "update fired...\n",
            "target_a: 0.0\n",
            "target_b: 0.0\n",
            "target_c: -5.0\n",
            "update fired...\n",
            "target_a: 0.0\n",
            "target_b: 0.0\n",
            "target_c: -5.0\n",
            "update fired...\n",
            "target_a: -0.21687610595489842\n",
            "target_b: -0.20624701882416652\n",
            "target_c: -5.2062470188241665\n",
            "update fired...\n",
            "target_a: -0.21719388959723435\n",
            "target_b: -0.20654922790604896\n",
            "target_c: -5.206549227906049\n",
            "update fired...\n",
            "target_a: -0.21728223218285744\n",
            "target_b: -0.20663324082595896\n",
            "target_c: -5.206633240825959\n",
            "update fired...\n",
            "target_a: -0.41145569422247413\n",
            "target_b: -0.39129027118026977\n",
            "target_c: -5.39129027118027\n",
            "update fired...\n",
            "target_a: -0.4091290376431719\n",
            "target_b: -0.38907764392381894\n",
            "target_c: -5.389077643923819\n",
            "update fired...\n",
            "target_a: -0.411915558270428\n",
            "target_b: -0.3917275973141806\n",
            "target_c: -5.391727597314181\n",
            "update fired...\n",
            "target_a: -0.5885345645282384\n",
            "target_b: -0.5596905148885841\n",
            "target_c: -5.559690514888584\n",
            "update fired...\n",
            "target_a: -0.5847692489915935\n",
            "target_b: -0.556109737278501\n",
            "target_c: -5.556109737278501\n",
            "update fired...\n",
            "target_a: -0.5893014420633543\n",
            "target_b: -0.5604198077939713\n",
            "target_c: -5.560419807793972\n",
            "update fired...\n",
            "target_a: -0.7526412728744081\n",
            "target_b: -0.7157543616476327\n",
            "target_c: -5.715754361647633\n",
            "update fired...\n",
            "target_a: -0.7461933358940867\n",
            "target_b: -0.7096224377369649\n",
            "target_c: -5.709622437736964\n",
            "update fired...\n",
            "target_a: -0.7538154696763888\n",
            "target_b: -0.7168710111229408\n",
            "target_c: -5.716871011122941\n",
            "update fired...\n",
            "target_a: -0.9072351632004672\n",
            "target_b: -0.8627716131230468\n",
            "target_c: -5.862771613123047\n",
            "update fired...\n",
            "target_a: -0.8972549261520164\n",
            "target_b: -0.8532805069943268\n",
            "target_c: -5.853280506994327\n",
            "update fired...\n",
            "target_a: -0.9078792638190513\n",
            "target_b: -0.8633841464024548\n",
            "target_c: -5.8633841464024545\n",
            "update fired...\n",
            "target_a: -1.0532857408746739\n",
            "target_b: -1.0016642592733644\n",
            "target_c: -6.001664259273364\n",
            "update fired...\n",
            "target_a: -1.0402702201937104\n",
            "target_b: -0.9892866286115005\n",
            "target_c: -5.9892866286115005\n",
            "update fired...\n",
            "target_a: -1.053438635996163\n",
            "target_b: -1.0018096610125788\n",
            "target_c: -6.001809661012579\n",
            "update fired...\n",
            "target_a: -1.1922778406811672\n",
            "target_b: -1.1338443632040474\n",
            "target_c: -6.133844363204047\n",
            "update fired...\n",
            "target_a: -1.1772704977729433\n",
            "target_b: -1.119572529422889\n",
            "target_c: -6.119572529422889\n",
            "update fired...\n",
            "target_a: -1.1921530970379455\n",
            "target_b: -1.1337257332405553\n",
            "target_c: -6.1337257332405555\n",
            "update fired...\n",
            "target_a: -1.3254553470573238\n",
            "target_b: -1.2604948466382662\n",
            "target_c: -6.260494846638267\n",
            "update fired...\n",
            "target_a: -1.309930149236054\n",
            "target_b: -1.2457305379875092\n",
            "target_c: -6.245730537987509\n",
            "update fired...\n",
            "target_a: -1.3253712530486021\n",
            "target_b: -1.2604148740727155\n",
            "target_c: -6.2604148740727155\n",
            "update fired...\n",
            "target_a: -1.453756777453536\n",
            "target_b: -1.3825082303330014\n",
            "target_c: -6.382508230333001\n",
            "update fired...\n",
            "target_a: -1.4394704507041176\n",
            "target_b: -1.3689220757446843\n",
            "target_c: -6.368922075744685\n",
            "update fired...\n",
            "target_a: -1.4540843871966456\n",
            "target_b: -1.3828197839389487\n",
            "target_c: -6.382819783938949\n",
            "update fired...\n",
            "target_a: -1.5778054875754703\n",
            "target_b: -1.5004773193618903\n",
            "target_c: -6.50047731936189\n",
            "update fired...\n",
            "target_a: -1.5666477995689463\n",
            "target_b: -1.4898664690877972\n",
            "target_c: -6.489866469087797\n",
            "update fired...\n",
            "target_a: -1.5789463106607546\n",
            "target_b: -1.5015622307646919\n",
            "target_c: -6.501562230764692\n",
            "update fired...\n",
            "target_a: -1.697995257136197\n",
            "target_b: -1.6147765943139152\n",
            "target_c: -6.614776594313915\n",
            "update fired...\n",
            "target_a: -1.6918466151960105\n",
            "target_b: -1.6089292970084\n",
            "target_c: -6.6089292970084\n",
            "update fired...\n",
            "target_a: -1.7003755906163036\n",
            "target_b: -1.6170402677689404\n",
            "target_c: -6.617040267768941\n",
            "update fired...\n",
            "target_a: -1.8146343646685283\n",
            "target_b: -1.7256992250063785\n",
            "target_c: -6.7256992250063785\n",
            "update fired...\n",
            "target_a: -1.8152250149926534\n",
            "target_b: -1.7262609275875915\n",
            "target_c: -6.7262609275875915\n",
            "update fired...\n",
            "target_a: -1.8186971145597934\n",
            "target_b: -1.7295628597282038\n",
            "target_c: -6.729562859728204\n",
            "update fired...\n",
            "target_a: -1.9280849593098355\n",
            "target_b: -1.8335896116654997\n",
            "target_c: -6.8335896116654995\n",
            "update fired...\n",
            "target_a: -1.9368597433371544\n",
            "target_b: -1.8419343439655014\n",
            "target_c: -6.841934343965502\n",
            "update fired...\n",
            "target_a: -1.9342806314440655\n",
            "target_b: -1.8394816342175953\n",
            "target_c: -6.839481634217595\n",
            "update fired...\n",
            "target_a: -2.038871514715733\n",
            "target_b: -1.9389465235192034\n",
            "target_c: -6.938946523519204\n",
            "update fired...\n",
            "target_a: -2.0568693025703655\n",
            "target_b: -1.95606224068917\n",
            "target_c: -6.95606224068917\n",
            "update fired...\n",
            "target_a: -2.0476455894405383\n",
            "target_b: -1.9472905812795722\n",
            "target_c: -6.947290581279573\n",
            "update fired...\n",
            "target_a: -2.14774702086596\n",
            "target_b: -2.0424860465458954\n",
            "target_c: -7.042486046545895\n",
            "update fired...\n",
            "target_a: -2.1755044467991866\n",
            "target_b: -2.06888308241923\n",
            "target_c: -7.06888308241923\n",
            "update fired...\n",
            "target_a: -2.15952788799034\n",
            "target_b: -2.053689533960375\n",
            "target_c: -7.053689533960375\n",
            "update fired...\n",
            "target_a: -2.2557233494620004\n",
            "target_b: -2.1451704606654625\n",
            "target_c: -7.1451704606654625\n",
            "update fired...\n",
            "target_a: -2.2932147357872883\n",
            "target_b: -2.1808243960177682\n",
            "target_c: -7.180824396017768\n",
            "update fired...\n",
            "target_a: -2.2709250441468787\n",
            "target_b: -2.1596271210523996\n",
            "target_c: -7.1596271210524\n",
            "update fired...\n",
            "target_a: -2.3640767864812764\n",
            "target_b: -2.2482135011432605\n",
            "target_c: -7.24821350114326\n",
            "update fired...\n",
            "target_a: -2.410681342988365\n",
            "target_b: -2.292533970661504\n",
            "target_c: -7.292533970661504\n",
            "update fired...\n",
            "target_a: -2.3830814185211984\n",
            "target_b: -2.266286717115237\n",
            "target_c: -7.266286717115237\n",
            "update fired...\n",
            "target_a: -2.474273454135143\n",
            "target_b: -2.353009435614225\n",
            "target_c: -7.353009435614225\n",
            "update fired...\n",
            "target_a: -2.52873088981822\n",
            "target_b: -2.4047979150919003\n",
            "target_c: -7.4047979150919\n",
            "update fired...\n",
            "target_a: -2.4973062758697995\n",
            "target_b: -2.3749134199050035\n",
            "target_c: -7.3749134199050035\n",
            "update fired...\n",
            "target_a: -2.5877140566697587\n",
            "target_b: -2.460890319879305\n",
            "target_c: -7.460890319879304\n",
            "update fired...\n",
            "target_a: -2.578825271396633\n",
            "target_b: -2.452437173528865\n",
            "target_c: -7.452437173528865\n",
            "update fired...\n",
            "target_a: -2.6170298920318746\n",
            "target_b: -2.488769387613184\n",
            "target_c: -7.488769387613184\n",
            "update fired...\n",
            "target_a: -2.706800526012283\n",
            "target_b: -2.574140367301767\n",
            "target_c: -7.5741403673017675\n",
            "update fired...\n",
            "target_a: -2.696974735412236\n",
            "target_b: -2.564796138208721\n",
            "target_c: -7.564796138208721\n",
            "update fired...\n",
            "target_a: -2.739224822460832\n",
            "target_b: -2.604975550599345\n",
            "target_c: -7.604975550599345\n",
            "update fired...\n",
            "target_a: -2.8295699026397254\n",
            "target_b: -2.6908928229068905\n",
            "target_c: -7.690892822906891\n",
            "update fired...\n",
            "target_a: -2.8195346283923044\n",
            "target_b: -2.681349376949575\n",
            "target_c: -7.681349376949575\n",
            "update fired...\n",
            "target_a: -2.863095284490428\n",
            "target_b: -2.7227751274660066\n",
            "target_c: -7.722775127466006\n",
            "update fired...\n",
            "target_a: -2.955828949183245\n",
            "target_b: -2.8109639198796383\n",
            "target_c: -7.810963919879638\n",
            "update fired...\n",
            "target_a: -2.945210177814789\n",
            "target_b: -2.8008655739660737\n",
            "target_c: -7.800865573966074\n",
            "update fired...\n",
            "target_a: -2.9867922994768143\n",
            "target_b: -2.840409757920391\n",
            "target_c: -7.840409757920391\n",
            "update fired...\n",
            "target_a: -3.081478108151981\n",
            "target_b: -2.9304550198372095\n",
            "target_c: -7.9304550198372095\n",
            "update fired...\n",
            "target_a: -3.071829209568551\n",
            "target_b: -2.9212790132918736\n",
            "target_c: -7.921279013291874\n",
            "update fired...\n",
            "target_a: -3.1079543527879747\n",
            "target_b: -2.955633665044758\n",
            "target_c: -7.955633665044758\n",
            "update fired...\n",
            "target_a: -3.2038093562947454\n",
            "target_b: -3.0467908196128266\n",
            "target_c: -8.046790819612827\n",
            "update fired...\n",
            "target_a: -3.1968540916028783\n",
            "target_b: -3.04017643209644\n",
            "target_c: -8.040176432096441\n",
            "update fired...\n",
            "target_a: -3.22430226409907\n",
            "target_b: -3.066279371028257\n",
            "target_c: -8.066279371028257\n",
            "update fired...\n",
            "target_a: -3.3204538239493084\n",
            "target_b: -3.1577185477281984\n",
            "target_c: -8.157718547728198\n",
            "update fired...\n",
            "target_a: -3.317942891819937\n",
            "target_b: -3.1553306762571918\n",
            "target_c: -8.155330676257192\n",
            "update fired...\n",
            "target_a: -3.3341817110969587\n",
            "target_b: -3.170773631811764\n",
            "target_c: -8.170773631811764\n",
            "update fired...\n",
            "target_a: -3.4298844077530655\n",
            "target_b: -3.2617859440803194\n",
            "target_c: -8.26178594408032\n",
            "update fired...\n",
            "target_a: -3.43339494112716\n",
            "target_b: -3.265124426388925\n",
            "target_c: -8.265124426388926\n",
            "update fired...\n",
            "target_a: -3.436891482566847\n",
            "target_b: -3.268449602507131\n",
            "target_c: -8.26844960250713\n",
            "update fired...\n",
            "target_a: -3.5316668519722185\n",
            "target_b: -3.3585800357872357\n",
            "target_c: -8.358580035787236\n",
            "update fired...\n",
            "target_a: -3.542381558403024\n",
            "target_b: -3.3687696149905313\n",
            "target_c: -8.368769614990532\n",
            "update fired...\n",
            "target_a: -3.5327875069828334\n",
            "target_b: -3.359645767551701\n",
            "target_c: -8.3596457675517\n",
            "update fired...\n",
            "target_a: -3.6261103731872057\n",
            "target_b: -3.448394884740208\n",
            "target_c: -8.448394884740209\n",
            "update fired...\n",
            "target_a: -3.6226465395032337\n",
            "target_b: -3.445100813372242\n",
            "target_c: -8.445100813372242\n",
            "update fired...\n",
            "target_a: -3.5928272382611364\n",
            "target_b: -3.416742954596037\n",
            "target_c: -8.416742954596037\n",
            "update fired...\n",
            "target_a: -3.717709387249075\n",
            "target_b: -3.535504635693696\n",
            "target_c: -8.535504635693696\n",
            "update fired...\n",
            "target_a: -3.716362632012032\n",
            "target_b: -3.5342238848636174\n",
            "target_c: -8.534223884863618\n",
            "update fired...\n",
            "target_a: -3.6754398582222123\n",
            "target_b: -3.49530673417519\n",
            "target_c: -8.495306734175191\n",
            "update fired...\n",
            "target_a: -3.806133048310917\n",
            "target_b: -3.619594657539238\n",
            "target_c: -8.619594657539238\n",
            "update fired...\n",
            "target_a: -3.807584805663253\n",
            "target_b: -3.6209752643361783\n",
            "target_c: -8.620975264336177\n",
            "update fired...\n",
            "target_a: -3.759343238424835\n",
            "target_b: -3.575098013900861\n",
            "target_c: -8.575098013900861\n",
            "update fired...\n",
            "target_a: -3.895043447149655\n",
            "target_b: -3.704147562167518\n",
            "target_c: -8.704147562167519\n",
            "update fired...\n",
            "target_a: -3.85114987537349\n",
            "target_b: -3.6624052121538138\n",
            "target_c: -8.662405212153814\n",
            "update fired...\n",
            "target_a: -3.851141342981935\n",
            "target_b: -3.662397097934343\n",
            "target_c: -8.662397097934344\n",
            "update fired...\n",
            "target_a: -3.985167187728502\n",
            "target_b: -3.7898543427177707\n",
            "target_c: -8.78985434271777\n",
            "update fired...\n",
            "target_a: -3.9421070413921235\n",
            "target_b: -3.7489045720046366\n",
            "target_c: -8.748904572004637\n",
            "update fired...\n",
            "target_a: -3.943334985248549\n",
            "target_b: -3.7500723343939333\n",
            "target_c: -8.750072334393934\n",
            "update fired...\n",
            "target_a: -4.076386747885428\n",
            "target_b: -3.8766032367832612\n",
            "target_c: -8.87660323678326\n",
            "update fired...\n",
            "target_a: -4.036833356348409\n",
            "target_b: -3.838988354991758\n",
            "target_c: -8.838988354991757\n",
            "update fired...\n",
            "target_a: -4.038139903137003\n",
            "target_b: -3.840230867987439\n",
            "target_c: -8.840230867987438\n",
            "update fired...\n",
            "target_a: -4.168215523864459\n",
            "target_b: -3.9639314890338166\n",
            "target_c: -8.963931489033817\n",
            "update fired...\n",
            "target_a: -4.133690847036015\n",
            "target_b: -3.931098864893953\n",
            "target_c: -8.931098864893952\n",
            "update fired...\n",
            "target_a: -4.133889732724297\n",
            "target_b: -3.9312880032045765\n",
            "target_c: -8.931288003204576\n",
            "update fired...\n",
            "target_a: -4.25648099591556\n",
            "target_b: -4.0478710747041395\n",
            "target_c: -9.04787107470414\n",
            "update fired...\n",
            "target_a: -4.2536551757470615\n",
            "target_b: -4.045183747841091\n",
            "target_c: -9.04518374784109\n",
            "update fired...\n",
            "target_a: -4.268063627845325\n",
            "target_b: -4.058886042421\n",
            "target_c: -9.058886042421001\n",
            "update fired...\n",
            "target_a: -4.356325585352504\n",
            "target_b: -4.142822285795025\n",
            "target_c: -9.142822285795024\n",
            "update fired...\n",
            "target_a: -4.350237480226713\n",
            "target_b: -4.137032558397652\n",
            "target_c: -9.137032558397653\n",
            "update fired...\n",
            "target_a: -4.3546914142136535\n",
            "target_b: -4.1412682053021435\n",
            "target_c: -9.141268205302143\n",
            "update fired...\n",
            "target_a: -4.435535197025246\n",
            "target_b: -4.218149838352244\n",
            "target_c: -9.218149838352243\n",
            "update fired...\n",
            "target_a: -4.443775131624897\n",
            "target_b: -4.22598593416834\n",
            "target_c: -9.225985934168339\n",
            "update fired...\n",
            "target_a: -4.437508060092757\n",
            "target_b: -4.220026011499263\n",
            "target_c: -9.220026011499263\n",
            "update fired...\n",
            "target_a: -4.511394301708877\n",
            "target_b: -4.2902910921007\n",
            "target_c: -9.2902910921007\n",
            "update fired...\n",
            "target_a: -4.5350317617868345\n",
            "target_b: -4.312770081439746\n",
            "target_c: -9.312770081439746\n",
            "update fired...\n",
            "target_a: -4.5178485969547415\n",
            "target_b: -4.296429062658635\n",
            "target_c: -9.296429062658635\n",
            "update fired...\n",
            "target_a: -4.585095480258708\n",
            "target_b: -4.3603801795674935\n",
            "target_c: -9.360380179567493\n",
            "update fired...\n",
            "target_a: -4.624483061812096\n",
            "target_b: -4.3978373777143895\n",
            "target_c: -9.397837377714389\n",
            "update fired...\n",
            "target_a: -4.59714589665504\n",
            "target_b: -4.371840005657557\n",
            "target_c: -9.371840005657557\n",
            "update fired...\n",
            "target_a: -4.659105834739843\n",
            "target_b: -4.430763290268624\n",
            "target_c: -9.430763290268624\n",
            "update fired...\n",
            "target_a: -4.713638697402613\n",
            "target_b: -4.4826235000534815\n",
            "target_c: -9.482623500053482\n",
            "update fired...\n",
            "target_a: -4.677861014721851\n",
            "target_b: -4.448599279815598\n",
            "target_c: -9.448599279815598\n",
            "update fired...\n",
            "target_a: -4.736406510122454\n",
            "target_b: -4.504275463408037\n",
            "target_c: -9.504275463408037\n",
            "update fired...\n",
            "target_a: -4.804497384535382\n",
            "target_b: -4.569029207463722\n",
            "target_c: -9.569029207463721\n",
            "update fired...\n",
            "target_a: -4.7627491737544885\n",
            "target_b: -4.529327074409965\n",
            "target_c: -9.529327074409965\n",
            "update fired...\n",
            "target_a: -4.819932634788824\n",
            "target_b: -4.583707976872462\n",
            "target_c: -9.58370797687246\n",
            "update fired...\n",
            "target_a: -4.898958152807849\n",
            "target_b: -4.658860458196748\n",
            "target_c: -9.658860458196749\n",
            "update fired...\n",
            "target_a: -4.854124801210312\n",
            "target_b: -4.616224386923822\n",
            "target_c: -9.616224386923822\n",
            "update fired...\n",
            "target_a: -4.911771641448634\n",
            "target_b: -4.671045958398641\n",
            "target_c: -9.67104595839864\n",
            "update fired...\n",
            "target_a: -4.998030829280698\n",
            "target_b: -4.753077587739389\n",
            "target_c: -9.753077587739389\n",
            "update fired...\n",
            "target_a: -4.953043569711776\n",
            "target_b: -4.710295151517075\n",
            "target_c: -9.710295151517075\n",
            "update fired...\n",
            "target_a: -5.012422932056417\n",
            "target_b: -4.766764334276235\n",
            "target_c: -9.766764334276235\n",
            "update fired...\n",
            "target_a: -5.101217744183753\n",
            "target_b: -4.851207317092072\n",
            "target_c: -9.851207317092072\n",
            "update fired...\n",
            "target_a: -5.058794052144657\n",
            "target_b: -4.81086280808287\n",
            "target_c: -9.81086280808287\n",
            "update fired...\n",
            "target_a: -5.120511828932603\n",
            "target_b: -4.869555799710156\n",
            "target_c: -9.869555799710156\n",
            "update fired...\n",
            "target_a: -5.20642150505933\n",
            "target_b: -4.951255046896805\n",
            "target_c: -9.951255046896804\n",
            "update fired...\n",
            "target_a: -5.168954686270006\n",
            "target_b: -4.9156244750267515\n",
            "target_c: -9.915624475026751\n",
            "update fired...\n",
            "target_a: -5.233102834863949\n",
            "target_b: -4.976628726059098\n",
            "target_c: -9.976628726059097\n",
            "update fired...\n",
            "target_a: -5.310430096066798\n",
            "target_b: -5.050166182049026\n",
            "target_c: -10.050166182049026\n",
            "update fired...\n",
            "target_a: -5.279980477425661\n",
            "target_b: -5.021208897698054\n",
            "target_c: -10.021208897698054\n",
            "update fired...\n",
            "target_a: -5.346455600770161\n",
            "target_b: -5.08442607856455\n",
            "target_c: -10.084426078564551\n",
            "update fired...\n",
            "target_a: -5.408779360022106\n",
            "target_b: -5.143695353485512\n",
            "target_c: -10.143695353485512\n",
            "update fired...\n",
            "target_a: -5.428644321962912\n",
            "target_b: -5.16258673463286\n",
            "target_c: -10.16258673463286\n",
            "update fired...\n",
            "target_a: -5.497885731415061\n",
            "target_b: -5.228434626062906\n",
            "target_c: -10.228434626062906\n",
            "update fired...\n",
            "target_a: -5.512271828921453\n",
            "target_b: -5.242115661648377\n",
            "target_c: -10.242115661648377\n",
            "update fired...\n",
            "target_a: -5.51813320862753\n",
            "target_b: -5.247689775427541\n",
            "target_c: -10.247689775427542\n",
            "update fired...\n",
            "target_a: -5.587509907565214\n",
            "target_b: -5.313666325812187\n",
            "target_c: -10.313666325812186\n",
            "update fired...\n",
            "target_a: -5.608372608348506\n",
            "target_b: -5.333506546671138\n",
            "target_c: -10.333506546671138\n",
            "update fired...\n",
            "target_a: -5.599735610622066\n",
            "target_b: -5.3252928477722845\n",
            "target_c: -10.325292847772285\n",
            "update fired...\n",
            "target_a: -5.670184475182176\n",
            "target_b: -5.3922890169957025\n",
            "target_c: -10.392289016995703\n",
            "update fired...\n",
            "target_a: -5.697768211853843\n",
            "target_b: -5.418520876109519\n",
            "target_c: -10.418520876109518\n",
            "update fired...\n",
            "target_a: -5.6757770613485\n",
            "target_b: -5.397607510793085\n",
            "target_c: -10.397607510793085\n",
            "update fired...\n",
            "target_a: -5.747059754009387\n",
            "target_b: -5.465396642243668\n",
            "target_c: -10.465396642243668\n",
            "update fired...\n",
            "target_a: -5.743383594047268\n",
            "target_b: -5.461900650697852\n",
            "target_c: -10.461900650697853\n",
            "update fired...\n",
            "target_a: -5.699948632084607\n",
            "target_b: -5.4205944340535765\n",
            "target_c: -10.420594434053577\n",
            "update fired...\n",
            "target_a: -5.819956419452072\n",
            "target_b: -5.53472064575055\n",
            "target_c: -10.53472064575055\n",
            "update fired...\n",
            "target_a: -5.823387176864991\n",
            "target_b: -5.537983261913857\n",
            "target_c: -10.537983261913858\n",
            "update fired...\n",
            "target_a: -5.766834896616117\n",
            "target_b: -5.484202606098021\n",
            "target_c: -10.484202606098021\n",
            "update fired...\n",
            "target_a: -5.892656255477161\n",
            "target_b: -5.603857466439772\n",
            "target_c: -10.603857466439772\n",
            "update fired...\n",
            "target_a: -5.903200769581828\n",
            "target_b: -5.61388519443434\n",
            "target_c: -10.61388519443434\n",
            "update fired...\n",
            "target_a: -5.838764472058083\n",
            "target_b: -5.552606916636862\n",
            "target_c: -10.552606916636861\n",
            "update fired...\n",
            "target_a: -5.969154420108659\n",
            "target_b: -5.676606459839938\n",
            "target_c: -10.676606459839938\n",
            "update fired...\n",
            "target_a: -5.919528661469881\n",
            "target_b: -5.629412857155722\n",
            "target_c: -10.629412857155721\n",
            "update fired...\n",
            "target_a: -5.921454971699456\n",
            "target_b: -5.6312447590170684\n",
            "target_c: -10.631244759017068\n",
            "update fired...\n",
            "target_a: -6.049310436781811\n",
            "target_b: -5.7528340341357245\n",
            "target_c: -10.752834034135724\n",
            "update fired...\n",
            "target_a: -6.0036207435737525\n",
            "target_b: -5.7093835905118775\n",
            "target_c: -10.709383590511877\n",
            "update fired...\n",
            "target_a: -6.007654843453203\n",
            "target_b: -5.713219979357538\n",
            "target_c: -10.713219979357538\n",
            "update fired...\n",
            "target_a: -6.132045085323283\n",
            "target_b: -5.831513861680638\n",
            "target_c: -10.831513861680637\n",
            "update fired...\n",
            "target_a: -6.092757421850165\n",
            "target_b: -5.794151684633883\n",
            "target_c: -10.794151684633883\n",
            "update fired...\n",
            "target_a: -6.09694953653737\n",
            "target_b: -5.7981383439894545\n",
            "target_c: -10.798138343989454\n",
            "update fired...\n",
            "target_a: -6.215877745602304\n",
            "target_b: -5.911237887462634\n",
            "target_c: -10.911237887462633\n",
            "update fired...\n",
            "target_a: -6.184005456366991\n",
            "target_b: -5.880927657532316\n",
            "target_c: -10.880927657532316\n",
            "update fired...\n",
            "target_a: -6.186274741484212\n",
            "target_b: -5.883085725099179\n",
            "target_c: -10.883085725099178\n",
            "update fired...\n",
            "target_a: -6.2966162537922425\n",
            "target_b: -5.988019405395035\n",
            "target_c: -10.988019405395036\n",
            "update fired...\n",
            "target_a: -6.29939604572062\n",
            "target_b: -5.990662959859715\n",
            "target_c: -10.990662959859716\n",
            "update fired...\n",
            "target_a: -6.277350565260372\n",
            "target_b: -5.969697927296754\n",
            "target_c: -10.969697927296753\n",
            "update fired...\n",
            "target_a: -6.374293137468174\n",
            "target_b: -6.061889348878086\n",
            "target_c: -11.061889348878086\n",
            "update fired...\n",
            "target_a: -6.372929342094944\n",
            "target_b: -6.0605923930480445\n",
            "target_c: -11.060592393048044\n",
            "update fired...\n",
            "target_a: -6.3581139415559935\n",
            "target_b: -6.04650309455022\n",
            "target_c: -11.04650309455022\n",
            "update fired...\n",
            "target_a: -6.416584794755399\n",
            "target_b: -6.102108294152017\n",
            "target_c: -11.102108294152018\n",
            "update fired...\n",
            "target_a: -6.45278077816419\n",
            "target_b: -6.136530314220123\n",
            "target_c: -11.136530314220124\n",
            "update fired...\n",
            "target_a: -6.42388058691078\n",
            "target_b: -6.109046519897923\n",
            "target_c: -11.109046519897923\n",
            "update fired...\n",
            "target_a: -6.471471789575968\n",
            "target_b: -6.154305280095292\n",
            "target_c: -11.154305280095292\n",
            "update fired...\n",
            "target_a: -6.528470783460343\n",
            "target_b: -6.208510756133643\n",
            "target_c: -11.208510756133643\n",
            "update fired...\n",
            "target_a: -6.487829745807083\n",
            "target_b: -6.169861533707782\n",
            "target_c: -11.169861533707781\n",
            "update fired...\n",
            "target_a: -6.52767003468868\n",
            "target_b: -6.207749252019322\n",
            "target_c: -11.207749252019322\n",
            "update fired...\n",
            "target_a: -6.60489059378867\n",
            "target_b: -6.281185235371128\n",
            "target_c: -11.281185235371128\n",
            "update fired...\n",
            "target_a: -6.555154339245933\n",
            "target_b: -6.233886552181691\n",
            "target_c: -11.23388655218169\n",
            "update fired...\n",
            "target_a: -6.588442803113612\n",
            "target_b: -6.265543550096309\n",
            "target_c: -11.265543550096309\n",
            "update fired...\n",
            "target_a: -6.683325274236797\n",
            "target_b: -6.355775836044382\n",
            "target_c: -11.355775836044382\n",
            "update fired...\n",
            "target_a: -6.6281453266191575\n",
            "target_b: -6.303300254906004\n",
            "target_c: -11.303300254906004\n",
            "update fired...\n",
            "target_a: -6.65774789895555\n",
            "target_b: -6.331452006649358\n",
            "target_c: -11.331452006649357\n",
            "update fired...\n",
            "target_a: -6.766306381164416\n",
            "target_b: -6.434690043062235\n",
            "target_c: -11.434690043062236\n",
            "update fired...\n",
            "target_a: -6.709616833878116\n",
            "target_b: -6.380778847659629\n",
            "target_c: -11.380778847659629\n",
            "update fired...\n",
            "target_a: -6.738193921424569\n",
            "target_b: -6.407955373571427\n",
            "target_c: -11.407955373571427\n"
          ]
        }
      ],
      "source": [
        "# reset the env\n",
        "state, _ = agent.env.reset()\n",
        "# instantiate a list used to track state,action,reward pairs used in an update\n",
        "sar_tracker = []\n",
        "# enter a loop that will take a step in the env, record (state, action, reward),\n",
        "# and update the model until termination of episode\n",
        "done = False\n",
        "tot_reward = 0\n",
        "while not done:\n",
        "    # get action\n",
        "    action = agent.get_action([state])\n",
        "    # take step using action\n",
        "    next_state, reward, term, trunc, _ = agent.env.step(action)\n",
        "    # update total reward collected during episode\n",
        "    tot_reward += reward\n",
        "    # append state, action, reward to sar_tracker array\n",
        "    sar_tracker.append((state, action, reward))\n",
        "    # if the lenght of the sar_tracker array is equal to the n_step parameter value,\n",
        "    # then update the model using the sar_tracker array\n",
        "    if len(sar_tracker) == agent.n_steps:\n",
        "        update(sar_tracker, next_state)\n",
        "        # remove first state from tracker as Q for that state has been updated\n",
        "        sar_tracker.remove(sar_tracker[0])\n",
        "    # update state\n",
        "    state = next_state\n",
        "    if term or trunc:\n",
        "        done = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uLCl2ZeWWzl",
        "outputId": "0a567fb8-bd4f-49f8-bf24-3f525c567c10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sar_tracker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTF7TjHrMpyM"
      },
      "outputs": [],
      "source": [
        "def update(sar_tracker, next_state):\n",
        "    \"\"\"\n",
        "    updates the model weights using the sar_tracker array.\n",
        "    Parameters:\n",
        "    -sar_tracker: tracks the (state, action, reward) combinations used in an update.\n",
        "\n",
        "    Returns:\n",
        "    -None\n",
        "    \"\"\"\n",
        "    print('update fired...')\n",
        "    # get action taken at next state\n",
        "    action = agent.get_action([next_state])\n",
        "    # predict return taking action at the next state\n",
        "    # target = agent.models[action].predict([next_state])\n",
        "    target = agent.predict([next_state])[action]\n",
        "    print(f'target_a: {target}')\n",
        "    # multiply target by discount factor (gamma) which is gamma^n_steps\n",
        "    target = target*agent.gamma**len(sar_tracker)\n",
        "    print(f'target_b: {target}')\n",
        "    # add discounted return to the sum of rewards from previous states in tracker\n",
        "    target += np.sum([r for s,a,r in sar_tracker])\n",
        "    print(f'target_c: {target}')\n",
        "    # grab first state from sar_tracker to be used as 'x' value in partial fit\n",
        "    # function of model\n",
        "    s,a,r = sar_tracker[0]\n",
        "    s = agent.scaler.transform([s])\n",
        "    s = agent.rbf_union.transform(s)\n",
        "    agent.models[action].partial_fit(s, [target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D69fvqQBwQd5",
        "outputId": "fc3f6cf5-0024-493c-b484-a4d6ecf91079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s: [1.1, 0.4], a: 1, r: -2\n",
            "[0.]\n"
          ]
        }
      ],
      "source": [
        "# calculate return at initial state\n",
        "s,a,r = sar_tracker[0]\n",
        "print(f's: {s}, a: {a}, r: {r}')\n",
        "s = scaler.transform([s])\n",
        "s = rbf_union.transform(s)\n",
        "prediction = models[a].predict(s)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMYplCTK24FI",
        "outputId": "07e30ced-c0ee-4b5c-f59d-98f706b4b938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "s: [0.4, 0.6], a: 2, r: -1\n",
            "[0.]\n",
            "target: [-2.]\n"
          ]
        }
      ],
      "source": [
        "# calculate return at final state in sar_tracker and then add total reward from states 2-end [1:]\n",
        "\n",
        "s,a,r = sar_tracker[-1]\n",
        "print(f's: {s}, a: {a}, r: {r}')\n",
        "s = scaler.transform([s])\n",
        "s = rbf_union.transform(s)\n",
        "target = models[a].predict(s)\n",
        "print(target)\n",
        "target += np.sum([r for s,a,r in sar_tracker[1:]])\n",
        "print(f'target: {target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emi5BdZc_QXE"
      },
      "outputs": [],
      "source": [
        "sar_tracker.remove(sar_tracker[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JS4l-ukQNaP",
        "outputId": "78aee104-9f2a-48a3-ae14-5b9bd2d5b79c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[([1.4, 0.2], 0, -1), ([0.4, 0.6], 2, -1)]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state, _ = env.reset()\n",
        "for i in range(10):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "int6EyzVQOJZ",
        "outputId": "f8f5fdf6-f625-4c03-d362-18ffab7f0c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.439"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# each reward, except the first reward received, needs to be discounted by a factor of gamma\n",
        "\n",
        "rewards = np.array([-1.0,-1.0,-1.0,-1.0])\n",
        "gamma = 0.9\n",
        "for i in range(len(rewards)):\n",
        "    rewards[i] = rewards[i] * gamma**i\n",
        "sum(rewards)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkdqTfqzzLNU",
        "outputId": "edcb78a5-7a03-4ef3-97e8-3ab8ccb469b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gamma**0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "614C8RA-zUHf",
        "outputId": "ba025e72-69be-4b4a-e900-3f6c122243a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.439"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sar_tracker = [([1.1, 0.9], 0, -1), ([1.4, 0.4], 1, -1), ([0.3, 2.0], 2, -1), ([1.2, 0.3], 0, -1)]\n",
        "\n",
        "np.sum([r*gamma**i for i,(s,a,r) in enumerate(sar_tracker)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHPngW3v1DM8",
        "outputId": "e38ee7aa-d13b-442d-8686-bae89c115325"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([env.observation_space.sample() for _ in range(10000)]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtR614WVoPPs"
      },
      "outputs": [],
      "source": [
        "# play a bunch of episodes and collect all the states to sample from them for\n",
        "# rbf kernels and scale to it\n",
        "\n",
        "# run a bunch of episodes and collect each state visited\n",
        "states = []\n",
        "\n",
        "for i in range(10000):\n",
        "    done = False\n",
        "    state, _ = env.reset()\n",
        "    states.append(state)\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        next_state, reward, term, trunc, _ = env.step(action)\n",
        "        states.append(next_state)\n",
        "        if term or trunc:\n",
        "            done = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-IKicmZo4Sw",
        "outputId": "226a3796-39dc-46a9-a135-7992f8a1399a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([-0.04114367, -0.0146307 ,  0.04465247,  0.00080533], dtype=float32),\n",
              " array([-0.04143628, -0.21036364,  0.04466857,  0.30723557], dtype=float32),\n",
              " array([-0.04564356, -0.01590572,  0.05081329,  0.02896781], dtype=float32),\n",
              " array([-0.04596167,  0.1784521 ,  0.05139264, -0.24725994], dtype=float32),\n",
              " array([-0.04239263, -0.01736472,  0.04644744,  0.06118027], dtype=float32),\n",
              " array([-0.04273992,  0.17706156,  0.04767105, -0.216494  ], dtype=float32),\n",
              " array([-0.03919869,  0.37147075,  0.04334117, -0.49376652], dtype=float32),\n",
              " array([-0.03176928,  0.1757652 ,  0.03346584, -0.18774553], dtype=float32),\n",
              " array([-0.02825397,  0.37039277,  0.02971093, -0.4696863 ], dtype=float32),\n",
              " array([-0.02084612,  0.56508267,  0.0203172 , -0.7528586 ], dtype=float32),\n",
              " array([-0.00954446,  0.36968657,  0.00526003, -0.45385203], dtype=float32),\n",
              " array([-0.00215073,  0.56473374, -0.00381701, -0.74487233], dtype=float32),\n",
              " array([ 0.00914394,  0.7599082 , -0.01871446, -1.038754  ], dtype=float32),\n",
              " array([ 0.0243421 ,  0.5650398 , -0.03948954, -0.75200444], dtype=float32),\n",
              " array([ 0.0356429 ,  0.7606835 , -0.05452963, -1.0568479 ], dtype=float32),\n",
              " array([ 0.05085657,  0.95648396, -0.07566658, -1.366136  ], dtype=float32),\n",
              " array([ 0.06998625,  0.76238656, -0.1029893 , -1.0980476 ], dtype=float32),\n",
              " array([ 0.08523398,  0.9587023 , -0.12495025, -1.4211863 ], dtype=float32),\n",
              " array([ 0.10440803,  0.76532793, -0.15337399, -1.170026  ], dtype=float32),\n",
              " array([ 0.11971459,  0.57249653, -0.1767745 , -0.92908967], dtype=float32),\n",
              " array([ 0.13116452,  0.38014445, -0.1953563 , -0.6967594 ], dtype=float32),\n",
              " array([ 0.1387674 ,  0.57736164, -0.20929149, -1.0440283 ], dtype=float32),\n",
              " array([ 0.15031464,  0.38553932, -0.23017205, -0.82365704], dtype=float32),\n",
              " array([ 0.0091292 , -0.00839429,  0.01697595, -0.04758254], dtype=float32),\n",
              " array([ 0.00896132, -0.2037555 ,  0.0160243 ,  0.25040773], dtype=float32),\n",
              " array([ 0.00488621, -0.008866  ,  0.02103245, -0.03717803], dtype=float32),\n",
              " array([ 0.00470889,  0.18594813,  0.02028889, -0.3231515 ], dtype=float32),\n",
              " array([ 0.00842785,  0.3807754 ,  0.01382586, -0.6093677 ], dtype=float32),\n",
              " array([ 0.01604336,  0.18546292,  0.00163851, -0.31236234], dtype=float32),\n",
              " array([ 0.01975261, -0.00968234, -0.00460874, -0.01916313], dtype=float32),\n",
              " array([ 0.01955897,  0.1855054 , -0.004992  , -0.3132966 ], dtype=float32),\n",
              " array([ 0.02326908, -0.00954508, -0.01125793, -0.02219216], dtype=float32),\n",
              " array([ 0.02307817, -0.20450379, -0.01170177,  0.26691762], dtype=float32),\n",
              " array([ 0.0189881 , -0.0092168 , -0.00636342, -0.02943306], dtype=float32),\n",
              " array([ 0.01880376,  0.18599582, -0.00695208, -0.32411692], dtype=float32),\n",
              " array([ 0.02252368,  0.38121608, -0.01343442, -0.6189841 ], dtype=float32),\n",
              " array([ 0.030148  ,  0.57652307, -0.0258141 , -0.91586775], dtype=float32),\n",
              " array([ 0.04167846,  0.7719844 , -0.04413146, -1.2165506 ], dtype=float32),\n",
              " array([ 0.05711815,  0.9676469 , -0.06846247, -1.522729  ], dtype=float32),\n",
              " array([ 0.07647109,  1.1635258 , -0.09891705, -1.8359714 ], dtype=float32),\n",
              " array([ 0.0997416 ,  1.3595924 , -0.13563648, -2.1576679 ], dtype=float32),\n",
              " array([ 0.12693346,  1.5557592 , -0.17878984, -2.4889705 ], dtype=float32),\n",
              " array([ 0.15804864,  1.7518624 , -0.22856924, -2.830721  ], dtype=float32),\n",
              " array([0.04307996, 0.02113886, 0.00333232, 0.04481152], dtype=float32),\n",
              " array([ 0.04350274, -0.17403072,  0.00422855,  0.33854395], dtype=float32),\n",
              " array([ 0.04002213, -0.3692126 ,  0.01099943,  0.63255733], dtype=float32),\n",
              " array([ 0.03263788, -0.56448627,  0.02365057,  0.9286839 ], dtype=float32),\n",
              " array([ 0.02134815, -0.36969143,  0.04222425,  0.64352596], dtype=float32),\n",
              " array([ 0.01395432, -0.17518263,  0.05509477,  0.36443305], dtype=float32),\n",
              " array([0.01045067, 0.01911481, 0.06238343, 0.0896188 ], dtype=float32),\n",
              " array([ 0.01083296, -0.17684327,  0.06417581,  0.40131298], dtype=float32),\n",
              " array([ 0.0072961 , -0.37281403,  0.07220206,  0.71351874], dtype=float32),\n",
              " array([-1.6018150e-04, -5.6885737e-01,  8.6472444e-02,  1.0280266e+00],\n",
              "       dtype=float32),\n",
              " array([-0.01153733, -0.37498614,  0.10703297,  0.7636975 ], dtype=float32),\n",
              " array([-0.01903705, -0.5714066 ,  0.12230692,  1.0880498 ], dtype=float32),\n",
              " array([-0.03046518, -0.76791024,  0.14406791,  1.4164721 ], dtype=float32),\n",
              " array([-0.04582339, -0.9644924 ,  0.17239736,  1.7505    ], dtype=float32),\n",
              " array([-0.06511324, -1.1611018 ,  0.20740736,  2.0914767 ], dtype=float32),\n",
              " array([-0.08833528, -0.9685884 ,  0.2492369 ,  1.8694369 ], dtype=float32),\n",
              " array([ 0.04398246, -0.01789044,  0.01035827, -0.03779109], dtype=float32),\n",
              " array([ 0.04362465,  0.17708145,  0.00960245, -0.32718796], dtype=float32),\n",
              " array([ 0.04716628,  0.3720654 ,  0.00305869, -0.6168273 ], dtype=float32),\n",
              " array([ 0.05460759,  0.17690085, -0.00927786, -0.32318258], dtype=float32),\n",
              " array([ 0.05814561,  0.37215367, -0.01574151, -0.61877686], dtype=float32),\n",
              " array([ 0.06558868,  0.1772551 , -0.02811705, -0.33109304], dtype=float32),\n",
              " array([ 0.06913378, -0.01745558, -0.03473891, -0.0474078 ], dtype=float32),\n",
              " array([ 0.06878467,  0.17814684, -0.03568706, -0.3508456 ], dtype=float32),\n",
              " array([ 0.07234761, -0.0164499 , -0.04270397, -0.06962611], dtype=float32),\n",
              " array([ 0.07201861,  0.17925744, -0.0440965 , -0.37547064], dtype=float32),\n",
              " array([ 0.07560376, -0.01521133, -0.05160591, -0.09701121], dtype=float32),\n",
              " array([ 0.07529953, -0.20955713, -0.05354613,  0.17895398], dtype=float32),\n",
              " array([ 0.07110839, -0.01371144, -0.04996705, -0.13012856], dtype=float32),\n",
              " array([ 0.07083416, -0.20808333, -0.05256962,  0.14638118], dtype=float32),\n",
              " array([ 0.0666725, -0.0122495, -0.049642 , -0.1624121], dtype=float32),\n",
              " array([ 0.06642751, -0.20662694, -0.05289024,  0.11420611], dtype=float32),\n",
              " array([ 0.06229497, -0.4009527 , -0.05060612,  0.3897447 ], dtype=float32),\n",
              " array([ 0.05427591, -0.59532124, -0.04281123,  0.6660524 ], dtype=float32),\n",
              " array([ 0.04236949, -0.7898224 , -0.02949018,  0.94495416], dtype=float32),\n",
              " array([ 0.02657304, -0.5943159 , -0.0105911 ,  0.6431531 ], dtype=float32),\n",
              " array([ 0.01468672, -0.39904794,  0.00227196,  0.34715384], dtype=float32),\n",
              " array([ 0.00670576, -0.59420216,  0.00921504,  0.64055234], dtype=float32),\n",
              " array([-0.00517828, -0.78945136,  0.02202609,  0.9361229 ], dtype=float32),\n",
              " array([-0.02096731, -0.98486334,  0.04074854,  1.2356448 ], dtype=float32),\n",
              " array([-0.04066458, -1.1804845 ,  0.06546144,  1.54081   ], dtype=float32),\n",
              " array([-0.06427427, -1.3763298 ,  0.09627764,  1.8531805 ], dtype=float32),\n",
              " array([-0.09180086, -1.1823891 ,  0.13334125,  1.5918788 ], dtype=float32),\n",
              " array([-0.11544865, -0.9890783 ,  0.16517882,  1.3435726 ], dtype=float32),\n",
              " array([-0.13523021, -1.1858474 ,  0.19205028,  1.683051  ], dtype=float32),\n",
              " array([-0.15894715, -1.3826045 ,  0.2257113 ,  2.0288768 ], dtype=float32),\n",
              " array([-0.04871136,  0.00757864, -0.01769055, -0.03149317], dtype=float32),\n",
              " array([-0.04855978, -0.18728521, -0.01832042,  0.2555561 ], dtype=float32),\n",
              " array([-0.05230549,  0.00809346, -0.01320929, -0.04284861], dtype=float32),\n",
              " array([-0.05214362,  0.20340231, -0.01406626, -0.33966973], dtype=float32),\n",
              " array([-0.04807558,  0.39872155, -0.02085966, -0.636755  ], dtype=float32),\n",
              " array([-0.04010114,  0.20389663, -0.03359476, -0.35071346], dtype=float32),\n",
              " array([-0.03602321,  0.39947984, -0.04060903, -0.65379775], dtype=float32),\n",
              " array([-0.02803361,  0.20494616, -0.05368498, -0.37417358], dtype=float32),\n",
              " array([-0.02393469,  0.01062627, -0.06116845, -0.09888946], dtype=float32),\n",
              " array([-0.02372217,  0.20656912, -0.06314624, -0.41022637], dtype=float32),\n",
              " array([-0.01959078,  0.01239659, -0.07135077, -0.13810073], dtype=float32),\n",
              " array([-0.01934285, -0.18163472, -0.07411279,  0.13124637], dtype=float32),\n",
              " array([-0.02297555, -0.3756211 , -0.07148786,  0.39965796], dtype=float32),\n",
              " array([-0.03048797, -0.56966   , -0.0634947 ,  0.6689733 ], dtype=float32),\n",
              " array([-0.04188117, -0.7638443 , -0.05011523,  0.9410079 ], dtype=float32),\n",
              " array([-0.05715805, -0.56808406, -0.03129507,  0.6330085 ], dtype=float32),\n",
              " array([-0.06851973, -0.3725398 , -0.0186349 ,  0.33063653], dtype=float32),\n",
              " array([-0.07597053, -0.17715761, -0.01202217,  0.03213578], dtype=float32),\n",
              " array([-0.07951368, -0.37210512, -0.01137946,  0.32100147], dtype=float32),\n",
              " array([-0.08695579, -0.17682298, -0.00495943,  0.02475173], dtype=float32),\n",
              " array([-0.09049225,  0.01836975, -0.00446439, -0.26949182], dtype=float32),\n",
              " array([-0.09012485, -0.17668821, -0.00985423,  0.02177968], dtype=float32),\n",
              " array([-0.09365861, -0.37166747, -0.00941864,  0.31133726], dtype=float32),\n",
              " array([-0.10109197, -0.1764126 , -0.00319189,  0.01569892], dtype=float32),\n",
              " array([-0.10462022,  0.01875498, -0.00287791, -0.27798936], dtype=float32),\n",
              " array([-0.10424512,  0.21391787, -0.0084377 , -0.5715786 ], dtype=float32),\n",
              " array([-0.09996676,  0.40915713, -0.01986927, -0.8669077 ], dtype=float32),\n",
              " array([-0.09178361,  0.60454375, -0.03720742, -1.165771  ], dtype=float32),\n",
              " array([-0.07969274,  0.40992528, -0.06052285, -0.8849818 ], dtype=float32),\n",
              " array([-0.07149424,  0.21567498, -0.07822248, -0.6119227 ], dtype=float32),\n",
              " array([-0.06718074,  0.41179803, -0.09046093, -0.92818165], dtype=float32),\n",
              " array([-0.05894478,  0.60801715, -0.10902457, -1.2478662 ], dtype=float32),\n",
              " array([-0.04678443,  0.8043549 , -0.13398188, -1.572614  ], dtype=float32),\n",
              " array([-0.03069733,  0.61106163, -0.16543417, -1.3245455 ], dtype=float32),\n",
              " array([-0.0184761 ,  0.80784076, -0.19192508, -1.6641003 ], dtype=float32),\n",
              " array([-0.00231929,  1.0046089 , -0.22520709, -2.0099134 ], dtype=float32),\n",
              " array([ 0.0306578 , -0.02751728,  0.01729803,  0.00373486], dtype=float32),\n",
              " array([ 0.03010745, -0.22288299,  0.01737273,  0.30182493], dtype=float32),\n",
              " array([ 0.02564979, -0.41824818,  0.02340923,  0.5999358 ], dtype=float32),\n",
              " array([ 0.01728483, -0.22346142,  0.03540794,  0.31471744], dtype=float32),\n",
              " array([ 0.0128156 , -0.41906938,  0.04170229,  0.61835325], dtype=float32),\n",
              " array([ 0.00443421, -0.6147483 ,  0.05406936,  0.9238733 ], dtype=float32),\n",
              " array([-0.00786075, -0.42039678,  0.07254682,  0.6486607 ], dtype=float32),\n",
              " array([-0.01626869, -0.22635645,  0.08552004,  0.3796759 ], dtype=float32),\n",
              " array([-0.02079582, -0.42258215,  0.09311356,  0.69805104], dtype=float32),\n",
              " array([-0.02924746, -0.22886622,  0.10707457,  0.4360717 ], dtype=float32),\n",
              " array([-0.03382478, -0.42532805,  0.11579601,  0.76049656], dtype=float32),\n",
              " array([-0.04233135, -0.62183875,  0.13100594,  1.0872566 ], dtype=float32),\n",
              " array([-0.05476812, -0.42866474,  0.15275107,  0.8383842 ], dtype=float32),\n",
              " array([-0.06334142, -0.6255056 ,  0.16951875,  1.174942  ], dtype=float32),\n",
              " array([-0.07585153, -0.82237524,  0.19301759,  1.5156137 ], dtype=float32),\n",
              " array([-0.09229903, -0.6300411 ,  0.22332987,  1.2888654 ], dtype=float32),\n",
              " array([-0.01003486, -0.02123646,  0.01863206, -0.02947563], dtype=float32),\n",
              " array([-0.01045959, -0.21662058,  0.01804254,  0.2690272 ], dtype=float32),\n",
              " array([-0.014792  , -0.41199532,  0.02342309,  0.5673458 ], dtype=float32),\n",
              " array([-0.02303191, -0.60743785,  0.03477   ,  0.867315  ], dtype=float32),\n",
              " array([-0.03518067, -0.80301523,  0.0521163 ,  1.170724  ], dtype=float32),\n",
              " array([-0.05124097, -0.6086083 ,  0.07553078,  0.89482486], dtype=float32),\n",
              " array([-0.06341314, -0.41458735,  0.09342728,  0.6268081 ], dtype=float32),\n",
              " array([-0.07170489, -0.6108807 ,  0.10596345,  0.9473916 ], dtype=float32),\n",
              " array([-0.0839225 , -0.8072576 ,  0.12491128,  1.2713999 ], dtype=float32),\n",
              " array([-0.10006765, -0.61393154,  0.15033928,  1.0202987 ], dtype=float32),\n",
              " array([-0.11234628, -0.42109776,  0.17074525,  0.77834404], dtype=float32),\n",
              " array([-0.12076823, -0.22868326,  0.18631212,  0.5438749 ], dtype=float32),\n",
              " array([-0.1253419 , -0.4258673 ,  0.19718963,  0.88899165], dtype=float32),\n",
              " array([-0.13385925, -0.62303966,  0.21496946,  1.2366176 ], dtype=float32),\n",
              " array([ 0.01914049, -0.02565459,  0.04925486,  0.02102168], dtype=float32),\n",
              " array([ 0.0186274 , -0.22144704,  0.04967529,  0.32882926], dtype=float32),\n",
              " array([ 0.01419846, -0.02706616,  0.05625188,  0.05221613], dtype=float32),\n",
              " array([ 0.01365714,  0.16720597,  0.0572962 , -0.22220181], dtype=float32),\n",
              " array([ 0.01700126, -0.02868613,  0.05285216,  0.08799004], dtype=float32),\n",
              " array([ 0.01642754,  0.16563998,  0.05461197, -0.1875608 ], dtype=float32),\n",
              " array([ 0.01974034, -0.03021906,  0.05086075,  0.12183771], dtype=float32),\n",
              " array([ 0.01913596, -0.22603141,  0.0532975 ,  0.43012303], dtype=float32),\n",
              " array([ 0.01461533, -0.421866  ,  0.06189997,  0.7391198 ], dtype=float32),\n",
              " array([ 0.00617801, -0.22765093,  0.07668236,  0.46654212], dtype=float32),\n",
              " array([ 0.00162499, -0.42376783,  0.08601321,  0.7823755 ], dtype=float32),\n",
              " array([-0.00685037, -0.22992672,  0.10166071,  0.51794547], dtype=float32),\n",
              " array([-0.0114489 , -0.03637202,  0.11201963,  0.25894922], dtype=float32),\n",
              " array([-0.01217634,  0.15698734,  0.11719861,  0.00359299], dtype=float32),\n",
              " array([-0.0090366 , -0.03960339,  0.11727047,  0.33083373], dtype=float32),\n",
              " array([-0.00982866,  0.15367101,  0.12388714,  0.0773119 ], dtype=float32),\n",
              " array([-0.00675524, -0.0429891 ,  0.12543339,  0.4063709 ], dtype=float32),\n",
              " array([-0.00761503, -0.23964576,  0.1335608 ,  0.73581916], dtype=float32),\n",
              " array([-0.01240794, -0.04659672,  0.14827718,  0.48797476], dtype=float32),\n",
              " array([-0.01333988, -0.24346544,  0.15803668,  0.8234714 ], dtype=float32),\n",
              " array([-0.01820918, -0.44035536,  0.17450611,  1.1613955 ], dtype=float32),\n",
              " array([-0.02701629, -0.6372667 ,  0.19773401,  1.5033214 ], dtype=float32),\n",
              " array([-0.03976163, -0.44501692,  0.22780044,  1.2783216 ], dtype=float32),\n",
              " array([-0.00543872, -0.0193851 ,  0.04410516, -0.04850445], dtype=float32),\n",
              " array([-0.00582642, -0.21511082,  0.04313507,  0.25776133], dtype=float32),\n",
              " array([-0.01012864, -0.4108212 ,  0.04829029,  0.5637316 ], dtype=float32),\n",
              " array([-0.01834506, -0.6065863 ,  0.05956493,  0.87122875], dtype=float32),\n",
              " array([-0.03047679, -0.80246556,  0.0769895 ,  1.1820284 ], dtype=float32),\n",
              " array([-0.0465261 , -0.9984976 ,  0.10063007,  1.497818  ], dtype=float32),\n",
              " array([-0.06649605, -1.1946883 ,  0.13058643,  1.8201505 ], dtype=float32),\n",
              " array([-0.09038982, -1.001237  ,  0.16698945,  1.5707277 ], dtype=float32),\n",
              " array([-0.11041456, -0.80845535,  0.198404  ,  1.3344446 ], dtype=float32),\n",
              " array([-0.12658367, -1.0054462 ,  0.22509289,  1.682083  ], dtype=float32),\n",
              " array([-0.04317953, -0.01200214,  0.00182251, -0.03009401], dtype=float32),\n",
              " array([-0.04341957,  0.18309362,  0.00122063, -0.32220134], dtype=float32),\n",
              " array([-0.0397577 , -0.01204568, -0.00522339, -0.02913374], dtype=float32),\n",
              " array([-0.03999862,  0.18315078, -0.00580607, -0.3234601 ], dtype=float32),\n",
              " array([-0.0363356 ,  0.37835494, -0.01227527, -0.6179684 ], dtype=float32),\n",
              " array([-0.0287685 ,  0.18340658, -0.02463464, -0.32917672], dtype=float32),\n",
              " array([-0.02510037, -0.01135618, -0.03121817, -0.04436308], dtype=float32),\n",
              " array([-0.02532749,  0.1841992 , -0.03210543, -0.34672987], dtype=float32),\n",
              " array([-0.02164351, -0.01045172, -0.03904003, -0.06434133], dtype=float32),\n",
              " array([-0.02185254,  0.18520759, -0.04032686, -0.36908153], dtype=float32),\n",
              " array([-0.01814839,  0.38087863, -0.04770849, -0.6742023 ], dtype=float32),\n",
              " array([-0.01053082,  0.57663006, -0.06119253, -0.9815163 ], dtype=float32),\n",
              " array([ 1.0017806e-03,  7.7251631e-01, -8.0822863e-02, -1.2927752e+00],\n",
              "       dtype=float32),\n",
              " array([ 0.01645211,  0.9685672 , -0.10667837, -1.6096276 ], dtype=float32),\n",
              " array([ 0.03582345,  1.1647756 , -0.13887091, -1.933571  ], dtype=float32),\n",
              " array([ 0.05911896,  0.97138596, -0.17754233, -1.6869762 ], dtype=float32),\n",
              " array([ 0.07854668,  0.77870643, -0.21128187, -1.4544238 ], dtype=float32),\n",
              " array([-0.00876477,  0.03370452, -0.0430873 , -0.04400708], dtype=float32),\n",
              " array([-0.00809068,  0.22941698, -0.04396744, -0.34996706], dtype=float32),\n",
              " array([-0.00350234,  0.03494702, -0.05096678, -0.07146629], dtype=float32),\n",
              " array([-0.0028034 , -0.1594086 , -0.05239611,  0.20471084], dtype=float32),\n",
              " array([-0.00599157, -0.35374364, -0.04830189,  0.4804159 ], dtype=float32),\n",
              " array([-0.01306644, -0.1579743 , -0.03869357,  0.17290919], dtype=float32),\n",
              " array([-0.01622593, -0.35252172, -0.03523539,  0.4531388 ], dtype=float32),\n",
              " array([-0.02327636, -0.54712814, -0.02617261,  0.7345102 ], dtype=float32),\n",
              " array([-0.03421893, -0.7418789 , -0.01148241,  1.0188425 ], dtype=float32),\n",
              " array([-0.04905651, -0.93684596,  0.00889444,  1.3078979 ], dtype=float32),\n",
              " array([-0.06779343, -0.74183786,  0.0350524 ,  1.0180123 ], dtype=float32),\n",
              " array([-0.08263018, -0.54720026,  0.05541265,  0.7365385 ], dtype=float32),\n",
              " array([-0.09357419, -0.743042  ,  0.07014342,  1.0461333 ], dtype=float32),\n",
              " array([-0.10843503, -0.93902135,  0.09106608,  1.3599846 ], dtype=float32),\n",
              " array([-0.12721546, -0.7451514 ,  0.11826578,  1.0971212 ], dtype=float32),\n",
              " array([-0.14211848, -0.94161505,  0.1402082 ,  1.4244472 ], dtype=float32),\n",
              " array([-0.16095078, -0.748477  ,  0.16869715,  1.1786693 ], dtype=float32),\n",
              " array([-0.17592032, -0.5558984 ,  0.19227053,  0.9432642 ], dtype=float32),\n",
              " array([-0.18703829, -0.7530178 ,  0.21113582,  1.2896746 ], dtype=float32),\n",
              " array([ 0.00285095, -0.00463083, -0.00510049, -0.00943786], dtype=float32),\n",
              " array([ 0.00275833,  0.1905639 , -0.00528925, -0.3037257 ], dtype=float32),\n",
              " array([ 0.00656961, -0.00448228, -0.01136376, -0.01271554], dtype=float32),\n",
              " array([ 0.00647997,  0.19080079, -0.01161807, -0.3089621 ], dtype=float32),\n",
              " array([ 0.01029598,  0.38608634, -0.01779732, -0.6052863 ], dtype=float32),\n",
              " array([ 0.01801771,  0.19121772, -0.02990304, -0.3182618 ], dtype=float32),\n",
              " array([ 0.02184206,  0.38675252, -0.03626828, -0.62022305], dtype=float32),\n",
              " array([ 0.02957712,  0.58236176, -0.04867274, -0.92410445], dtype=float32),\n",
              " array([ 0.04122435,  0.38792986, -0.06715483, -0.6471062 ], dtype=float32),\n",
              " array([ 0.04898295,  0.19380467, -0.08009695, -0.3763034 ], dtype=float32),\n",
              " array([ 5.2859038e-02, -9.3712864e-05, -8.7623022e-02, -1.0991165e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.05285716,  0.19616745, -0.08982126, -0.4289022 ], dtype=float32),\n",
              " array([ 0.05678051,  0.392439  , -0.0983993 , -0.7484946 ], dtype=float32),\n",
              " array([ 0.06462929,  0.5887707 , -0.11336919, -1.0704504 ], dtype=float32),\n",
              " array([ 0.07640471,  0.7851942 , -0.1347782 , -1.3964535 ], dtype=float32),\n",
              " array([ 0.09210859,  0.98171055, -0.16270727, -1.7280595 ], dtype=float32),\n",
              " array([ 0.1117428 ,  0.78877956, -0.19726846, -1.4901105 ], dtype=float32),\n",
              " array([ 0.1275184 ,  0.5965297 , -0.22707067, -1.26495   ], dtype=float32),\n",
              " array([-0.03181141,  0.02863012,  0.03924487,  0.0219521 ], dtype=float32),\n",
              " array([-0.03123881, -0.16703203,  0.03968391,  0.32675436], dtype=float32),\n",
              " array([-0.03457944,  0.02750312,  0.046219  ,  0.04684538], dtype=float32),\n",
              " array([-0.03402938, -0.16825005,  0.04715591,  0.35374513], dtype=float32),\n",
              " array([-0.03739439,  0.02617075,  0.05423081,  0.0762968 ], dtype=float32),\n",
              " array([-0.03687097, -0.169685  ,  0.05575674,  0.3855846 ], dtype=float32),\n",
              " array([-0.04026467, -0.36555234,  0.06346843,  0.69531304], dtype=float32),\n",
              " array([-0.04757572, -0.17136542,  0.0773747 ,  0.4232663 ], dtype=float32),\n",
              " array([-0.05100302, -0.36749336,  0.08584002,  0.73930347], dtype=float32),\n",
              " array([-0.05835289, -0.17365499,  0.1006261 ,  0.47482246], dtype=float32),\n",
              " array([-0.06182599,  0.01991273,  0.11012254,  0.21547382], dtype=float32),\n",
              " array([-0.06142774, -0.17659716,  0.11443202,  0.5407638 ], dtype=float32),\n",
              " array([-0.06495968, -0.37312588,  0.1252473 ,  0.8671985 ], dtype=float32),\n",
              " array([-0.0724222 , -0.56970924,  0.14259127,  1.1964902 ], dtype=float32),\n",
              " array([-0.08381638, -0.37669137,  0.16652107,  0.95168173], dtype=float32),\n",
              " array([-0.09135021, -0.18415426,  0.1855547 ,  0.7156023 ], dtype=float32),\n",
              " array([-0.0950333 ,  0.00798088,  0.19986674,  0.48658738], dtype=float32),\n",
              " array([-0.09487367,  0.19980478,  0.2095985 ,  0.26294985], dtype=float32),\n",
              " array([ 0.02530907, -0.04016047, -0.02011368,  0.01018071], dtype=float32),\n",
              " array([ 0.02450586, -0.23498827, -0.01991007,  0.2964503 ], dtype=float32),\n",
              " array([ 0.0198061 , -0.03958823, -0.01398106, -0.00244486], dtype=float32),\n",
              " array([ 0.01901433,  0.15573141, -0.01402996, -0.29950598], dtype=float32),\n",
              " array([ 0.02212896,  0.3510505 , -0.02002008, -0.59658045], dtype=float32),\n",
              " array([ 0.02914997,  0.15621436, -0.03195169, -0.3102703 ], dtype=float32),\n",
              " array([ 0.03227426, -0.03843814, -0.0381571 , -0.02783281], dtype=float32),\n",
              " array([ 0.0315055 , -0.23299271, -0.03871375,  0.25257117], dtype=float32),\n",
              " array([ 0.02684564, -0.03733995, -0.03366233, -0.05206708], dtype=float32),\n",
              " array([ 0.02609884, -0.23196346, -0.03470367,  0.22980793], dtype=float32),\n",
              " array([ 0.02145957, -0.42657274, -0.03010751,  0.51134527], dtype=float32),\n",
              " array([ 0.01292812, -0.23103993, -0.01988061,  0.20932868], dtype=float32),\n",
              " array([ 0.00830732, -0.03563943, -0.01569403, -0.08955865], dtype=float32),\n",
              " array([ 0.00759453,  0.15970393, -0.01748521, -0.38715145], dtype=float32),\n",
              " array([ 0.01078861,  0.35506967, -0.02522824, -0.68529564], dtype=float32),\n",
              " array([ 0.01789   ,  0.16030687, -0.03893415, -0.40066075], dtype=float32),\n",
              " array([ 0.02109614,  0.35595885, -0.04694736, -0.70536005], dtype=float32),\n",
              " array([ 0.02821532,  0.5516988 , -0.06105457, -1.0124439 ], dtype=float32),\n",
              " array([ 0.03924929,  0.35744217, -0.08130344, -0.73954076], dtype=float32),\n",
              " array([ 0.04639814,  0.16353133, -0.09609426, -0.47351226], dtype=float32),\n",
              " array([ 0.04966876, -0.0301115 , -0.1055645 , -0.2125963 ], dtype=float32),\n",
              " array([ 0.04906653, -0.2235782 , -0.10981642,  0.04500993], dtype=float32),\n",
              " array([ 0.04459497, -0.02706688, -0.10891623, -0.28020263], dtype=float32),\n",
              " array([ 0.04405363,  0.16942656, -0.11452028, -0.6051544 ], dtype=float32),\n",
              " array([ 0.04744216,  0.365948  , -0.12662336, -0.93160105], dtype=float32),\n",
              " array([ 0.05476112,  0.5625302 , -0.14525539, -1.2612416 ], dtype=float32),\n",
              " array([ 0.06601173,  0.75918007, -0.17048022, -1.595665  ], dtype=float32),\n",
              " array([ 0.08119533,  0.56644046, -0.20239352, -1.3606254 ], dtype=float32),\n",
              " array([ 0.09252414,  0.3743474 , -0.22960603, -1.1374655 ], dtype=float32),\n",
              " array([-0.02628943, -0.00243532,  0.02637042,  0.03641639], dtype=float32),\n",
              " array([-0.02633814,  0.19229874,  0.02709875, -0.24783114], dtype=float32),\n",
              " array([-0.02249216,  0.38702342,  0.02214213, -0.53184485], dtype=float32),\n",
              " array([-0.01475169,  0.58182704,  0.01150523, -0.8174694 ], dtype=float32),\n",
              " array([-0.00311515,  0.3865495 , -0.00484416, -0.52119   ], dtype=float32),\n",
              " array([ 0.00461584,  0.5817393 , -0.01526796, -0.8153955 ], dtype=float32),\n",
              " array([ 0.01625062,  0.3868297 , -0.03157587, -0.52755374], dtype=float32),\n",
              " array([ 0.02398722,  0.58238137, -0.04212694, -0.8300168 ], dtype=float32),\n",
              " array([ 0.03563485,  0.3878598 , -0.05872728, -0.55087495], dtype=float32),\n",
              " array([ 0.04339204,  0.5837553 , -0.06974478, -0.86146754], dtype=float32),\n",
              " array([ 0.05506714,  0.77975416, -0.08697413, -1.1752393 ], dtype=float32),\n",
              " array([ 0.07066223,  0.9758918 , -0.11047892, -1.493872  ], dtype=float32),\n",
              " array([ 0.09018006,  1.1721706 , -0.14035636, -1.8189101 ], dtype=float32),\n",
              " array([ 0.11362348,  1.3685465 , -0.17673455, -2.1517065 ], dtype=float32),\n",
              " array([ 0.14099441,  1.5649123 , -0.21976869, -2.493357  ], dtype=float32),\n",
              " array([-0.0241343 ,  0.00212391, -0.02726601,  0.03823092], dtype=float32),\n",
              " array([-0.02409182,  0.19762602, -0.02650139, -0.2629285 ], dtype=float32),\n",
              " array([-0.0201393 ,  0.39311603, -0.03175996, -0.563851  ], dtype=float32),\n",
              " array([-0.01227698,  0.5886689 , -0.04303698, -0.86636823], dtype=float32),\n",
              " array([-5.0360261e-04,  3.9415821e-01, -6.0364347e-02, -5.8752137e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.00737956,  0.5900713 , -0.07211477, -0.89859205], dtype=float32),\n",
              " array([ 0.01918099,  0.39599696, -0.09008662, -0.6294206 ], dtype=float32),\n",
              " array([ 0.02710093,  0.20223998, -0.10267503, -0.3664133 ], dtype=float32),\n",
              " array([ 0.03114573,  0.3986597 , -0.11000329, -0.68962467], dtype=float32),\n",
              " array([ 0.03911892,  0.5951224 , -0.12379579, -1.0148133 ], dtype=float32),\n",
              " array([ 0.05102137,  0.79165834, -0.14409205, -1.3436642 ], dtype=float32),\n",
              " array([ 0.06685454,  0.98826873, -0.17096533, -1.6777401 ], dtype=float32),\n",
              " array([ 0.08661991,  0.79549223, -0.20452014, -1.4428104 ], dtype=float32),\n",
              " array([ 0.10252976,  0.6033896 , -0.23337634, -1.2203727 ], dtype=float32),\n",
              " array([-0.00588876,  0.03971424, -0.04811776,  0.03871783], dtype=float32),\n",
              " array([-0.00509447,  0.23549199, -0.04734341, -0.26875007], dtype=float32),\n",
              " array([-3.8463360e-04,  4.3125647e-01, -5.2718408e-02, -5.7598156e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.0082405 ,  0.62707627, -0.06423804, -0.8847951 ], dtype=float32),\n",
              " array([ 0.02078202,  0.82300884, -0.08193395, -1.1969608 ], dtype=float32),\n",
              " array([ 0.0372422 ,  0.6290374 , -0.10587316, -0.9310413 ], dtype=float32),\n",
              " array([ 0.04982295,  0.8254165 , -0.12449399, -1.2550293 ], dtype=float32),\n",
              " array([ 0.06633127,  1.021893  , -0.14959458, -1.58397   ], dtype=float32),\n",
              " array([ 0.08676913,  1.2184442 , -0.18127397, -1.919321  ], dtype=float32),\n",
              " array([ 0.11113802,  1.025676  , -0.21966039, -1.6879095 ], dtype=float32),\n",
              " array([ 0.01803233, -0.02472582, -0.01334266, -0.01369765], dtype=float32),\n",
              " array([ 0.01753782, -0.2196539 , -0.01361661,  0.27474582], dtype=float32),\n",
              " array([ 0.01314474, -0.41457894, -0.0081217 ,  0.56310314], dtype=float32),\n",
              " array([ 0.00485316, -0.21934399,  0.00314037,  0.2678726 ], dtype=float32),\n",
              " array([ 0.00046628, -0.024267  ,  0.00849782, -0.02381819], dtype=float32),\n",
              " array([-1.9059680e-05,  1.7073207e-01,  8.0214553e-03, -3.1380790e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.00339558,  0.36573884,  0.0017453 , -0.6039504 ], dtype=float32),\n",
              " array([ 0.01071036,  0.5608363 , -0.01033371, -0.89608306], dtype=float32),\n",
              " array([ 0.02192708,  0.75609684, -0.02825537, -1.1919962 ], dtype=float32),\n",
              " array([ 0.03704902,  0.56135213, -0.05209529, -0.9083017 ], dtype=float32),\n",
              " array([ 0.04827606,  0.3669726 , -0.07026133, -0.63243705], dtype=float32),\n",
              " array([ 0.05561552,  0.17289758, -0.08291007, -0.36268264], dtype=float32),\n",
              " array([ 0.05907347,  0.36909404, -0.09016372, -0.68031406], dtype=float32),\n",
              " array([ 0.06645535,  0.565345  , -0.10377   , -0.999967  ], dtype=float32),\n",
              " array([ 0.07776225,  0.37175155, -0.12376934, -0.7415925 ], dtype=float32),\n",
              " array([ 0.08519728,  0.17853579, -0.1386012 , -0.4902813 ], dtype=float32),\n",
              " array([ 0.088768  ,  0.3753129 , -0.14840682, -0.8232348 ], dtype=float32),\n",
              " array([ 0.09627426,  0.5721195 , -0.16487151, -1.1586714 ], dtype=float32),\n",
              " array([ 0.10771664,  0.37948415, -0.18804495, -0.9218896 ], dtype=float32),\n",
              " array([ 0.11530633,  0.18733224, -0.20648274, -0.69370276], dtype=float32),\n",
              " array([ 0.11905297, -0.00441841, -0.22035679, -0.47246197], dtype=float32),\n",
              " array([-0.02600638, -0.03483524, -0.02415024,  0.04569728], dtype=float32),\n",
              " array([-0.02670308,  0.16062453, -0.02323629, -0.25450638], dtype=float32),\n",
              " array([-0.02349059, -0.03415807, -0.02832642,  0.03075781], dtype=float32),\n",
              " array([-0.02417375,  0.16135842, -0.02771126, -0.2707261 ], dtype=float32),\n",
              " array([-0.02094658,  0.3568646 , -0.03312578, -0.57201886], dtype=float32),\n",
              " array([-0.01380929,  0.55243504, -0.04456616, -0.87495077], dtype=float32),\n",
              " array([-0.00276059,  0.35794634, -0.06206518, -0.59660554], dtype=float32),\n",
              " array([ 0.00439834,  0.16374534, -0.07399729, -0.32410035], dtype=float32),\n",
              " array([ 0.00767324,  0.35983863, -0.08047929, -0.63917077], dtype=float32),\n",
              " array([ 0.01487001,  0.55598503, -0.09326271, -0.95607334], dtype=float32),\n",
              " array([ 0.02598972,  0.75222915, -0.11238418, -1.2765398 ], dtype=float32),\n",
              " array([ 0.0410343 ,  0.5587052 , -0.13791497, -1.0210567 ], dtype=float32),\n",
              " array([ 0.0522084 ,  0.36566332, -0.1583361 , -0.77466184], dtype=float32),\n",
              " array([ 0.05952167,  0.17303249, -0.17382935, -0.53568655], dtype=float32),\n",
              " array([ 0.06298232, -0.01927391, -0.18454307, -0.30242297], dtype=float32),\n",
              " array([ 0.06259684, -0.21135207, -0.19059153, -0.07314613], dtype=float32),\n",
              " array([ 0.0583698 , -0.4033033 , -0.19205445,  0.15387177], dtype=float32),\n",
              " array([ 0.05030373, -0.5952309 , -0.18897702,  0.3803525 ], dtype=float32),\n",
              " array([ 0.03839912, -0.3979986 , -0.18136998,  0.03454192], dtype=float32),\n",
              " array([ 0.03043914, -0.59011894, -0.18067913,  0.26496464], dtype=float32),\n",
              " array([ 0.01863676, -0.78226405, -0.17537984,  0.4956595 ], dtype=float32),\n",
              " array([ 0.00299148, -0.9745355 , -0.16546665,  0.728345  ], dtype=float32),\n",
              " array([-0.01649923, -0.77755994, -0.15089975,  0.38849157], dtype=float32),\n",
              " array([-0.03205042, -0.58065426, -0.14312991,  0.05229314], dtype=float32),\n",
              " array([-0.04366351, -0.383801  , -0.14208405, -0.281904  ], dtype=float32),\n",
              " array([-0.05133953, -0.18696845, -0.14772214, -0.6158099 ], dtype=float32),\n",
              " array([-0.0550789 , -0.3797514 , -0.16003834, -0.37305745], dtype=float32),\n",
              " array([-0.06267393, -0.18276092, -0.16749948, -0.7116179 ], dtype=float32),\n",
              " array([-0.06632914, -0.37521634, -0.18173184, -0.47598988], dtype=float32),\n",
              " array([-0.07383347, -0.5673697 , -0.19125164, -0.24564195], dtype=float32),\n",
              " array([-0.08518086, -0.7593189 , -0.19616447, -0.01885364], dtype=float32),\n",
              " array([-0.10036724, -0.5620038 , -0.19654155, -0.36645308], dtype=float32),\n",
              " array([-0.11160732, -0.36471128, -0.20387061, -0.7141063 ], dtype=float32),\n",
              " array([-0.11890154, -0.16743828, -0.21815273, -1.0634112 ], dtype=float32),\n",
              " array([ 0.00742479, -0.01606339, -0.04266935,  0.03539903], dtype=float32),\n",
              " array([ 0.00710352, -0.2105483 , -0.04196137,  0.31431988], dtype=float32),\n",
              " array([ 0.00289255, -0.40504816, -0.03567497,  0.5934799 ], dtype=float32),\n",
              " array([-0.00520841, -0.59965307, -0.02380537,  0.87471527], dtype=float32),\n",
              " array([-0.01720147, -0.40421572, -0.00631107,  0.57464415], dtype=float32),\n",
              " array([-0.02528578, -0.5992486 ,  0.00518182,  0.86533225], dtype=float32),\n",
              " array([-0.03727076, -0.7944407 ,  0.02248846,  1.15964   ], dtype=float32),\n",
              " array([-0.05315957, -0.59961885,  0.04568126,  0.8740921 ], dtype=float32),\n",
              " array([-0.06515194, -0.40514678,  0.0631631 ,  0.5961139 ], dtype=float32),\n",
              " array([-0.07325488, -0.21096301,  0.07508538,  0.32397667], dtype=float32),\n",
              " array([-0.07747415, -0.40706933,  0.08156491,  0.6393617 ], dtype=float32),\n",
              " array([-0.08561553, -0.6032281 ,  0.09435215,  0.9565751 ], dtype=float32),\n",
              " array([-0.09768009, -0.7994836 ,  0.11348365,  1.2773474 ], dtype=float32),\n",
              " array([-0.11366976, -0.6059765 ,  0.13903059,  1.0222465 ], dtype=float32),\n",
              " array([-0.1257893 , -0.80264914,  0.15947552,  1.3551522 ], dtype=float32),\n",
              " array([-0.14184228, -0.60984695,  0.18657857,  1.1163061 ], dtype=float32),\n",
              " array([-0.15403922, -0.8068615 ,  0.2089047 ,  1.4612354 ], dtype=float32),\n",
              " array([-0.17017645, -1.0038412 ,  0.2381294 ,  1.8112532 ], dtype=float32),\n",
              " array([-0.01932008, -0.03447837, -0.01579686,  0.03312315], dtype=float32),\n",
              " array([-0.02000965,  0.16086651, -0.0151344 , -0.2645017 ], dtype=float32),\n",
              " array([-0.01679232, -0.03403619, -0.02042443,  0.02336954], dtype=float32),\n",
              " array([-0.01747304, -0.22885938, -0.01995704,  0.309539  ], dtype=float32),\n",
              " array([-0.02205023, -0.03345885, -0.01376626,  0.01062958], dtype=float32),\n",
              " array([-0.02271941, -0.2283807 , -0.01355367,  0.2989375 ], dtype=float32),\n",
              " array([-0.02728702, -0.03306819, -0.00757492,  0.002011  ], dtype=float32),\n",
              " array([-0.02794839,  0.16216157, -0.0075347 , -0.29305226], dtype=float32),\n",
              " array([-0.02470515, -0.03285215, -0.01339575, -0.00275516], dtype=float32),\n",
              " array([-0.0253622 ,  0.16245933, -0.01345085, -0.29963434], dtype=float32),\n",
              " array([-0.02211301,  0.3577704 , -0.01944354, -0.5965288 ], dtype=float32),\n",
              " array([-0.0149576 ,  0.16292587, -0.03137411, -0.31003335], dtype=float32),\n",
              " array([-0.01169909, -0.03173536, -0.03757478, -0.02740768], dtype=float32),\n",
              " array([-0.01233379, -0.22629887, -0.03812293,  0.2531872 ], dtype=float32),\n",
              " array([-0.01685977, -0.03065389, -0.03305919, -0.05127246], dtype=float32),\n",
              " array([-0.01747285, -0.2252866 , -0.03408464,  0.23079945], dtype=float32),\n",
              " array([-0.02197858, -0.02969459, -0.02946865, -0.07243709], dtype=float32),\n",
              " array([-0.02257247,  0.16583717, -0.03091739, -0.37426993], dtype=float32),\n",
              " array([-0.01925573,  0.36138433, -0.03840279, -0.67653877], dtype=float32),\n",
              " array([-0.01202804,  0.5570183 , -0.05193356, -0.9810609 ], dtype=float32),\n",
              " array([-8.8767731e-04,  7.5279635e-01, -7.1554780e-02, -1.2895937e+00],\n",
              "       dtype=float32),\n",
              " array([ 0.01416825,  0.5586537 , -0.09734666, -1.0201441 ], dtype=float32),\n",
              " array([ 0.02534132,  0.36495423, -0.11774954, -0.75954527], dtype=float32),\n",
              " array([ 0.03264041,  0.56148475, -0.13294044, -1.0868381 ], dtype=float32),\n",
              " array([ 0.0438701 ,  0.75808537, -0.15467721, -1.4181064 ], dtype=float32),\n",
              " array([ 0.05903181,  0.9547466 , -0.18303934, -1.7548705 ], dtype=float32),\n",
              " array([ 0.07812674,  1.1514118 , -0.21813674, -2.0984538 ], dtype=float32),\n",
              " array([-0.01427052,  0.01125203, -0.04978106,  0.03886457], dtype=float32),\n",
              " array([-0.01404548, -0.18312202, -0.04900377,  0.31543487], dtype=float32),\n",
              " array([-0.01770792,  0.01266246, -0.04269507,  0.00770934], dtype=float32),\n",
              " array([-0.01745467,  0.20836988, -0.04254089, -0.2981328 ], dtype=float32),\n",
              " array([-0.01328727,  0.01387935, -0.04850354, -0.0191642 ], dtype=float32),\n",
              " array([-0.01300969, -0.18051466, -0.04888682,  0.25782943], dtype=float32),\n",
              " array([-0.01661998, -0.37490582, -0.04373024,  0.5347008 ], dtype=float32),\n",
              " array([-0.0241181 , -0.5693864 , -0.03303622,  0.81329024], dtype=float32),\n",
              " array([-0.03550582, -0.7640407 , -0.01677042,  1.0954014 ], dtype=float32),\n",
              " array([-0.05078664, -0.9589378 ,  0.00513761,  1.3827757 ], dtype=float32),\n",
              " array([-0.06996539, -0.7638803 ,  0.03279313,  1.0917038 ], dtype=float32),\n",
              " array([-0.085243 , -0.9594187,  0.0546272,  1.3944932], dtype=float32),\n",
              " array([-0.10443138, -0.7650175 ,  0.08251707,  1.1193787 ], dtype=float32),\n",
              " array([-0.11973172, -0.57106924,  0.10490464,  0.8536787 ], dtype=float32),\n",
              " array([-0.1311531 , -0.3775216 ,  0.12197822,  0.5957387 ], dtype=float32),\n",
              " array([-0.13870354, -0.18429887,  0.13389298,  0.34383085], dtype=float32),\n",
              " array([-0.14238952, -0.38104624,  0.1407696 ,  0.6755575 ], dtype=float32),\n",
              " array([-0.15001044, -0.5778146 ,  0.15428075,  1.0090401 ], dtype=float32),\n",
              " array([-0.16156673, -0.7746215 ,  0.17446156,  1.345923  ], dtype=float32),\n",
              " array([-0.17705916, -0.58206886,  0.20138001,  1.1125102 ], dtype=float32),\n",
              " array([-0.18870054, -0.39007804,  0.22363022,  0.8891502 ], dtype=float32),\n",
              " array([-0.01529115,  0.04649884, -0.02328089, -0.03601928], dtype=float32),\n",
              " array([-0.01436117, -0.14828165, -0.02400127,  0.24922833], dtype=float32),\n",
              " array([-0.01732681,  0.04717469, -0.01901671, -0.05092744], dtype=float32),\n",
              " array([-0.01638331,  0.24256408, -0.02003526, -0.3495491 ], dtype=float32),\n",
              " array([-0.01153203,  0.43796515, -0.02702624, -0.6484819 ], dtype=float32),\n",
              " array([-0.00277273,  0.633453  , -0.03999588, -0.9495513 ], dtype=float32),\n",
              " array([ 0.00989633,  0.43889162, -0.0589869 , -0.6696983 ], dtype=float32),\n",
              " array([ 0.01867417,  0.63478196, -0.07238087, -0.98035485], dtype=float32),\n",
              " array([ 0.03136981,  0.4407009 , -0.09198797, -0.71125686], dtype=float32),\n",
              " array([ 0.04018382,  0.63696814, -0.1062131 , -1.0314194 ], dtype=float32),\n",
              " array([ 0.05292318,  0.8333304 , -0.12684149, -1.3554709 ], dtype=float32),\n",
              " array([ 0.06958979,  0.64000773, -0.15395091, -1.105008  ], dtype=float32),\n",
              " array([ 0.08238994,  0.44720796, -0.17605107, -0.86431175], dtype=float32),\n",
              " array([ 0.0913341 ,  0.25486308, -0.1933373 , -0.63174605], dtype=float32),\n",
              " array([ 0.09643137,  0.06288902, -0.20597222, -0.40563786], dtype=float32),\n",
              " array([ 0.09768914, -0.12880795, -0.21408498, -0.18429893], dtype=float32),\n",
              " array([ 0.00055593,  0.03108721, -0.03501045, -0.00868941], dtype=float32),\n",
              " array([ 0.00117767, -0.16351561, -0.03518423,  0.27274495], dtype=float32),\n",
              " array([-0.00209264,  0.03209026, -0.02972933, -0.03082427], dtype=float32),\n",
              " array([-0.00145083, -0.16259302, -0.03034582,  0.25233248], dtype=float32),\n",
              " array([-0.00470269,  0.03294881, -0.02529917, -0.04976554], dtype=float32),\n",
              " array([-0.00404372,  0.22842422, -0.02629448, -0.35032198], dtype=float32),\n",
              " array([ 0.00052477,  0.0336859 , -0.03330092, -0.06604517], dtype=float32),\n",
              " array([ 0.00119849,  0.22926907, -0.03462182, -0.36904594], dtype=float32),\n",
              " array([ 0.00578387,  0.03465572, -0.04200274, -0.08747762], dtype=float32),\n",
              " array([ 0.00647698,  0.23035377, -0.04375229, -0.393111  ], dtype=float32),\n",
              " array([ 0.01108406,  0.03587913, -0.05161452, -0.11453725], dtype=float32),\n",
              " array([ 0.01180164, -0.15846673, -0.05390526,  0.16142537], dtype=float32),\n",
              " array([ 0.0086323 , -0.35277718, -0.05067675,  0.43662724], dtype=float32),\n",
              " array([ 0.00157676, -0.5471465 , -0.04194421,  0.71291435], dtype=float32),\n",
              " array([-0.00936617, -0.7416634 , -0.02768592,  0.99210507], dtype=float32),\n",
              " array([-0.02419944, -0.54618216, -0.00784382,  0.69085693], dtype=float32),\n",
              " array([-0.03512308, -0.74119437,  0.00597332,  0.98106027], dtype=float32),\n",
              " array([-0.04994697, -0.9363959 ,  0.02559453,  1.2756134 ], dtype=float32),\n",
              " array([-0.06867488, -1.1318347 ,  0.05110679,  1.5761997 ], dtype=float32),\n",
              " array([-0.09131158, -1.3275272 ,  0.08263078,  1.8843739 ], dtype=float32),\n",
              " array([-0.11786213, -1.5234452 ,  0.12031826,  2.201514  ], dtype=float32),\n",
              " array([-0.14833103, -1.7195019 ,  0.16434854,  2.5287611 ], dtype=float32),\n",
              " array([-0.18272106, -1.526053  ,  0.21492377,  2.290599  ], dtype=float32),\n",
              " array([ 0.00877242, -0.04104441,  0.00556539, -0.00075632], dtype=float32),\n",
              " array([ 0.00795153, -0.23624574,  0.00555026,  0.29367736], dtype=float32),\n",
              " array([ 0.00322661, -0.43144637,  0.01142381,  0.58810556], dtype=float32),\n",
              " array([-0.00540232, -0.62672645,  0.02318592,  0.8843651 ], dtype=float32),\n",
              " array([-0.01793684, -0.43192685,  0.04087322,  0.5990603 ], dtype=float32),\n",
              " array([-0.02657538, -0.62759614,  0.05285443,  0.9043324 ], dtype=float32),\n",
              " array([-0.0391273 , -0.4332283 ,  0.07094108,  0.6287198 ], dtype=float32),\n",
              " array([-0.04779187, -0.62926483,  0.08351547,  0.9428742 ], dtype=float32),\n",
              " array([-0.06037717, -0.82540673,  0.10237295,  1.2605866 ], dtype=float32),\n",
              " array([-0.0768853 , -1.0216782 ,  0.12758468,  1.5834975 ], dtype=float32),\n",
              " array([-0.09731887, -1.2180662 ,  0.15925464,  1.9130934 ], dtype=float32),\n",
              " array([-0.12168019, -1.0249789 ,  0.1975165 ,  1.6737506 ], dtype=float32),\n",
              " array([-0.14217977, -0.8326222 ,  0.23099151,  1.4485186 ], dtype=float32),\n",
              " array([-0.00661564, -0.02749735, -0.04628458,  0.02221719], dtype=float32),\n",
              " array([-0.00716558,  0.16825676, -0.04584024, -0.28470233], dtype=float32),\n",
              " array([-0.00380045, -0.02618245, -0.05153428, -0.0068222 ], dtype=float32),\n",
              " array([-0.0043241 ,  0.16963924, -0.05167073, -0.31530917], dtype=float32),\n",
              " array([-0.00093131,  0.36545768, -0.05797691, -0.62382925], dtype=float32),\n",
              " array([ 0.00637784,  0.17119107, -0.07045349, -0.3499546 ], dtype=float32),\n",
              " array([ 0.00980166,  0.3672406 , -0.07745259, -0.6639955 ], dtype=float32),\n",
              " array([ 0.01714647,  0.17327668, -0.0907325 , -0.3966702 ], dtype=float32),\n",
              " array([ 0.02061201,  0.36956093, -0.0986659 , -0.71652424], dtype=float32),\n",
              " array([ 0.02800323,  0.56589997, -0.11299638, -1.0385612 ], dtype=float32),\n",
              " array([ 0.03932123,  0.7623273 , -0.1337676 , -1.3644735 ], dtype=float32),\n",
              " array([ 0.05456777,  0.5691102 , -0.16105708, -1.1164474 ], dtype=float32),\n",
              " array([ 0.06594998,  0.76593685, -0.18338603, -1.4550129 ], dtype=float32),\n",
              " array([ 0.08126871,  0.96277463, -0.21248628, -1.7989324 ], dtype=float32),\n",
              " array([-0.04930549, -0.04235002, -0.00478087,  0.00272335], dtype=float32),\n",
              " array([-0.05015249, -0.23740308, -0.0047264 ,  0.29389402], dtype=float32),\n",
              " array([-0.05490055, -0.04221407,  0.00115148, -0.00027578], dtype=float32),\n",
              " array([-0.05574483, -0.2373525 ,  0.00114596,  0.29277024], dtype=float32),\n",
              " array([-0.06049188, -0.4324908 ,  0.00700137,  0.58581436], dtype=float32),\n",
              " array([-0.06914169, -0.6277101 ,  0.01871765,  0.8806945 ], dtype=float32),\n",
              " array([-0.0816959 , -0.43284735,  0.03633154,  0.59395427], dtype=float32),\n",
              " array([-0.09035285, -0.6284585 ,  0.04821063,  0.89785653], dtype=float32),\n",
              " array([-0.10292201, -0.43402204,  0.06616776,  0.6207091 ], dtype=float32),\n",
              " array([-0.11160246, -0.6300026 ,  0.07858194,  0.9334758 ], dtype=float32),\n",
              " array([-0.1242025 , -0.82609177,  0.09725146,  1.2497811 ], dtype=float32),\n",
              " array([-0.14072435, -1.0223163 ,  0.12224708,  1.5712742 ], dtype=float32),\n",
              " array([-0.16117068, -1.2186667 ,  0.15367256,  1.8994528 ], dtype=float32),\n",
              " array([-0.185544  , -1.4150825 ,  0.19166163,  2.2356067 ], dtype=float32),\n",
              " array([-0.21384566, -1.6114361 ,  0.23637375,  2.5807483 ], dtype=float32),\n",
              " array([ 0.03577501, -0.03717407, -0.03439767,  0.0292651 ], dtype=float32),\n",
              " array([ 0.03503153, -0.23178628, -0.03381237,  0.31089982], dtype=float32),\n",
              " array([ 0.0303958 , -0.03619932, -0.02759437,  0.00774813], dtype=float32),\n",
              " array([ 0.02967181,  0.15930729, -0.02743941, -0.29351184], dtype=float32),\n",
              " array([ 0.03285796, -0.03541293, -0.03330965, -0.00960766], dtype=float32),\n",
              " array([ 0.0321497 ,  0.1601705 , -0.0335018 , -0.31261128], dtype=float32),\n",
              " array([ 0.03535311, -0.03445856, -0.03975403, -0.0306792 ], dtype=float32),\n",
              " array([ 0.03466394,  0.16121027, -0.04036761, -0.33563516], dtype=float32),\n",
              " array([ 0.03788815, -0.03331463, -0.04708031, -0.05595037], dtype=float32),\n",
              " array([ 0.03722185,  0.16244966, -0.04819932, -0.36310792], dtype=float32),\n",
              " array([ 0.04047085,  0.35822234, -0.05546148, -0.670591  ], dtype=float32),\n",
              " array([ 0.04763529,  0.16391352, -0.0688733 , -0.39587325], dtype=float32),\n",
              " array([ 0.05091356, -0.03016708, -0.07679076, -0.1256753 ], dtype=float32),\n",
              " array([ 0.05031022, -0.22410972, -0.07930427,  0.14182706], dtype=float32),\n",
              " array([ 0.04582803, -0.02794683, -0.07646773, -0.17478351], dtype=float32),\n",
              " array([ 0.04526909, -0.22189586, -0.0799634 ,  0.09283026], dtype=float32),\n",
              " array([ 0.04083117, -0.41578606, -0.07810679,  0.35925204], dtype=float32),\n",
              " array([ 0.03251545, -0.21964568, -0.07092176,  0.04299841], dtype=float32),\n",
              " array([ 0.02812254, -0.02358218, -0.07006179, -0.27119103], dtype=float32),\n",
              " array([ 0.02765089, -0.21763806, -0.0754856 , -0.00140264], dtype=float32),\n",
              " array([ 0.02329814, -0.02151926, -0.07551366, -0.31691483], dtype=float32),\n",
              " array([ 0.02286775,  0.1745925 , -0.08185195, -0.63242406], dtype=float32),\n",
              " array([ 0.0263596 ,  0.37075523, -0.09450044, -0.9497206 ], dtype=float32),\n",
              " array([ 0.0337747 ,  0.17702368, -0.11349485, -0.68816173], dtype=float32),\n",
              " array([ 0.03731518, -0.01635537, -0.12725808, -0.43325523], dtype=float32),\n",
              " array([ 0.03698807,  0.18031697, -0.13592319, -0.76319116], dtype=float32),\n",
              " array([ 0.04059441,  0.37702304, -0.15118702, -1.0953673 ], dtype=float32),\n",
              " array([ 0.04813487,  0.5737775 , -0.17309436, -1.4314122 ], dtype=float32),\n",
              " array([ 0.05961042,  0.77056116, -0.2017226 , -1.7728128 ], dtype=float32),\n",
              " array([ 0.07502164,  0.967306  , -0.23717886, -2.120851  ], dtype=float32),\n",
              " array([ 0.00414412, -0.04632584, -0.04225229,  0.01516782], dtype=float32),\n",
              " array([ 0.00321761, -0.24081717, -0.04194893,  0.29422596], dtype=float32),\n",
              " array([-0.00159874, -0.43531674, -0.03606442,  0.5733893 ], dtype=float32),\n",
              " array([-0.01030507, -0.62991494, -0.02459663,  0.8544962 ], dtype=float32),\n",
              " array([-0.02290337, -0.43446657, -0.00750671,  0.5541816 ], dtype=float32),\n",
              " array([-0.0315927 , -0.6294823 ,  0.00357693,  0.84449   ], dtype=float32),\n",
              " array([-0.04418235, -0.43440935,  0.02046673,  0.55293405], dtype=float32),\n",
              " array([-0.05287053, -0.62981266,  0.03152541,  0.8519944 ], dtype=float32),\n",
              " array([-0.06546679, -0.43513435,  0.04856529,  0.569389  ], dtype=float32),\n",
              " array([-0.07416947, -0.24072598,  0.05995307,  0.29239285], dtype=float32),\n",
              " array([-0.07898399, -0.04650781,  0.06580094,  0.01920465], dtype=float32),\n",
              " array([-0.07991415, -0.24250868,  0.06618503,  0.33190125], dtype=float32),\n",
              " array([-0.08476432, -0.04838818,  0.07282306,  0.0608022 ], dtype=float32),\n",
              " array([-0.08573209, -0.2444746 ,  0.07403909,  0.37554333], dtype=float32),\n",
              " array([-0.09062158, -0.05047811,  0.08154996,  0.10709341], dtype=float32),\n",
              " array([-0.09163114,  0.14338626,  0.08369183, -0.1587876 ], dtype=float32),\n",
              " array([-0.08876342, -0.05282797,  0.08051608,  0.15908028], dtype=float32),\n",
              " array([-0.08981998, -0.24900481,  0.08369768,  0.4760384 ], dtype=float32),\n",
              " array([-0.09480007, -0.4452027 ,  0.09321845,  0.7938834 ], dtype=float32),\n",
              " array([-0.10370412, -0.25147548,  0.10909612,  0.5319208 ], dtype=float32),\n",
              " array([-0.10873364, -0.44794917,  0.11973453,  0.8568899 ], dtype=float32),\n",
              " array([-0.11769262, -0.6444812 ,  0.13687234,  1.1846951 ], dtype=float32),\n",
              " array([-0.13058224, -0.841087  ,  0.16056624,  1.5169607 ], dtype=float32),\n",
              " array([-0.14740399, -0.6482302 ,  0.19090545,  1.2784005 ], dtype=float32),\n",
              " array([-0.16036859, -0.8452025 ,  0.21647346,  1.6242772 ], dtype=float32),\n",
              " array([-0.03711419, -0.02342848,  0.00223195, -0.03581196], dtype=float32),\n",
              " array([-0.03758276,  0.17166139,  0.00151571, -0.32778984], dtype=float32),\n",
              " array([-0.03414953,  0.36676174, -0.00504009, -0.6199944 ], dtype=float32),\n",
              " array([-0.02681429,  0.17171054, -0.01743997, -0.3289031 ], dtype=float32),\n",
              " array([-0.02338008,  0.36707637, -0.02401804, -0.62703437], dtype=float32),\n",
              " array([-0.01603856,  0.17229773, -0.03655872, -0.34201133], dtype=float32),\n",
              " array([-0.0125926 ,  0.36792022, -0.04339895, -0.6459949 ], dtype=float32),\n",
              " array([-0.0052342 ,  0.5636192 , -0.05631885, -0.9520222 ], dtype=float32),\n",
              " array([ 0.00603819,  0.36929852, -0.07535929, -0.6775523 ], dtype=float32),\n",
              " array([ 0.01342416,  0.17529997, -0.08891034, -0.40951505], dtype=float32),\n",
              " array([ 0.01693016,  0.37156257, -0.09710064, -0.7288513 ], dtype=float32),\n",
              " array([ 0.02436141,  0.5678831 , -0.11167767, -1.0504477 ], dtype=float32),\n",
              " array([ 0.03571907,  0.37440532, -0.13268661, -0.794804  ], dtype=float32),\n",
              " array([ 0.04320718,  0.57107455, -0.1485827 , -1.1261102 ], dtype=float32),\n",
              " array([ 0.05462867,  0.7677975 , -0.17110491, -1.4614662 ], dtype=float32),\n",
              " array([ 0.06998461,  0.9645536 , -0.20033424, -1.8023503 ], dtype=float32),\n",
              " array([ 0.08927569,  1.1612717 , -0.23638123, -2.150031  ], dtype=float32),\n",
              " array([ 0.03950249, -0.00844781,  0.03416619,  0.03758779], dtype=float32),\n",
              " array([ 0.03933353, -0.20404263,  0.03491794,  0.3408517 ], dtype=float32),\n",
              " array([ 0.03525268, -0.39964354,  0.04173498,  0.644338  ], dtype=float32),\n",
              " array([ 0.02725981, -0.20512731,  0.05462174,  0.36508426], dtype=float32),\n",
              " array([ 0.02315726, -0.40098125,  0.06192342,  0.6744778 ], dtype=float32),\n",
              " array([ 0.01513764, -0.59690666,  0.07541298,  0.9859965 ], dtype=float32),\n",
              " array([ 0.00319951, -0.40287125,  0.09513291,  0.7179211 ], dtype=float32),\n",
              " array([-0.00485792, -0.20918554,  0.10949133,  0.4566331 ], dtype=float32),\n",
              " array([-0.00904163, -0.40567133,  0.11862399,  0.7817231 ], dtype=float32),\n",
              " array([-0.01715506, -0.60220665,  0.13425845,  1.109248  ], dtype=float32),\n",
              " array([-0.02919919, -0.79881257,  0.15644342,  1.4408565 ], dtype=float32),\n",
              " array([-0.04517544, -0.99547684,  0.18526053,  1.7780572 ], dtype=float32),\n",
              " array([-0.06508498, -1.1921389 ,  0.22082168,  2.122158  ], dtype=float32),\n",
              " array([ 0.04711037, -0.04886732, -0.00558078, -0.00728546], dtype=float32),\n",
              " array([ 0.04613302, -0.2439088 , -0.00572649,  0.28363144], dtype=float32),\n",
              " array([ 4.1254845e-02, -4.3894860e-01, -5.3860487e-05,  5.7450277e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.03247587, -0.2438259 ,  0.0114362 ,  0.2818029 ], dtype=float32),\n",
              " array([ 0.02759936, -0.04886892,  0.01707225, -0.00725127], dtype=float32),\n",
              " array([ 0.02662198,  0.14600408,  0.01692723, -0.2944992 ], dtype=float32),\n",
              " array([ 0.02954206,  0.34088066,  0.01103724, -0.5817958 ], dtype=float32),\n",
              " array([ 0.03635967,  0.14560582, -0.00059867, -0.2856565 ], dtype=float32),\n",
              " array([ 0.03927179, -0.04950758, -0.0063118 ,  0.00683754], dtype=float32),\n",
              " array([ 0.03828163, -0.24453846, -0.00617505,  0.29752237], dtype=float32),\n",
              " array([ 3.3390868e-02, -4.3957183e-01, -2.2460432e-04,  5.8825141e-01],\n",
              "       dtype=float32),\n",
              " array([ 0.02459943, -0.63469064,  0.01154042,  0.88086355], dtype=float32),\n",
              " array([ 0.01190562, -0.43972734,  0.02915769,  0.5918309 ], dtype=float32),\n",
              " array([ 0.00311107, -0.24502547,  0.04099431,  0.30847338], dtype=float32),\n",
              " array([-0.00178944, -0.05051087,  0.04716378,  0.02899558], dtype=float32),\n",
              " array([-0.00279966, -0.24627635,  0.04774369,  0.33617824], dtype=float32),\n",
              " array([-0.00772518, -0.05186521,  0.05446726,  0.05892516], dtype=float32),\n",
              " array([-0.00876249,  0.1424352 ,  0.05564576, -0.21608777], dtype=float32),\n",
              " array([-0.00591378,  0.3367193 ,  0.05132401, -0.49071145], dtype=float32),\n",
              " array([ 0.0008206 ,  0.14091235,  0.04150978, -0.18230514], dtype=float32),\n",
              " array([ 0.00363885,  0.33541653,  0.03786367, -0.4616097 ], dtype=float32),\n",
              " array([ 0.01034718,  0.13978045,  0.02863148, -0.15723665], dtype=float32),\n",
              " array([ 0.01314279, -0.05573948,  0.02548675,  0.14433955], dtype=float32),\n",
              " array([ 0.012028  , -0.25121698,  0.02837354,  0.44495285], dtype=float32),\n",
              " array([ 0.00700366, -0.05650772,  0.03727259,  0.16134723], dtype=float32),\n",
              " array([ 0.00587351,  0.13806136,  0.04049954, -0.11934809], dtype=float32),\n",
              " array([ 0.00863473,  0.33258036,  0.03811258, -0.39898372], dtype=float32),\n",
              " array([ 0.01528634,  0.13693903,  0.0301329 , -0.09453247], dtype=float32),\n",
              " array([ 0.01802512, -0.05860155,  0.02824225,  0.20750299], dtype=float32),\n",
              " array([ 0.01685309,  0.1361054 ,  0.03239231, -0.07613885], dtype=float32),\n",
              " array([ 0.0195752 , -0.05946558,  0.03086954,  0.2265854 ], dtype=float32),\n",
              " array([ 0.01838589, -0.25501478,  0.03540124,  0.5288437 ], dtype=float32),\n",
              " array([ 0.01328559, -0.45061642,  0.04597812,  0.8324681 ], dtype=float32),\n",
              " array([ 0.00427326, -0.64633554,  0.06262748,  1.1392493 ], dtype=float32),\n",
              " array([-0.00865345, -0.45208582,  0.08541247,  0.8668464 ], dtype=float32),\n",
              " array([-0.01769516, -0.25822356,  0.10274939,  0.60219383], dtype=float32),\n",
              " array([-0.02285963, -0.45462126,  0.11479327,  0.92539185], dtype=float32),\n",
              " array([-0.03195206, -0.26122114,  0.13330111,  0.67087615], dtype=float32),\n",
              " array([-0.03717648, -0.06817951,  0.14671862,  0.42295706], dtype=float32),\n",
              " array([-0.03854007, -0.2650422 ,  0.15517777,  0.75805914], dtype=float32),\n",
              " array([-0.04384092, -0.46192327,  0.17033896,  1.0952716 ], dtype=float32),\n",
              " array([-0.05307939, -0.26940367,  0.19224438,  0.8605094 ], dtype=float32),\n",
              " array([-0.05846746, -0.46655062,  0.20945458,  1.2069545 ], dtype=float32),\n",
              " array([ 0.03150591, -0.02605632, -0.04943578, -0.04507694], dtype=float32),\n",
              " array([ 0.03098479, -0.22043581, -0.05033732,  0.23160788], dtype=float32),\n",
              " array([ 0.02657607, -0.02463207, -0.04570516, -0.07651863], dtype=float32),\n",
              " array([ 0.02608343,  0.17111428, -0.04723553, -0.38326418], dtype=float32),\n",
              " array([ 0.02950571,  0.36687395, -0.05490082, -0.69045824], dtype=float32),\n",
              " array([ 0.03684319,  0.17255507, -0.06870998, -0.4155518 ], dtype=float32),\n",
              " array([ 0.04029429, -0.02152921, -0.07702102, -0.14529718], dtype=float32),\n",
              " array([ 0.03986371, -0.2154685 , -0.07992696,  0.12212751], dtype=float32),\n",
              " array([ 0.03555434, -0.01929781, -0.07748441, -0.19466262], dtype=float32),\n",
              " array([ 0.03516838, -0.2132308 , -0.08137766,  0.07260641], dtype=float32),\n",
              " array([ 0.03090377, -0.0170422 , -0.07992554, -0.24460125], dtype=float32),\n",
              " array([ 0.03056292, -0.210937  , -0.08481756,  0.02183938], dtype=float32),\n",
              " array([ 0.02634418, -0.40474662, -0.08438078,  0.2866023 ], dtype=float32),\n",
              " array([ 0.01824925, -0.59857017, -0.07864872,  0.5515247 ], dtype=float32),\n",
              " array([ 0.00627785, -0.40243685, -0.06761824,  0.23513521], dtype=float32),\n",
              " array([-0.00177089, -0.5965308 , -0.06291553,  0.50574625], dtype=float32),\n",
              " array([-0.01370151, -0.4005813 , -0.0528006 ,  0.19391854], dtype=float32),\n",
              " array([-0.02171313, -0.20474538, -0.04892223, -0.11494214], dtype=float32),\n",
              " array([-0.02580804, -0.39913344, -0.05122108,  0.1619137 ], dtype=float32),\n",
              " array([-0.03379071, -0.20331706, -0.0479828 , -0.14647807], dtype=float32),\n",
              " array([-0.03785705, -0.00754198, -0.05091237, -0.45390424], dtype=float32),\n",
              " array([-0.03800789,  0.18826152, -0.05999045, -0.7621907 ], dtype=float32),\n",
              " array([-0.03424266, -0.00598502, -0.07523426, -0.48897162], dtype=float32),\n",
              " array([-0.03436236,  0.19011323, -0.0850137 , -0.80438495], dtype=float32),\n",
              " array([-0.03056009,  0.38629144, -0.10110139, -1.1225535 ], dtype=float32),\n",
              " array([-0.02283427,  0.58258307, -0.12355246, -1.4451606 ], dtype=float32),\n",
              " array([-0.01118261,  0.7789896 , -0.15245567, -1.7737567 ], dtype=float32),\n",
              " array([ 0.00439719,  0.97546655, -0.18793081, -2.1097023 ], dtype=float32),\n",
              " array([ 0.02390652,  1.1719078 , -0.23012486, -2.454103  ], dtype=float32),\n",
              " array([-0.03083448,  0.00179974,  0.0017262 , -0.01714726], dtype=float32),\n",
              " array([-0.03079848, -0.19334692,  0.00138325,  0.2760798 ], dtype=float32),\n",
              " array([-0.03466542,  0.00175526,  0.00690485, -0.01616652], dtype=float32),\n",
              " array([-0.03463031, -0.19346502,  0.00658152,  0.27868694], dtype=float32),\n",
              " array([-0.03849961, -0.38868025,  0.01215526,  0.5734384 ], dtype=float32),\n",
              " array([-0.04627322, -0.19373082,  0.02362403,  0.28460938], dtype=float32),\n",
              " array([-0.05014784,  0.00104638,  0.02931621, -0.00053005], dtype=float32),\n",
              " array([-0.05012691, -0.19448347,  0.02930561,  0.30125645], dtype=float32),\n",
              " array([-0.05401658,  0.00020879,  0.03533074,  0.01795805], dtype=float32),\n",
              " array([-0.0540124 , -0.19540156,  0.0356899 ,  0.32157555], dtype=float32),\n",
              " array([-0.05792043, -0.3910131 ,  0.04212141,  0.6252966 ], dtype=float32),\n",
              " array([-0.0657407 , -0.586697  ,  0.05462734,  0.93094206], dtype=float32),\n",
              " array([-0.07747463, -0.39235312,  0.07324619,  0.65591365], dtype=float32),\n",
              " array([-0.08532169, -0.58841425,  0.08636446,  0.97073185], dtype=float32),\n",
              " array([-0.09708998, -0.78458256,  0.1057791 ,  1.2892472 ], dtype=float32),\n",
              " array([-0.11278163, -0.9808789 ,  0.13156404,  1.613087  ], dtype=float32),\n",
              " array([-0.13239922, -0.7875325 ,  0.16382578,  1.3641422 ], dtype=float32),\n",
              " array([-0.14814986, -0.9842831 ,  0.19110863,  1.7032661 ], dtype=float32),\n",
              " array([-0.16783552, -1.1810225 ,  0.22517395,  2.0488472 ], dtype=float32),\n",
              " array([-0.03114121,  0.02477416,  0.01437856, -0.02734219], dtype=float32),\n",
              " array([-0.03064572,  0.219687  ,  0.01383171, -0.31545407], dtype=float32),\n",
              " array([-0.02625198,  0.41460922,  0.00752263, -0.603743  ], dtype=float32),\n",
              " array([-0.0179598 ,  0.60962516, -0.00455223, -0.894047  ], dtype=float32),\n",
              " array([-0.0057673 ,  0.41456524, -0.02243317, -0.6027985 ], dtype=float32),\n",
              " array([ 0.00252401,  0.60999364, -0.03448914, -0.9024622 ], dtype=float32),\n",
              " array([ 0.01472388,  0.8055654 , -0.05253838, -1.2057832 ], dtype=float32),\n",
              " array([ 0.03083519,  1.0013255 , -0.07665405, -1.5144572 ], dtype=float32),\n",
              " array([ 0.0508617 ,  1.197287  , -0.10694319, -1.8300507 ], dtype=float32),\n",
              " array([ 0.07480744,  1.0034999 , -0.14354421, -1.572412  ], dtype=float32),\n",
              " array([ 0.09487744,  1.200013  , -0.17499244, -1.9062073 ], dtype=float32),\n",
              " array([ 0.1188777 ,  1.0071603 , -0.21311659, -1.6725317 ], dtype=float32),\n",
              " array([ 0.03715191, -0.04045759, -0.02764808,  0.0063002 ], dtype=float32),\n",
              " array([ 0.03634275,  0.15504974, -0.02752208, -0.2949762 ], dtype=float32),\n",
              " array([ 0.03944375,  0.35055304, -0.0334216 , -0.59621054], dtype=float32),\n",
              " array([ 0.04645481,  0.54612637, -0.04534581, -0.8992309 ], dtype=float32),\n",
              " array([ 0.05737734,  0.35164732, -0.06333043, -0.6211393 ], dtype=float32),\n",
              " array([ 0.06441028,  0.1574643 , -0.07575322, -0.34905535], dtype=float32),\n",
              " array([ 0.06755957,  0.35357732, -0.08273432, -0.66463137], dtype=float32),\n",
              " array([ 0.07463112,  0.15969776, -0.09602695, -0.39910296], dtype=float32),\n",
              " array([ 0.07782507,  0.35604146, -0.10400901, -0.7204502 ], dtype=float32),\n",
              " array([ 0.0849459 ,  0.5524368 , -0.11841802, -1.0439749 ], dtype=float32),\n",
              " array([ 0.09599464,  0.3590692 , -0.13929752, -0.7906883 ], dtype=float32),\n",
              " array([ 0.10317602,  0.555801  , -0.15511128, -1.1237487 ], dtype=float32),\n",
              " array([ 0.11429204,  0.75257796, -0.17758624, -1.4607905 ], dtype=float32),\n",
              " array([ 0.1293436 ,  0.9493764 , -0.20680206, -1.803282  ], dtype=float32),\n",
              " array([ 0.14833112,  0.75707823, -0.2428677 , -1.5813482 ], dtype=float32),\n",
              " array([0.04978618, 0.00572242, 0.04570793, 0.04560957], dtype=float32),\n",
              " array([ 0.04990063,  0.20016016,  0.04662012, -0.23230895], dtype=float32),\n",
              " array([ 0.05390384,  0.39458603,  0.04197394, -0.50992954], dtype=float32),\n",
              " array([ 0.06179556,  0.5890923 ,  0.03177535, -0.7890953 ], dtype=float32),\n",
              " array([ 0.0735774 ,  0.78376377,  0.01599345, -1.0716147 ], dtype=float32),\n",
              " array([ 0.08925268,  0.97867066, -0.00543885, -1.3592358 ], dtype=float32),\n",
              " array([ 0.10882609,  0.7836173 , -0.03262356, -1.0682591 ], dtype=float32),\n",
              " array([ 0.12449844,  0.58894175, -0.05398875, -0.7859908 ], dtype=float32),\n",
              " array([ 0.13627727,  0.78476226, -0.06970856, -1.0951585 ], dtype=float32),\n",
              " array([ 0.15197252,  0.5906242 , -0.09161173, -0.82513636], dtype=float32),\n",
              " array([ 0.16378501,  0.78687173, -0.10811446, -1.1451694 ], dtype=float32),\n",
              " array([ 0.17952244,  0.59331506, -0.13101785, -0.8882534 ], dtype=float32),\n",
              " array([ 0.19138874,  0.4001913 , -0.14878291, -0.63945967], dtype=float32),\n",
              " array([ 0.19939257,  0.59704006, -0.16157211, -0.9750516 ], dtype=float32),\n",
              " array([ 0.21133336,  0.793917  , -0.18107314, -1.3138165 ], dtype=float32),\n",
              " array([ 0.22721171,  0.6014889 , -0.20734946, -1.0828384 ], dtype=float32),\n",
              " array([ 0.23924148,  0.40961564, -0.22900625, -0.86171836], dtype=float32),\n",
              " array([-0.03495115, -0.00334888,  0.04664902, -0.00399901], dtype=float32),\n",
              " array([-0.03501813, -0.19910774,  0.04656904,  0.30302966], dtype=float32),\n",
              " array([-0.03900029, -0.39486137,  0.05262963,  0.61002815], dtype=float32),\n",
              " array([-0.04689752, -0.590678  ,  0.0648302 ,  0.9188123 ], dtype=float32),\n",
              " array([-0.05871107, -0.7866135 ,  0.08320644,  1.231145  ], dtype=float32),\n",
              " array([-0.07444335, -0.5926545 ,  0.10782934,  0.96564746], dtype=float32),\n",
              " array([-0.08629644, -0.39913315,  0.1271423 ,  0.7086918 ], dtype=float32),\n",
              " array([-0.0942791 , -0.20598012,  0.14131613,  0.45858005], dtype=float32),\n",
              " array([-0.0983987 , -0.01310904,  0.15048774,  0.21356618], dtype=float32),\n",
              " array([-0.09866089, -0.21002625,  0.15475905,  0.5496803 ], dtype=float32),\n",
              " array([-0.1028614 , -0.4069446 ,  0.16575266,  0.88684547], dtype=float32),\n",
              " array([-0.1110003 , -0.60388154,  0.18348956,  1.2267106 ], dtype=float32),\n",
              " array([-0.12307793, -0.4115331 ,  0.20802377,  0.9966751 ], dtype=float32),\n",
              " array([-0.13130859, -0.60873747,  0.22795728,  1.3468232 ], dtype=float32),\n",
              " array([ 0.04564538,  0.0132734 , -0.02606602, -0.00872   ], dtype=float32),\n",
              " array([ 0.04591085, -0.18146522, -0.02624042,  0.27562615], dtype=float32),\n",
              " array([ 0.04228154, -0.37620315, -0.0207279 ,  0.5599187 ], dtype=float32),\n",
              " array([ 0.03475748, -0.5710281 , -0.00952952,  0.84599984], dtype=float32),\n",
              " array([ 0.02333692, -0.7660188 ,  0.00739047,  1.1356709 ], dtype=float32),\n",
              " array([ 0.00801654, -0.5709943 ,  0.03010389,  0.8453149 ], dtype=float32),\n",
              " array([-0.00340335, -0.37629575,  0.04701019,  0.56224865], dtype=float32),\n",
              " array([-0.01092926, -0.18186392,  0.05825516,  0.284739  ], dtype=float32),\n",
              " array([-0.01456654,  0.01238088,  0.06394994,  0.01098339], dtype=float32),\n",
              " array([-0.01431892, -0.18359713,  0.06416961,  0.323138  ], dtype=float32),\n",
              " array([-0.01799086, -0.37957135,  0.07063237,  0.6353472 ], dtype=float32),\n",
              " array([-0.02558229, -0.57560366,  0.08333932,  0.94941115], dtype=float32),\n",
              " array([-0.03709437, -0.38169652,  0.10232754,  0.68403333], dtype=float32),\n",
              " array([-0.04472829, -0.18813302,  0.11600821,  0.42523867], dtype=float32),\n",
              " array([-0.04849096,  0.00517101,  0.12451298,  0.1712615 ], dtype=float32),\n",
              " array([-0.04838753,  0.19831124,  0.12793821, -0.07969369], dtype=float32),\n",
              " array([-0.04442131,  0.39138913,  0.12634434, -0.3294322 ], dtype=float32),\n",
              " array([-0.03659353,  0.58450735,  0.11975569, -0.579754  ], dtype=float32),\n",
              " array([-0.02490338,  0.7777655 ,  0.10816061, -0.83244103], dtype=float32),\n",
              " array([-0.00934807,  0.5813449 ,  0.09151179, -0.50779456], dtype=float32),\n",
              " array([ 0.00227883,  0.7750664 ,  0.0813559 , -0.77029395], dtype=float32),\n",
              " array([ 0.01778015,  0.9689801 ,  0.06595002, -1.0363102 ], dtype=float32),\n",
              " array([ 0.03715976,  1.1631663 ,  0.04522382, -1.307581  ], dtype=float32),\n",
              " array([ 0.06042308,  1.3576869 ,  0.0190722 , -1.5857723 ], dtype=float32),\n",
              " array([ 0.08757682,  1.5525769 , -0.01264325, -1.8724474 ], dtype=float32),\n",
              " array([ 0.11862836,  1.7478347 , -0.0500922 , -2.1690276 ], dtype=float32),\n",
              " array([ 0.15358505,  1.5532358 , -0.09347275, -1.8922163 ], dtype=float32),\n",
              " array([ 0.18464977,  1.7492394 , -0.13131708, -2.2123795 ], dtype=float32),\n",
              " array([ 0.21963456,  1.555597  , -0.17556466, -1.9629127 ], dtype=float32),\n",
              " array([ 0.2507465 ,  1.3627154 , -0.21482292, -1.7293891 ], dtype=float32),\n",
              " array([ 0.00400386,  0.04072005, -0.02869075, -0.01093947], dtype=float32),\n",
              " array([ 0.00481826,  0.23624147, -0.02890953, -0.3125348 ], dtype=float32),\n",
              " array([ 0.00954309,  0.04154304, -0.03516023, -0.02910743], dtype=float32),\n",
              " array([ 0.01037395,  0.23715112, -0.03574238, -0.33267316], dtype=float32),\n",
              " array([ 0.01511697,  0.4327631 , -0.04239584, -0.63640976], dtype=float32),\n",
              " array([ 0.02377223,  0.62844986, -0.05512404, -0.9421368 ], dtype=float32),\n",
              " array([ 0.03634123,  0.4341123 , -0.07396677, -0.66727155], dtype=float32),\n",
              " array([ 0.04502347,  0.6301808 , -0.08731221, -0.9822964 ], dtype=float32),\n",
              " array([ 0.05762709,  0.8263573 , -0.10695814, -1.3010775 ], dtype=float32),\n",
              " array([ 0.07415424,  0.63274276, -0.13297968, -1.043701  ], dtype=float32),\n",
              " array([ 0.08680909,  0.8293556 , -0.1538537 , -1.3749975 ], dtype=float32),\n",
              " array([ 0.1033962 ,  1.0260288 , -0.18135366, -1.7115773 ], dtype=float32),\n",
              " array([ 0.12391677,  0.83339405, -0.2155852 , -1.4803901 ], dtype=float32),\n",
              " array([-0.01081498, -0.01949571,  0.02487826, -0.03688735], dtype=float32),\n",
              " array([-0.0112049 , -0.21496542,  0.02414051,  0.26353994], dtype=float32),\n",
              " array([-0.01550421, -0.02019622,  0.02941131, -0.02143213], dtype=float32),\n",
              " array([-0.01590813,  0.17449187,  0.02898267, -0.30469227], dtype=float32),\n",
              " array([-0.01241829, -0.02103086,  0.02288883, -0.00301163], dtype=float32),\n",
              " array([-0.01283891,  0.17375548,  0.02282859, -0.2883859 ], dtype=float32),\n",
              " array([-0.0093638 ,  0.36854458,  0.01706088, -0.5737824 ], dtype=float32),\n",
              " array([-0.00199291,  0.17318763,  0.00558523, -0.27577394], dtype=float32),\n",
              " array([ 1.4708427e-03, -2.2013558e-02,  6.9749054e-05,  1.8665314e-02],\n",
              "       dtype=float32),\n",
              " array([ 0.00103057,  0.1731074 ,  0.00044306, -0.2739956 ], dtype=float32),\n",
              " array([ 0.00449272, -0.02202088, -0.00503686,  0.01882703], dtype=float32),\n",
              " array([ 0.0040523 , -0.21707024, -0.00466032,  0.30991653], dtype=float32),\n",
              " array([-2.8910267e-04, -4.1212547e-01,  1.5380142e-03,  6.0112607e-01],\n",
              "       dtype=float32),\n",
              " array([-0.00853161, -0.6072689 ,  0.01356054,  0.89429307], dtype=float32),\n",
              " array([-0.02067699, -0.41233346,  0.0314464 ,  0.60590345], dtype=float32),\n",
              " array([-0.02892366, -0.6078807 ,  0.04356446,  0.908323  ], dtype=float32),\n",
              " array([-0.04108127, -0.41337466,  0.06173092,  0.6296447 ], dtype=float32),\n",
              " array([-0.04934877, -0.60930127,  0.07432382,  0.94111216], dtype=float32),\n",
              " array([-0.06153479, -0.41525543,  0.09314606,  0.67267805], dtype=float32),\n",
              " array([-0.0698399 , -0.22154316,  0.10659962,  0.41071463], dtype=float32),\n",
              " array([-0.07427076, -0.0280812 ,  0.11481392,  0.15344988], dtype=float32),\n",
              " array([-0.07483239,  0.16522558,  0.11788291, -0.10092005], dtype=float32),\n",
              " array([-0.07152788, -0.03137122,  0.11586452,  0.2265059 ], dtype=float32),\n",
              " array([-0.0721553 ,  0.16192067,  0.12039463, -0.02749995], dtype=float32),\n",
              " array([-0.06891689, -0.03470366,  0.11984463,  0.30061215], dtype=float32),\n",
              " array([-0.06961096, -0.23131178,  0.12585688,  0.62855905], dtype=float32),\n",
              " array([-0.0742372 , -0.42794463,  0.13842805,  0.9580797 ], dtype=float32),\n",
              " array([-0.08279609, -0.62462896,  0.15758964,  1.2908521 ], dtype=float32),\n",
              " array([-0.09528866, -0.4318222 ,  0.1834067 ,  1.0513655 ], dtype=float32),\n",
              " array([-0.10392511, -0.23954327,  0.20443399,  0.82140416], dtype=float32),\n",
              " array([-0.10871597, -0.43678764,  0.22086208,  1.1707954 ], dtype=float32),\n",
              " array([-0.04756359, -0.02324056, -0.02630695,  0.00226362], dtype=float32),\n",
              " array([-0.0480284 , -0.21797554, -0.02626168,  0.2865317 ], dtype=float32),\n",
              " array([-0.05238791, -0.0224891 , -0.02053105, -0.01431692], dtype=float32),\n",
              " array([-0.0528377 ,  0.17292118, -0.02081738, -0.3134063 ], dtype=float32),\n",
              " array([-0.04937927, -0.02189813, -0.02708551, -0.02736051], dtype=float32),\n",
              " array([-0.04981723, -0.21662138, -0.02763272,  0.2566551 ], dtype=float32),\n",
              " array([-0.05414966, -0.41133815, -0.02249962,  0.54049575], dtype=float32),\n",
              " array([-0.06237642, -0.21590728, -0.0116897 ,  0.2408093 ], dtype=float32),\n",
              " array([-0.06669457, -0.4108603 , -0.00687352,  0.5297822 ], dtype=float32),\n",
              " array([-0.07491177, -0.6058849 ,  0.00372213,  0.82029134], dtype=float32),\n",
              " array([-0.08702947, -0.41081408,  0.02012795,  0.5287815 ], dtype=float32),\n",
              " array([-0.09524576, -0.215981  ,  0.03070358,  0.24250825], dtype=float32),\n",
              " array([-0.09956538, -0.02131077,  0.03555375, -0.04033404], dtype=float32),\n",
              " array([-0.09999159,  0.17328379,  0.03474707, -0.3215908 ], dtype=float32),\n",
              " array([-0.09652591,  0.36789414,  0.02831525, -0.6031165 ], dtype=float32),\n",
              " array([-0.08916803,  0.17238782,  0.01625292, -0.30165106], dtype=float32),\n",
              " array([-0.08572028, -0.02296195,  0.0102199 , -0.00388694], dtype=float32),\n",
              " array([-0.08617952, -0.21822897,  0.01014216,  0.2920029 ], dtype=float32),\n",
              " array([-0.0905441 , -0.41349405,  0.01598222,  0.5878672 ], dtype=float32),\n",
              " array([-0.09881397, -0.6088361 ,  0.02773956,  0.88554144], dtype=float32),\n",
              " array([-0.1109907 , -0.41410154,  0.04545039,  0.6017063 ], dtype=float32),\n",
              " array([-0.11927273, -0.21964385,  0.05748452,  0.32367882], dtype=float32),\n",
              " array([-0.12366561, -0.02538554,  0.06395809,  0.04966381], dtype=float32),\n",
              " array([-0.12417331, -0.22136351,  0.06495137,  0.36182058], dtype=float32),\n",
              " array([-0.12860058, -0.41734564,  0.07218778,  0.6742562 ], dtype=float32),\n",
              " array([-0.1369475 , -0.61339265,  0.08567291,  0.9887656 ], dtype=float32),\n",
              " array([-0.14921536, -0.8095506 ,  0.10544822,  1.3070804 ], dtype=float32),\n",
              " array([-0.16540636, -1.0058391 ,  0.13158983,  1.6308221 ], dtype=float32),\n",
              " array([-0.18552315, -1.2022387 ,  0.16420627,  1.9614503 ], dtype=float32),\n",
              " array([-0.20956792, -1.0091934 ,  0.20343527,  1.7238376 ], dtype=float32),\n",
              " array([-0.22975178, -0.8168978 ,  0.23791203,  1.5007406 ], dtype=float32),\n",
              " array([ 0.01365165,  0.00203102, -0.01682436,  0.04544169], dtype=float32),\n",
              " array([ 0.01369227,  0.19739012, -0.01591553, -0.25250164], dtype=float32),\n",
              " array([ 0.01764007,  0.00249901, -0.02096556,  0.03511904], dtype=float32),\n",
              " array([ 0.01769005,  0.19791524, -0.02026318, -0.2641043 ], dtype=float32),\n",
              " array([ 0.02164836,  0.00308829, -0.02554527,  0.02211916], dtype=float32),\n",
              " array([ 0.02171012, -0.19165818, -0.02510288,  0.30663407], dtype=float32),\n",
              " array([ 0.01787696, -0.3864136 , -0.0189702 ,  0.59129566], dtype=float32),\n",
              " array([ 0.01014869, -0.19103126, -0.00714429,  0.292698  ], dtype=float32),\n",
              " array([ 0.00632806, -0.3860506 , -0.00129033,  0.58311915], dtype=float32),\n",
              " array([-0.00139295, -0.58115447,  0.01037205,  0.87539536], dtype=float32),\n",
              " array([-0.01301604, -0.38617504,  0.02787996,  0.58599126], dtype=float32),\n",
              " array([-0.02073954, -0.19145446,  0.03959979,  0.30221954], dtype=float32),\n",
              " array([-0.02456863,  0.00308138,  0.04564418,  0.02228384], dtype=float32),\n",
              " array([-0.024507  ,  0.19752005,  0.04608985, -0.25565565], dtype=float32),\n",
              " array([-0.0205566 ,  0.00177137,  0.04097674,  0.05120116], dtype=float32),\n",
              " array([-0.02052117,  0.19628254,  0.04200076, -0.22827688], dtype=float32),\n",
              " array([-0.01659552,  0.00058632,  0.03743523,  0.07735316], dtype=float32),\n",
              " array([-0.0165838 ,  0.19515218,  0.03898229, -0.20328775], dtype=float32),\n",
              " array([-0.01268075, -0.00050496,  0.03491654,  0.10143287], dtype=float32),\n",
              " array([-0.01269085,  0.19409965,  0.03694519, -0.18003273], dtype=float32),\n",
              " array([-0.00880886,  0.38867396,  0.03334454, -0.46083564], dtype=float32),\n",
              " array([-0.00103538,  0.19309698,  0.02412783, -0.15783176], dtype=float32),\n",
              " array([ 0.00282656,  0.38786533,  0.02097119, -0.44280633], dtype=float32),\n",
              " array([ 0.01058387,  0.58268434,  0.01211506, -0.72880554], dtype=float32),\n",
              " array([ 0.02223755,  0.38739705, -0.00246105, -0.43233433], dtype=float32),\n",
              " array([ 0.02998549,  0.58255374, -0.01110773, -0.72579205], dtype=float32),\n",
              " array([ 0.04163657,  0.38758713, -0.02562358, -0.4366258 ], dtype=float32),\n",
              " array([ 0.04938831,  0.1928371 , -0.03435609, -0.15212914], dtype=float32),\n",
              " array([ 0.05324505, -0.0017765 , -0.03739867,  0.12952028], dtype=float32),\n",
              " array([ 0.05320952, -0.1963433 , -0.03480827,  0.41017377], dtype=float32),\n",
              " array([ 0.04928266, -0.3909549 , -0.02660479,  0.6916828 ], dtype=float32),\n",
              " array([ 0.04146356, -0.19547413, -0.01277114,  0.3907445 ], dtype=float32),\n",
              " array([ 0.03755408, -0.00017328, -0.00495625,  0.09406251], dtype=float32),\n",
              " array([ 0.03755061, -0.19522385, -0.003075  ,  0.38517764], dtype=float32),\n",
              " array([ 0.03364614, -0.390302  ,  0.00462856,  0.6768894 ], dtype=float32),\n",
              " array([ 0.02584009, -0.58548796,  0.01816634,  0.971026  ], dtype=float32),\n",
              " array([ 0.01413034, -0.780849  ,  0.03758686,  1.2693598 ], dtype=float32),\n",
              " array([-1.4866440e-03, -9.7643018e-01,  6.2974058e-02,  1.5735723e+00],\n",
              "       dtype=float32),\n",
              " array([-0.02101525, -1.1722441 ,  0.0944455 ,  1.8852131 ], dtype=float32),\n",
              " array([-0.04446013, -0.97826785,  0.13214977,  1.6232712 ], dtype=float32),\n",
              " array([-0.06402548, -1.1746747 ,  0.1646152 ,  1.954052  ], dtype=float32),\n",
              " array([-0.08751898, -1.3711187 ,  0.20369624,  2.292913  ], dtype=float32),\n",
              " array([-0.11494136, -1.5674564 ,  0.24955449,  2.640804  ], dtype=float32),\n",
              " array([-0.02758753,  0.02483548,  0.04716524,  0.03380205], dtype=float32),\n",
              " array([-0.02709082,  0.21925044,  0.04784128, -0.24363466], dtype=float32),\n",
              " array([-0.02270581,  0.41365758,  0.04296859, -0.52085173], dtype=float32),\n",
              " array([-0.01443266,  0.6081492 ,  0.03255156, -0.7996909 ], dtype=float32),\n",
              " array([-0.00226968,  0.80280983,  0.01655774, -1.0819588 ], dtype=float32),\n",
              " array([ 0.01378652,  0.60747325, -0.00508144, -0.78412634], dtype=float32),\n",
              " array([ 0.02593599,  0.41242152, -0.02076396, -0.49304646], dtype=float32),\n",
              " array([ 0.03418441,  0.6078301 , -0.03062489, -0.79220027], dtype=float32),\n",
              " array([ 0.04634102,  0.41314167, -0.0464689 , -0.5093069 ], dtype=float32),\n",
              " array([ 0.05460385,  0.21870413, -0.05665503, -0.23162238], dtype=float32),\n",
              " array([ 0.05897793,  0.02443557, -0.06128749,  0.04266524], dtype=float32),\n",
              " array([ 0.05946665, -0.16975643, -0.06043418,  0.3153991 ], dtype=float32),\n",
              " array([ 0.05607152,  0.02617197, -0.0541262 ,  0.0042862 ], dtype=float32),\n",
              " array([ 0.05659495,  0.2220267 , -0.05404047, -0.304971  ], dtype=float32),\n",
              " array([ 0.06103549,  0.41787547, -0.06013989, -0.61419547], dtype=float32),\n",
              " array([ 0.069393  ,  0.61378396, -0.0724238 , -0.92519736], dtype=float32),\n",
              " array([ 0.08166867,  0.8098054 , -0.09092775, -1.2397327 ], dtype=float32),\n",
              " array([ 0.09786478,  0.6159611 , -0.1157224 , -0.9768634 ], dtype=float32),\n",
              " array([ 0.11018401,  0.8124287 , -0.13525967, -1.3035403 ], dtype=float32),\n",
              " array([ 0.12643258,  0.6192565 , -0.16133048, -1.0560737 ], dtype=float32),\n",
              " array([ 0.13881771,  0.4265973 , -0.18245195, -0.81806326], dtype=float32),\n",
              " array([ 0.14734966,  0.23437884, -0.19881321, -0.58786505], dtype=float32),\n",
              " array([ 0.15203723,  0.04251467, -0.21057051, -0.3638047 ], dtype=float32),\n",
              " array([ 0.02562804, -0.04909356, -0.01600268,  0.01887734], dtype=float32),\n",
              " array([ 0.02464616, -0.24398239, -0.01562513,  0.30646858], dtype=float32),\n",
              " array([ 0.01976652, -0.04864132, -0.00949576,  0.00889913], dtype=float32),\n",
              " array([ 0.01879369,  0.14661552, -0.00931777, -0.28676462], dtype=float32),\n",
              " array([ 0.021726  ,  0.34186912, -0.01505307, -0.58237165], dtype=float32),\n",
              " array([ 0.02856338,  0.14696126, -0.0267005 , -0.29446846], dtype=float32),\n",
              " array([ 0.03150261, -0.04777005, -0.03258987, -0.01032462], dtype=float32),\n",
              " array([ 0.03054721,  0.14780375, -0.03279636, -0.31310928], dtype=float32),\n",
              " array([ 0.03350328,  0.3433772 , -0.03905855, -0.6159521 ], dtype=float32),\n",
              " array([ 0.04037083,  0.53902245, -0.05137759, -0.92067647], dtype=float32),\n",
              " array([ 0.05115128,  0.7347997 , -0.06979112, -1.2290531 ], dtype=float32),\n",
              " array([ 0.06584727,  0.5406417 , -0.09437218, -0.9590271 ], dtype=float32),\n",
              " array([ 0.0766601 ,  0.34690648, -0.11355273, -0.69742167], dtype=float32),\n",
              " array([ 0.08359823,  0.15352699, -0.12750116, -0.4425333 ], dtype=float32),\n",
              " array([ 0.08666877,  0.35020077, -0.13635182, -0.7725332 ], dtype=float32),\n",
              " array([ 0.09367279,  0.546909  , -0.15180248, -1.1048201 ], dtype=float32),\n",
              " array([ 0.10461096,  0.35407338, -0.17389889, -0.8633519 ], dtype=float32),\n",
              " array([ 0.11169244,  0.16169101, -0.19116592, -0.6299997 ], dtype=float32),\n",
              " array([ 0.11492626,  0.35889375, -0.20376591, -0.97627634], dtype=float32),\n",
              " array([ 0.12210413,  0.5560788 , -0.22329144, -1.3254281 ], dtype=float32),\n",
              " array([-0.02118395,  0.03153773,  0.03434577,  0.00634094], dtype=float32),\n",
              " array([-0.02055319, -0.16405953,  0.03447259,  0.30965945], dtype=float32),\n",
              " array([-0.02383438, -0.35965526,  0.04066578,  0.61301166], dtype=float32),\n",
              " array([-0.03102749, -0.5553212 ,  0.05292601,  0.9182204 ], dtype=float32),\n",
              " array([-0.04213391, -0.75111717,  0.07129042,  1.227056  ], dtype=float32),\n",
              " array([-0.05715625, -0.9470807 ,  0.09583154,  1.5411963 ], dtype=float32),\n",
              " array([-0.07609787, -1.1432154 ,  0.12665546,  1.86218   ], dtype=float32),\n",
              " array([-0.09896218, -0.94968915,  0.16389906,  1.611353  ], dtype=float32),\n",
              " array([-0.11795596, -0.75683826,  0.19612612,  1.3739243 ], dtype=float32),\n",
              " array([-0.13309273, -0.56463265,  0.2236046 ,  1.1484352 ], dtype=float32),\n",
              " array([-0.02595036, -0.02539286,  0.01127601,  0.01102635], dtype=float32),\n",
              " array([-0.02645822,  0.16956559,  0.01149653, -0.27807763], dtype=float32),\n",
              " array([-0.02306691,  0.36452165,  0.00593498, -0.5671125 ], dtype=float32),\n",
              " array([-0.01577647,  0.16931695, -0.00540727, -0.27256575], dtype=float32),\n",
              " array([-0.01239013,  0.36451563, -0.01085858, -0.56694925], dtype=float32),\n",
              " array([-0.00509982,  0.5597882 , -0.02219757, -0.8630332 ], dtype=float32),\n",
              " array([ 0.00609594,  0.7552052 , -0.03945823, -1.1626121 ], dtype=float32),\n",
              " array([ 0.02120005,  0.9508182 , -0.06271047, -1.4674008 ], dtype=float32),\n",
              " array([ 0.04021641,  1.1466492 , -0.09205849, -1.7789948 ], dtype=float32),\n",
              " array([ 0.06314939,  1.3426789 , -0.12763838, -2.0988212 ], dtype=float32),\n",
              " array([ 0.09000298,  1.538832  , -0.1696148 , -2.428081  ], dtype=float32),\n",
              " array([ 0.12077961,  1.3455282 , -0.21817642, -2.1919146 ], dtype=float32),\n",
              " array([ 0.04635832, -0.00025996,  0.01960589, -0.00476407], dtype=float32),\n",
              " array([ 0.04635312,  0.19457541,  0.01951061, -0.29119718], dtype=float32),\n",
              " array([ 0.05024463, -0.00081923,  0.01368666,  0.00757473], dtype=float32),\n",
              " array([ 0.05022825,  0.19410379,  0.01383816, -0.28075865], dtype=float32),\n",
              " array([ 0.05411032, -0.00121279,  0.00822298,  0.01625645], dtype=float32),\n",
              " array([ 0.05408606,  0.19379027,  0.00854811, -0.27382073], dtype=float32),\n",
              " array([ 0.05796187,  0.3887892 ,  0.0030717 , -0.5637953 ], dtype=float32),\n",
              " array([ 0.06573766,  0.1936243 , -0.00820421, -0.27014628], dtype=float32),\n",
              " array([ 0.06961014,  0.38886237, -0.01360713, -0.5654055 ], dtype=float32),\n",
              " array([ 0.07738739,  0.58417255, -0.02491524, -0.862344  ], dtype=float32),\n",
              " array([ 0.08907084,  0.7796247 , -0.04216212, -1.1627556 ], dtype=float32),\n",
              " array([ 0.10466333,  0.5850764 , -0.06541724, -0.8835845 ], dtype=float32),\n",
              " array([ 0.11636486,  0.7810228 , -0.08308893, -1.1960944 ], dtype=float32),\n",
              " array([ 0.13198532,  0.9771162 , -0.10701082, -1.5136198 ], dtype=float32),\n",
              " array([ 0.15152764,  1.1733587 , -0.1372832 , -1.8377008 ], dtype=float32),\n",
              " array([ 0.17499481,  1.3697048 , -0.17403723, -2.1696837 ], dtype=float32),\n",
              " array([ 0.20238891,  1.176657  , -0.2174309 , -1.9353954 ], dtype=float32),\n",
              " array([-0.04700054,  0.03305282, -0.02163158,  0.02893914], dtype=float32),\n",
              " array([-0.04633949, -0.16175234, -0.0210528 ,  0.31471935], dtype=float32),\n",
              " array([-0.04957453, -0.3565682 , -0.01475841,  0.6006893 ], dtype=float32),\n",
              " array([-0.0567059 , -0.1612429 , -0.00274463,  0.30339447], dtype=float32),\n",
              " array([-0.05993076,  0.03391806,  0.00332326,  0.0098472 ], dtype=float32),\n",
              " array([-0.05925239,  0.2289922 ,  0.00352021, -0.28178534], dtype=float32),\n",
              " ...]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sHwLXLPpvdZ"
      },
      "outputs": [],
      "source": [
        "# create a scaler object and fit and transform states\n",
        "scaler = StandardScaler()\n",
        "states = scaler.fit_transform(states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQiVt5VArPZ7",
        "outputId": "3e674656-cf0f-42e4-e942-d97a8609df69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.4426546 , -0.04367049,  0.44278388,  0.0081417 ],\n",
              "       [-0.44561413, -0.39784059,  0.44294407,  0.37464018],\n",
              "       [-0.48816692, -0.04597757,  0.50406589,  0.04182475],\n",
              "       ...,\n",
              "       [-0.4907462 , -1.10414641,  1.75339135,  1.4431109 ],\n",
              "       [-0.61225813, -1.46044489,  1.99223724,  1.85260144],\n",
              "       [-0.77360121, -1.81670249,  2.2991959 ,  2.2687569 ]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "2jwFAR5srPxV",
        "outputId": "55ad4cdb-2f5a-40a0-c289-275443f1b8b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureUnion(transformer_list=[(&#x27;rbf0&#x27;,\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               (&#x27;rbf1&#x27;,\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               (&#x27;rbf2&#x27;,\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               (&#x27;rbf3&#x27;, RBFSampler(n_components=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;rbf0&#x27;,\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               (&#x27;rbf1&#x27;,\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               (&#x27;rbf2&#x27;,\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               (&#x27;rbf3&#x27;, RBFSampler(n_components=1000))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf0</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.05, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.1, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.5, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(n_components=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "FeatureUnion(transformer_list=[('rbf0',\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               ('rbf1',\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               ('rbf2',\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               ('rbf3', RBFSampler(n_components=1000))])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create RBF kernels and an RBF union and fit the kernels to the data\n",
        "rbf_samplers = create_rbf_samplers([0.05, 0.1, 0.5, 1.0], [1000, 1000, 1000, 1000])\n",
        "# create a FeatureUnion object of RBFSamplers\n",
        "rbf_union = FeatureUnion([*rbf_samplers])\n",
        "rbf_union.fit(states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCxDkA7blmBB"
      },
      "outputs": [],
      "source": [
        "# re-code a new agent class that uses scikit learn library\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.env = None\n",
        "        self.scaler = None\n",
        "        self.rbf_union = None\n",
        "        self.model = None\n",
        "        self.learning_rate = None\n",
        "        self.gamma = None\n",
        "        self.epsilon = None\n",
        "        self.epsilon_decay = None\n",
        "        self.min_epsilon = None\n",
        "        self.RBFSamplers = None\n",
        "        self.n_steps = None\n",
        "\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Get action from the Q-table.\n",
        "\n",
        "        Parameters:\n",
        "        -state: int of length n_features representing the assigned bin of each feature\n",
        "\n",
        "        Returns:\n",
        "        -action: random or optimal action\n",
        "        \"\"\"\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return self.env.action_space.sample()\n",
        "        else:\n",
        "            return np.argmax(self.predict(state))\n",
        "\n",
        "    def run_episode(self):\n",
        "        \"\"\"\n",
        "        Run an episode of the agent.\n",
        "\n",
        "        Returns:\n",
        "        -tot_reward: Total reward for the episode.\n",
        "        \"\"\"\n",
        "        state, _ = self.env.reset()\n",
        "        # print(f'state shape: {state.shape}')\n",
        "        if len(state.shape) == 1:\n",
        "            state = state.reshape(1,-1)\n",
        "            # print(f'state reshaped to: {state.shape}')\n",
        "        done = False\n",
        "        tot_reward = 0\n",
        "        tot_loss = 0\n",
        "        sar_tracker = []\n",
        "        while not done:\n",
        "            action = self.get_action(state)\n",
        "            # decay epsilon\n",
        "            next_state, reward, term, trunc, _ = self.env.step(action)\n",
        "            # print(f'next state shape: {next_state.shape}')\n",
        "            if len(next_state.shape) == 1:\n",
        "                next_state = next_state.reshape(1,-1)\n",
        "                # print(f'reshaped next state shape to: {next_state.shape}')\n",
        "            sar_tracker.append((state, action, reward))\n",
        "            tot_reward += reward\n",
        "            # calculate TD loss and add to tot_loss\n",
        "            tot_loss += (reward + self.gamma * np.max(self.predict(next_state))) - self.predict(state)[action]\n",
        "            if len(sar_tracker) == self.n_steps:\n",
        "                self.update(sar_tracker, next_state)\n",
        "                # remove first state from tracker as Q for that state has been updated\n",
        "                sar_tracker.remove(sar_tracker[0])\n",
        "\n",
        "            state = next_state\n",
        "            if term or trunc:\n",
        "                done = True\n",
        "        return tot_reward, tot_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train(self, env, model, episodes, learning_rate, gamma, epsilon, epsilon_decay, min_epsilon, n_steps, scaler=None, feature_union=None):\n",
        "        \"\"\"\n",
        "        Train the agent for a number of episodes.\n",
        "\n",
        "        Parameters:\n",
        "        -env: the gymnasium environment the agent will learn on\n",
        "        -episodes: Number of episodes to train for.\n",
        "        -learning_rate: learning rate of the regression model\n",
        "        -gamma: Discount factor of future rewards.\n",
        "        -epsilon: Epsilon greedy random action threshold.\n",
        "        -epsilon_decay: factor epsilon is multiplied by after every completed episode\n",
        "        -min_epsilon: the minimum number epsilon can be\n",
        "        -n_steps: number of steps taken before updating Q value of a (state, action) pair\n",
        "        -scaler: a StandardScaler() object used to scale state value\n",
        "        -feature_union: a FeatureUnion() object used to project state space onto a higher dimensional feature space\n",
        "\n",
        "\n",
        "        Returns:\n",
        "        -rewards: List of rewards per episode.\n",
        "        -losses: List of losses per episode.\n",
        "        \"\"\"\n",
        "\n",
        "        self.env = env\n",
        "        self.model = model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.n_steps = n_steps\n",
        "        self.scaler = scaler\n",
        "        self.feature_union = feature_union\n",
        "\n",
        "        rewards = []\n",
        "        losses = []\n",
        "        for i in range(episodes):\n",
        "            reward, loss = self.run_episode()\n",
        "            rewards.append(reward)\n",
        "            losses.append(loss)\n",
        "            self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "            if i % 1 == 0:\n",
        "                print(f\"Episode {i}; episode reward: {rewards[-1]}; AVG/10 reward: {np.mean(rewards[-10:])}; AVG/10 loss: {np.mean(losses[-10:])}\")\n",
        "\n",
        "        return rewards, losses\n",
        "\n",
        "    def predict(self, state):\n",
        "        \"\"\"\n",
        "        returns predictions.\n",
        "        Parameters:\n",
        "        -state: state to run prediction on.\n",
        "\n",
        "        Returns:\n",
        "        -predictions:\n",
        "        \"\"\"\n",
        "        if self.scaler:\n",
        "            state = self.scaler.transform(state)\n",
        "        if self.RBFSamplers:\n",
        "            state = self.rbf_union.transform(state)\n",
        "        predictions = np.array([m.predict(state)[0] for m in self.models])\n",
        "        return predictions\n",
        "\n",
        "    def update(self, sar_tracker, next_state):\n",
        "        \"\"\"\n",
        "        updates the model weights using the sar_tracker array.\n",
        "        Parameters:\n",
        "        -sar_tracker: tracks the (state, action, reward) combinations used in an update.\n",
        "\n",
        "        Returns:\n",
        "        -None\n",
        "        \"\"\"\n",
        "        # get action taken at next state\n",
        "        action = self.get_action(next_state)\n",
        "        # predict return taking action at the next state\n",
        "        # target = agent.models[action].predict([next_state])\n",
        "        target = self.predict(next_state)[action]\n",
        "        # multiply target by discount factor (gamma) which is gamma^n_steps\n",
        "        target = target*self.gamma**len(sar_tracker)\n",
        "        # add discounted return to the sum of rewards from previous states in tracker\n",
        "        target += np.sum([r*self.gamma**i for i,(s,a,r) in enumerate(sar_tracker)])\n",
        "        # grab first state from sar_tracker to be used as 'x' value in partial fit\n",
        "        # function of model\n",
        "        s,a,r = sar_tracker[0]\n",
        "        if self.scaler:\n",
        "            s = self.scaler.transform([s])\n",
        "        if self.RBFSamplers:\n",
        "            s = self.rbf_union.transform(s)\n",
        "        self.models[action].partial_fit(s, [target])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf71XZEJtYYO"
      },
      "outputs": [],
      "source": [
        "models = [SGDRegressor(max_iter=episodes, eta0=self.learning_rate) for _ in range(self.env.action_space.n)]\n",
        "        # run partial fit on each to initialize model weights to make initial target and prediction values\n",
        "        for m in self.models:\n",
        "            m.partial_fit(self.rbf_union.transform([self.env.reset()[0]]), [0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynOAwMTYP7_D"
      },
      "source": [
        "# From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jyy2_g9Pyo8"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from typing import List, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19T81lQwQOEm"
      },
      "outputs": [],
      "source": [
        "# instantiate scaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghl6iywtRNjZ"
      },
      "outputs": [],
      "source": [
        "def create_rbf_samplers(sigmas, n_components):\n",
        "    rbf_samplers = []\n",
        "    for e,(s,n) in enumerate(zip(sigmas, n_components)):\n",
        "        rbf_samplers.append((f'rbf{e}',RBFSampler(gamma=s, n_components=n)))\n",
        "    return rbf_samplers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv3tBsIHQvEW"
      },
      "outputs": [],
      "source": [
        "# instantiate rbf kernels and merge into a feature union\n",
        "rbf_samplers = create_rbf_samplers([0.05, 0.1, 0.5, 1.0], [1000, 1000, 1000, 1000])\n",
        "# create a FeatureUnion object of RBFSamplers\n",
        "rbf_union = FeatureUnion([*rbf_samplers])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeep3cwRRPqj"
      },
      "outputs": [],
      "source": [
        "# instantiate cartpole env\n",
        "env = gym.make('CartPole-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZQArrv-SNbv"
      },
      "outputs": [],
      "source": [
        "# collect sample states to fit scaler and rbf kernels\n",
        "sample_states = get_sample_states(env, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzHod-vKSV_I"
      },
      "outputs": [],
      "source": [
        "# scale the sample states\n",
        "sample_states = scaler.fit_transform(sample_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "xEVRKZjGSYqG",
        "outputId": "71c722c8-29f2-489d-b9b4-47e8d555804b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureUnion(transformer_list=[(&#x27;rbf0&#x27;,\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               (&#x27;rbf1&#x27;,\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               (&#x27;rbf2&#x27;,\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               (&#x27;rbf3&#x27;, RBFSampler(n_components=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;rbf0&#x27;,\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               (&#x27;rbf1&#x27;,\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               (&#x27;rbf2&#x27;,\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               (&#x27;rbf3&#x27;, RBFSampler(n_components=1000))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf0</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.05, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.1, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(gamma=0.5, n_components=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rbf3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RBFSampler</label><div class=\"sk-toggleable__content\"><pre>RBFSampler(n_components=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "FeatureUnion(transformer_list=[('rbf0',\n",
              "                                RBFSampler(gamma=0.05, n_components=1000)),\n",
              "                               ('rbf1',\n",
              "                                RBFSampler(gamma=0.1, n_components=1000)),\n",
              "                               ('rbf2',\n",
              "                                RBFSampler(gamma=0.5, n_components=1000)),\n",
              "                               ('rbf3', RBFSampler(n_components=1000))])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit the scaled sample states to the rbf kernel feature union\n",
        "rbf_union.fit(sample_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBfVv4hD0YEk"
      },
      "outputs": [],
      "source": [
        "# code a regressor model\n",
        "class SGDRegressor():\n",
        "\n",
        "    def __init__(self, X, learning_rate):\n",
        "        self.w = np.random.randn(X.shape[1]) / np.sqrt(X.shape[1])\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "\n",
        "    def partial_fit(self, X, y):\n",
        "        \"\"\"\n",
        "        updates model weights\n",
        "        -X: state.\n",
        "        -y: target value.\n",
        "        \"\"\"\n",
        "        # get pred\n",
        "        pred = self.predict(X)\n",
        "        # update model\n",
        "        # self.w-=self.learning_rate*(X.T.dot(pred-y))\n",
        "        self.w-=self.learning_rate*(pred-y).dot(X)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        run forward pass on X.\n",
        "        Parameters:\n",
        "        -X: state.\n",
        "        \"\"\"\n",
        "        # run forward pass\n",
        "        return X.dot(self.w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2opWge5gtOt6"
      },
      "outputs": [],
      "source": [
        "# run sample_states through srbf_kernel to feed to SGDRegressor constructor for weight shaping\n",
        "scaled_samples = rbf_union.transform(sample_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "8i69KhxrTFI5",
        "outputId": "6fa00d4e-b2b0-4030-aa86-1b09c47e1462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode 0: reward=16.0 AVG/100=16.0 epsilon=1.0\n",
            "episode 100: reward=500.0 AVG/100=243.23 epsilon=0.09950371902099892\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d9e981852d13>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_union\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# update while loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mover\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \"\"\"\n\u001b[0;32m-> 1242\u001b[0;31m         Xs = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/kernel_approximation.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mprojection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_weights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mprojection\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_offset_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;31m# thereby passing the test made in the lines following the scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# of warnings context manager.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/warnings.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"%s(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot enter %r twice\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# create models\n",
        "models = [SGDRegressor(scaled_samples, 0.1) for m in range(env.action_space.n)]\n",
        "# code a RL loop\n",
        "num_episodes = 2000\n",
        "epsilon = 1.0\n",
        "gamma = 0.97\n",
        "# set a random state to reproduce results\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "# initialize model\n",
        "rewards = []\n",
        "\n",
        "for n in range(num_episodes):\n",
        "    # reset env\n",
        "    state, _ = env.reset()\n",
        "    # check if state is 1D and if so, make 2D\n",
        "    state = np.atleast_2d(state)\n",
        "    # transform state\n",
        "    state = scaler.transform(state)\n",
        "    state = rbf_union.transform(state)\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    # set epsilon value for episode\n",
        "    eps = epsilon/np.sqrt(n+1)\n",
        "    while not done:\n",
        "\n",
        "        # choose action\n",
        "        if np.random.random() < eps:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax([m.predict(state) for m in models])\n",
        "        # take action\n",
        "        next_state, reward, term, trunc, _ = env.step(action)\n",
        "        # update reward\n",
        "        episode_reward += reward\n",
        "        # transform next state\n",
        "        next_state = np.atleast_2d(next_state)\n",
        "        next_state = scaler.transform(next_state)\n",
        "        next_state = rbf_union.transform(next_state)\n",
        "        # update while loop\n",
        "        if term or trunc:\n",
        "            done = True\n",
        "            if term:\n",
        "                reward = -200\n",
        "        # update model\n",
        "        G = reward + gamma*models[action].predict(next_state)\n",
        "        models[action].partial_fit(state, G)\n",
        "        # update state\n",
        "        state = next_state\n",
        "    rewards.append(episode_reward)\n",
        "    if n % 100 == 0:\n",
        "        print(f'episode {n}: reward={episode_reward} AVG/100={np.mean(rewards[-100:])} epsilon={eps}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "15mHeZ8Wht7F"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self, output_dim: int, input_dim: int=None):\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        # Initialize the weights, for example using random values\n",
        "        # self.w = np.random.randn(input_dim, output_dim)\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # Initialize the weights\n",
        "        self.w = np.random.randn(self.input_dim, self.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        pass\n",
        "\n",
        "    def backward(self, grad, learning_rate):\n",
        "        # Backward pass\n",
        "        pass\n",
        "\n",
        "class DenseLayer(Layer):\n",
        "    def __init__(self, output_dim: int, input_dim: int=None):\n",
        "        super().__init__(output_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        self.x = x\n",
        "        return self.x.dot(self.w)\n",
        "\n",
        "    def backward(self, grad, learning_rate, action):\n",
        "        # Backward pass & update weights\n",
        "        # self.w-=self.learning_rate*(X.T.dot(pred-y))\n",
        "        self.w[:,action] -= learning_rate*grad.dot(self.x)\n",
        "\n",
        "class Loss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, pred, y):\n",
        "        # Forward pass\n",
        "        pass\n",
        "\n",
        "    def backward(self, pred, y):\n",
        "        # Backward pass\n",
        "        pass\n",
        "\n",
        "class MeanSquaredError(Loss):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, pred, y):\n",
        "        # Forward pass\n",
        "        return np.mean((pred-y)**2)\n",
        "\n",
        "    def backward(self, pred, y):\n",
        "        # Backward pass\n",
        "        return pred-y\n",
        "    \n",
        "class TDError(Loss):\n",
        "    def __init__(self, lmbda: float=0.0):\n",
        "        self.e = 0 #eligibility trace\n",
        "        self.lmbda = lmbda\n",
        "    \n",
        "    def forward(self, pred, y):\n",
        "        # Forward pass\n",
        "        return np.mean((pred-y)**2)\n",
        "\n",
        "    def backward(self, pred, y):\n",
        "        # Backward pass\n",
        "        self.e = (pred-y) + (self.lmbda*self.e)\n",
        "        return self.e\n",
        "\n",
        "# Model class\n",
        "class Model:\n",
        "    def __init__(self, layers: List[Layer], loss: Loss, input_data: np.ndarray, learning_rate: float=0.1, learning_rate_decay: Union[bool, str]=False, decay_rate: float=0.97, min_learning_rate: float=0.001):\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.learning_rate_decay = learning_rate_decay\n",
        "        self.decay_rate = decay_rate\n",
        "        self.min_learning_rate = min_learning_rate\n",
        "        self._compile(input_data)\n",
        "\n",
        "    def _compile(self, input_data):\n",
        "        input_dim = input_data.shape[1]\n",
        "        for layer in self.layers:\n",
        "            layer.input_dim = input_dim\n",
        "            layer._init_weights()\n",
        "            input_dim = layer.output_dim\n",
        "\n",
        "\n",
        "    def get_learning_rate(self, episode: int):\n",
        "        if self.learning_rate_decay == 'constant':\n",
        "            return self.learning_rate\n",
        "        elif self.learning_rate_decay == 'exponential':\n",
        "            return max(self.min_learning_rate, self.learning_rate * np.exp(-self.decay_rate*episode))\n",
        "        elif self.learning_rate_decay == 'linear':\n",
        "            return max(self.min_learning_rate, self.learning_rate - self.decay_rate * episode)\n",
        "        elif self.learning_rate_decay == 'inverse':\n",
        "            return max(self.min_learning_rate, self.learning_rate / (1 + self.decay_rate * episode))\n",
        "        else:\n",
        "            return self.learning_rate\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Forward pass\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def update(self, x, y, action, episode):\n",
        "        # Backward pass\n",
        "        grad = self.loss.backward(self.predict(x)[:,action], y)\n",
        "        for layer in reversed(self.layers):\n",
        "            grad = layer.backward(grad, self.get_learning_rate(episode), action)\n",
        "\n",
        "# Agent class\n",
        "class Agent:\n",
        "    def __init__(self, env, model: Model, transformer=None, epsilon=0.1, min_epsilon=0.1, epsilon_decay=0.99, gamma=0.9, step_reward=None, term_reward=None):\n",
        "        self.env = env\n",
        "        self.model = model\n",
        "        self.transformer = transformer\n",
        "        self.epsilon = epsilon\n",
        "        self.min_epsilon = min_epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.gamma = gamma\n",
        "        self.step_reward = step_reward\n",
        "        self.term_reward = term_reward\n",
        "\n",
        "    def get_epsilon(self, episode):\n",
        "        return max(self.min_epsilon, self.epsilon*np.exp(-self.epsilon_decay*episode))\n",
        "\n",
        "    def get_action(self, state, episode):\n",
        "        if np.random.random() < self.get_epsilon(episode):\n",
        "            return self.env.action_space.sample()\n",
        "        else:\n",
        "            return np.argmax(self.model.predict(state))\n",
        "\n",
        "    def play(self, n_episodes: int, render: bool=False)-> list[int]:\n",
        "        rewards = []\n",
        "        for episode in range(n_episodes):\n",
        "            # re-instantiate environment with render mode set to 'human'\n",
        "            self.env = gym.make(self.env.spec.id, render_mode=\"human\")\n",
        "            # Reset the environment\n",
        "            state, _ = self.env.reset()\n",
        "            # make sure state is 2d arrray\n",
        "            state = np.atleast_2d(state)\n",
        "            if self.transformer:\n",
        "                    state = self.transformer.transform(state)\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            while not done:\n",
        "                # set the environment to render in real time\n",
        "                if render:\n",
        "                    self.env.render()\n",
        "                action = np.argmax(self.model.predict(state))\n",
        "                next_state, reward, term, trunc, _ = self.env.step(action)\n",
        "                # make sure next state is a 2D array\n",
        "                next_state = np.atleast_2d(next_state)\n",
        "                # transform next state if exists\n",
        "                if self.transformer:\n",
        "                    next_state = self.transformer.transform(next_state)\n",
        "                if term or trunc:\n",
        "                    done = True\n",
        "                total_reward += reward\n",
        "                # update state\n",
        "                state = next_state\n",
        "            # close the renderer if done\n",
        "            if render:\n",
        "                self.env.close()\n",
        "            rewards.append(total_reward)\n",
        "        return rewards\n",
        "\n",
        "\n",
        "    def train(self, n_episodes, streamlit=False, update_freq=1):\n",
        "        rewards = []\n",
        "        for episode in range(n_episodes):\n",
        "            # Reset the environment\n",
        "            state, _ = self.env.reset()\n",
        "            # make sure state is 2d arrray\n",
        "            state = np.atleast_2d(state)\n",
        "            if self.transformer:\n",
        "                    state = self.transformer.transform(state)\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            while not done:\n",
        "                action = self.get_action(state, episode)\n",
        "                next_state, reward, term, trunc, _ = self.env.step(action)\n",
        "                if self.step_reward:\n",
        "                    reward += self.step_reward\n",
        "                total_reward += reward\n",
        "                # make sure next state is a 2D array\n",
        "                next_state = np.atleast_2d(next_state)\n",
        "                # transform next state if exists\n",
        "                if self.transformer:\n",
        "                    next_state = self.transformer.transform(next_state)\n",
        "                if term or trunc:\n",
        "                    done = True\n",
        "                    if term and self.term_reward:\n",
        "                        reward += self.term_reward\n",
        "                # update model\n",
        "                G = reward + self.gamma*np.max(self.model.predict(next_state))\n",
        "                self.model.update(state, G, action, episode)\n",
        "                # update state\n",
        "                state = next_state\n",
        "            rewards.append(total_reward)\n",
        "            if streamlit:\n",
        "                if episode % update_freq == 0:\n",
        "                    # print({\n",
        "                    #     'episode': episode,\n",
        "                    #     'total_reward': total_reward,\n",
        "                    #     'avg_reward': np.mean(rewards[-100:]),\n",
        "                    #     'epsilon': self.get_epsilon(episode),\n",
        "                    #     'learning_rate': self.model.get_learning_rate(episode)\n",
        "                    # })  # Print values for debugging\n",
        "                    yield {\n",
        "                        'episode': episode,\n",
        "                        'total_reward': total_reward,\n",
        "                        'avg_reward': np.mean(rewards[-100:]),\n",
        "                        'epsilon': self.get_epsilon(episode),\n",
        "                        'learning_rate': self.model.get_learning_rate(episode)\n",
        "                    }\n",
        "            elif episode % 100 == 0:\n",
        "                print(f'episode {episode}: reward={total_reward} AVG/100={np.mean(rewards[-100:])} epsilon={self.get_epsilon(episode)}')\n",
        "\n",
        "class Transformer:\n",
        "    def __init__(self):\n",
        "        self.transformers = []\n",
        "\n",
        "    def add(self, transformer):\n",
        "        self.transformers.append(transformer)\n",
        "\n",
        "    def transform(self, x):\n",
        "        for transformer in self.transformers:\n",
        "            x = transformer.transform(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self, x):\n",
        "        for transformer in self.transformers:\n",
        "            x = transformer.fit_transform(x)\n",
        "        # return x\n",
        "\n",
        "# write a function to gather sample states from env by taking random actions over episodes\n",
        "def get_sample_states(env, n_episodes):\n",
        "    \"\"\"\n",
        "    Plays n_episode number of episodes using random actions and returns states.\n",
        "    Parameters:\n",
        "    -env: gym environment.\n",
        "    -n_episodes: number of episodes to play.\n",
        "\n",
        "    Returns:\n",
        "    -states: list of states.\n",
        "    \"\"\"\n",
        "\n",
        "    states = []\n",
        "\n",
        "    for i in range(n_episodes):\n",
        "        done = False\n",
        "        state, _ = env.reset()\n",
        "        states.append(state)\n",
        "        while not done:\n",
        "            action = env.action_space.sample()\n",
        "            next_state, reward, term, trunc, _ = env.step(action)\n",
        "            states.append(next_state)\n",
        "            if term or trunc:\n",
        "                done = True\n",
        "    return np.array(states)\n",
        "\n",
        "def create_rbf_samplers(sigmas, n_components):\n",
        "    rbf_samplers = []\n",
        "    for e,(s,n) in enumerate(zip(sigmas, n_components)):\n",
        "        rbf_samplers.append((f'rbf{e}',RBFSampler(gamma=s, n_components=n)))\n",
        "    return rbf_samplers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"MountainCar-v0\")\n",
        "sample_states = get_sample_states(env, 1000)\n",
        "transformer = Transformer()\n",
        "scaler = StandardScaler()\n",
        "transformer.add(scaler)\n",
        "rbf_samplers = create_rbf_samplers([0.01, 0.05, 0.1, 0.5, 1.0, 2.0],[500, 500, 500, 500, 500, 500])\n",
        "rbf_union = FeatureUnion([*rbf_samplers])\n",
        "transformer.add(rbf_union)\n",
        "transformer.fit(sample_states)\n",
        "sample_states = transformer.transform(sample_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = [\n",
        "    DenseLayer(3),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = TDError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    layers = layers,\n",
        "    loss = loss,\n",
        "    input_data = sample_states,\n",
        "    learning_rate = 0.1,\n",
        "    learning_rate_decay = 'inverse',\n",
        "    decay_rate = 0.01,\n",
        "    min_learning_rate = 0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = Agent(\n",
        "    env,\n",
        "    model,\n",
        "    transformer,\n",
        "    epsilon = 1.0,\n",
        "    min_epsilon = 0.01,\n",
        "    gamma = 0.9,\n",
        "    step_reward = None,\n",
        "    term_reward = 100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generator object Agent.train at 0x00000213245E09A0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.train(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.99"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.epsilon_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
